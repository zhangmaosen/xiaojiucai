{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAG7 Portfolio Optimization with XiaoJiuCai\n",
    "\n",
    "This notebook demonstrates how to use the XiaoJiuCai framework to optimize a portfolio of MAG7 stocks (Microsoft, Apple, Google, Amazon, Tesla, NVIDIA, and Meta). We'll use locally saved stock data and train a portfolio optimization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install yfinance torch numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# Import xiaojiucai modules\n",
    "from xiaojiucai.data import InRAMDataset, RigidDataLoader, prepare_standard_scaler, Scale\n",
    "from xiaojiucai.models.networks import GreatNet, LSTMNet\n",
    "from xiaojiucai.benchmarks import OneOverN, Random, InverseVolatility, MaximumReturn\n",
    "from xiaojiucai.losses import MaximumDrawdownLoss, MeanReturnsLoss, SharpeRatioLoss, VolatilityLoss\n",
    "from xiaojiucai.experiments import Run\n",
    "from xiaojiucai.callbacks import EarlyStoppingCallback\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Let's load the MAG7 stock data from a local parquet file containing multi-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ../data/mag7_data_raw.parquet\n",
      "Raw data shape: (5027, 35)\n",
      "Raw data columns: [['Close', 'High', 'Low', 'Open', 'Volume'], ['AAPL', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'TSLA']]\n",
      "Close prices data shape: (5027, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-09-26</th>\n",
       "      <td>1.616283</td>\n",
       "      <td>2.1670</td>\n",
       "      <td>7.810992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.601694</td>\n",
       "      <td>0.251990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-27</th>\n",
       "      <td>1.604275</td>\n",
       "      <td>2.1580</td>\n",
       "      <td>7.802541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.650463</td>\n",
       "      <td>0.252831</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-28</th>\n",
       "      <td>1.533428</td>\n",
       "      <td>2.1685</td>\n",
       "      <td>7.605204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.880327</td>\n",
       "      <td>0.254360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-29</th>\n",
       "      <td>1.571253</td>\n",
       "      <td>2.2395</td>\n",
       "      <td>7.695174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.068390</td>\n",
       "      <td>0.259632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>1.609379</td>\n",
       "      <td>2.2650</td>\n",
       "      <td>7.865171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.922119</td>\n",
       "      <td>0.261924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker          AAPL    AMZN     GOOGL  META       MSFT      NVDA  TSLA\n",
       "Date                                                                   \n",
       "2005-09-26  1.616283  2.1670  7.810992   NaN  17.601694  0.251990   NaN\n",
       "2005-09-27  1.604275  2.1580  7.802541   NaN  17.650463  0.252831   NaN\n",
       "2005-09-28  1.533428  2.1685  7.605204   NaN  17.880327  0.254360   NaN\n",
       "2005-09-29  1.571253  2.2395  7.695174   NaN  18.068390  0.259632   NaN\n",
       "2005-09-30  1.609379  2.2650  7.865171   NaN  17.922119  0.261924   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define MAG7 stocks\n",
    "mag7_tickers = ['MSFT', 'AAPL', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META']\n",
    "\n",
    "# Load multi-dimensional data from local parquet file\n",
    "data_path = os.path.join('..', 'data', 'mag7_data_raw.parquet')\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    # Load data from local parquet file\n",
    "    raw_data = pd.read_parquet(data_path)\n",
    "    print(f\"Data loaded from {data_path}\")\n",
    "    print(f\"Raw data shape: {raw_data.shape}\")\n",
    "    print(f\"Raw data columns: {raw_data.columns.levels}\")\n",
    "    \n",
    "    # Select only the 'Close' prices for initial processing\n",
    "    # In later steps, we'll use the full multi-dimensional data\n",
    "    data = raw_data['Close']\n",
    "    print(f\"Close prices data shape: {data.shape}\")\n",
    "else:\n",
    "    print(f\"Data file not found at {data_path}\")\n",
    "    raise FileNotFoundError(f\"Required data file not found: {data_path}\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data:\n",
      "Ticker\n",
      "AAPL        0\n",
      "AMZN        0\n",
      "GOOGL       0\n",
      "META     1674\n",
      "MSFT        0\n",
      "NVDA        0\n",
      "TSLA     1197\n",
      "dtype: int64\n",
      "\n",
      "After filling missing data:\n",
      "Ticker\n",
      "AAPL     0\n",
      "AMZN     0\n",
      "GOOGL    0\n",
      "META     0\n",
      "MSFT     0\n",
      "NVDA     0\n",
      "TSLA     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data\n",
    "print(\"Missing data:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Fill missing data with forward fill\n",
    "data = data.ffill().bfill()\n",
    "print(\"\\nAfter filling missing data:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Returns\n",
    "\n",
    "We'll calculate the log returns from the adjusted closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in returns before filling:\n",
      "Ticker\n",
      "AAPL     1\n",
      "AMZN     1\n",
      "GOOGL    1\n",
      "META     1\n",
      "MSFT     1\n",
      "NVDA     1\n",
      "TSLA     1\n",
      "dtype: int64\n",
      "\n",
      "NaN values in returns after filling:\n",
      "Ticker\n",
      "AAPL     0\n",
      "AMZN     0\n",
      "GOOGL    0\n",
      "META     0\n",
      "MSFT     0\n",
      "NVDA     0\n",
      "TSLA     0\n",
      "dtype: int64\n",
      "\n",
      "Returns shape: (5027, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-09-26</th>\n",
       "      <td>-0.007457</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-27</th>\n",
       "      <td>-0.007457</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-28</th>\n",
       "      <td>-0.045166</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-29</th>\n",
       "      <td>0.024368</td>\n",
       "      <td>0.032217</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>0.020515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.023975</td>\n",
       "      <td>0.011322</td>\n",
       "      <td>0.021851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.008128</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker          AAPL      AMZN     GOOGL  META      MSFT      NVDA  TSLA\n",
       "Date                                                                    \n",
       "2005-09-26 -0.007457 -0.004162 -0.001083   0.0  0.002767  0.003331   0.0\n",
       "2005-09-27 -0.007457 -0.004162 -0.001083   0.0  0.002767  0.003331   0.0\n",
       "2005-09-28 -0.045166  0.004854 -0.025617   0.0  0.012939  0.006027   0.0\n",
       "2005-09-29  0.024368  0.032217  0.011761   0.0  0.010463  0.020515   0.0\n",
       "2005-09-30  0.023975  0.011322  0.021851   0.0 -0.008128  0.008790   0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate log returns\n",
    "returns = np.log(data / data.shift(1))\n",
    "\n",
    "# Check for NaN values in returns\n",
    "print(\"NaN values in returns before filling:\")\n",
    "print(returns.isnull().sum())\n",
    "\n",
    "# Fill NaN values using forward fill then backward fill\n",
    "returns = returns.ffill().bfill()\n",
    "\n",
    "print(\"\\nNaN values in returns after filling:\")\n",
    "print(returns.isnull().sum())\n",
    "\n",
    "print(f\"\\nReturns shape: {returns.shape}\")\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "for ticker in mag7_tickers:\n",
    "    if ticker in returns.columns:\n",
    "        plt.plot(returns.index, returns[ticker], label=ticker, alpha=0.7)\n",
    "    elif (ticker,) in returns.columns:  # Handle tuple column names\n",
    "        plt.plot(returns.index, returns[(ticker,)], label=ticker, alpha=0.7)\n",
    "\n",
    "plt.title('MAG7 Log Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Return')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Training\n",
    "\n",
    "We'll use a rolling window approach to create features and targets for training using multi-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available channels: ['Close', 'High', 'Low', 'Open', 'Volume']\n",
      "Number of channels: 5\n",
      "Number of assets: 7\n",
      "Number of samples: 4947\n",
      "Lookback period: 60 days\n",
      "Prediction horizon: 20 days\n"
     ]
    }
   ],
   "source": [
    "# Parameters for data preparation\n",
    "lookback = 60   # Use 60 days of historical data\n",
    "horizon = 20    # Predict for the next 20 days\n",
    "gap = 1         # No gap between lookback and horizon\n",
    "\n",
    "# Use all available channels (Open, High, Low, Close, Volume)\n",
    "channels = raw_data.columns.levels[0].tolist()\n",
    "n_channels = len(channels)\n",
    "n_assets = len(mag7_tickers)\n",
    "\n",
    "print(f\"Available channels: {channels}\")\n",
    "print(f\"Number of channels: {n_channels}\")\n",
    "print(f\"Number of assets: {n_assets}\")\n",
    "\n",
    "# Get dimensions\n",
    "n_timesteps = len(raw_data)\n",
    "n_samples = n_timesteps - lookback - horizon - gap + 1\n",
    "\n",
    "print(f\"Number of samples: {n_samples}\")\n",
    "print(f\"Lookback period: {lookback} days\")\n",
    "print(f\"Prediction horizon: {horizon} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape: (5027, 5, 7)\n",
      "Handling NaN values in raw data...\n",
      "  Found 14355 NaN values in raw data\n",
      "  After filling: 0 NaN values remaining\n",
      "Features (X) shape: (4947, 60, 5, 7)\n",
      "Targets (y) shape: (4947, 20, 5, 7)\n",
      "NaN values in X: 0\n",
      "NaN values in y: 0\n",
      "Features (X) final shape: (4947, 5, 60, 7)\n",
      "Targets (y) final shape: (4947, 5, 20, 7)\n",
      "\n",
      "Final NaN check:\n",
      "NaN values in X: 0\n",
      "NaN values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# Create features and targets using rolling window with multi-dimensional data\n",
    "X_list, y_list = [], []\n",
    "\n",
    "# Convert to numpy array with shape (n_timesteps, n_channels, n_assets)\n",
    "raw_data_values = np.stack([raw_data[channel].values for channel in channels], axis=1)\n",
    "print(f'Raw data shape: {raw_data_values.shape}')\n",
    "\n",
    "# Handle NaN values in raw data using pandas Series for better filling\n",
    "print(\"Handling NaN values in raw data...\")\n",
    "nan_count_before = np.isnan(raw_data_values).sum()\n",
    "if nan_count_before > 0:\n",
    "    print(f\"  Found {nan_count_before} NaN values in raw data\")\n",
    "    # Create 3D array\n",
    "    filled_data = np.zeros_like(raw_data_values)\n",
    "    \n",
    "    # Use pandas Series for each channel and asset to handle NaN values\n",
    "    for channel in range(raw_data_values.shape[1]):\n",
    "        for asset in range(raw_data_values.shape[2]):\n",
    "            series = pd.Series(raw_data_values[:, channel, asset])\n",
    "            # First try to fill forward\n",
    "            series = series.ffill()\n",
    "            # Then fill backward for any remaining NaNs at the start\n",
    "            series = series.bfill()\n",
    "            # Finally, fill any remaining NaNs with 0 (should be rare)\n",
    "            series = series.fillna(0)\n",
    "            filled_data[:, channel, asset] = series.values\n",
    "            \n",
    "    raw_data_values = filled_data\n",
    "    nan_count_after = np.isnan(raw_data_values).sum()\n",
    "    print(f\"  After filling: {nan_count_after} NaN values remaining\")\n",
    "else:\n",
    "    print(\"  No NaN values found in raw data\")\n",
    "\n",
    "# Create rolling windows\n",
    "for i in range(lookback, n_timesteps - horizon - gap + 1):\n",
    "    X_list.append(raw_data_values[i - lookback: i, :, :])\n",
    "    y_list.append(raw_data_values[i + gap: i + gap + horizon, :, :])\n",
    "\n",
    "# Stack into arrays\n",
    "X = np.stack(X_list, axis=0)\n",
    "y = np.stack(y_list, axis=0)\n",
    "\n",
    "print(f'Features (X) shape: {X.shape}')  # (n_samples, lookback, n_channels, n_assets)\n",
    "print(f'Targets (y) shape: {y.shape}')   # (n_samples, horizon, n_channels, n_assets)\n",
    "\n",
    "# Double check for any remaining NaN values\n",
    "X_nan_count = np.isnan(X).sum()\n",
    "y_nan_count = np.isnan(y).sum()\n",
    "print(f\"NaN values in X: {X_nan_count}\")\n",
    "print(f\"NaN values in y: {y_nan_count}\")\n",
    "\n",
    "# If there are any remaining NaNs (which should be extremely rare), fill them\n",
    "if X_nan_count > 0:\n",
    "    print(\"Filling remaining NaNs in X with 0...\")\n",
    "    X = np.nan_to_num(X, nan=0.0)\n",
    "if y_nan_count > 0:\n",
    "    print(\"Filling remaining NaNs in y with 0...\")\n",
    "    y = np.nan_to_num(y, nan=0.0)\n",
    "\n",
    "# Transpose to match expected format (n_samples, n_channels, lookback, n_assets)\n",
    "X = np.transpose(X, (0, 2, 1, 3))\n",
    "y = np.transpose(y, (0, 2, 1, 3))\n",
    "\n",
    "print(f'Features (X) final shape: {X.shape}')\n",
    "print(f'Targets (y) final shape: {y.shape}')\n",
    "\n",
    "# Final verification\n",
    "print(\"\\nFinal NaN check:\")\n",
    "print(f\"NaN values in X: {np.isnan(X).sum()}\")\n",
    "print(f\"NaN values in y: {np.isnan(y).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.61628306e+00 2.16700006e+00 7.81099224e+00 ... 1.76016941e+01\n",
      "    2.51990378e-01 1.59266698e+00]\n",
      "   [1.60427475e+00 2.15799999e+00 7.80254126e+00 ... 1.76504631e+01\n",
      "    2.52831161e-01 1.59266698e+00]\n",
      "   [1.53342807e+00 2.16849995e+00 7.60520411e+00 ... 1.78803272e+01\n",
      "    2.54359603e-01 1.59266698e+00]\n",
      "   ...\n",
      "   [2.16685224e+00 2.47399998e+00 1.05018921e+01 ... 1.88059769e+01\n",
      "    2.79115587e-01 1.59266698e+00]\n",
      "   [2.13473105e+00 2.46050000e+00 1.06907797e+01 ... 1.87920017e+01\n",
      "    2.81559885e-01 1.59266698e+00]\n",
      "   [2.14283514e+00 2.41849995e+00 1.05528421e+01 ... 1.87431068e+01\n",
      "    2.76899368e-01 1.59266698e+00]]\n",
      "\n",
      "  [[1.63789724e+00 2.17100000e+00 7.97676622e+00 ... 1.77549335e+01\n",
      "    2.53748052e-01 1.66666698e+00]\n",
      "   [1.62829129e+00 2.18650007e+00 7.91363673e+00 ... 1.77270835e+01\n",
      "    2.55276476e-01 1.66666698e+00]\n",
      "   [1.59436891e+00 2.18700004e+00 7.83137114e+00 ... 1.80196369e+01\n",
      "    2.55047272e-01 1.66666698e+00]\n",
      "   ...\n",
      "   [2.18726618e+00 2.49749994e+00 1.05165567e+01 ... 1.89387089e+01\n",
      "    2.84616885e-01 1.66666698e+00]\n",
      "   [2.17045502e+00 2.49600005e+00 1.07491852e+01 ... 1.89177477e+01\n",
      "    2.82782993e-01 1.66666698e+00]\n",
      "   [2.17945930e+00 2.50000000e+00 1.10899284e+01 ... 1.87710510e+01\n",
      "    2.84234465e-01 1.66666698e+00]]\n",
      "\n",
      "  [[1.60067294e+00 2.11999989e+00 7.76824441e+00 ... 1.75599004e+01\n",
      "    2.47329854e-01 1.16933298e+00]\n",
      "   [1.60397464e+00 2.14100003e+00 7.78862301e+00 ... 1.76226006e+01\n",
      "    2.50921285e-01 1.16933298e+00]\n",
      "   [1.51871818e+00 2.14949989e+00 7.59526243e+00 ... 1.76783283e+01\n",
      "    2.50692054e-01 1.16933298e+00]\n",
      "   ...\n",
      "   [2.14193537e+00 2.45250010e+00 1.03515286e+01 ... 1.87291318e+01\n",
      "    2.76211808e-01 1.16933298e+00]\n",
      "   [2.13322981e+00 2.46050000e+00 1.05068618e+01 ... 1.87291287e+01\n",
      "    2.77433899e-01 1.16933298e+00]\n",
      "   [2.13262827e+00 2.41599989e+00 1.04412489e+01 ... 1.86173609e+01\n",
      "    2.76211726e-01 1.16933298e+00]]\n",
      "\n",
      "  [[1.62198711e+00 2.12249994e+00 7.94072747e+00 ... 1.76922444e+01\n",
      "    2.51838176e-01 1.26666701e+00]\n",
      "   [1.61868454e+00 2.16300011e+00 7.82764383e+00 ... 1.76713599e+01\n",
      "    2.53060366e-01 1.26666701e+00]\n",
      "   [1.59316778e+00 2.16249990e+00 7.80949974e+00 ... 1.76852940e+01\n",
      "    2.53594904e-01 1.26666701e+00]\n",
      "   ...\n",
      "   [2.18186224e+00 2.47499990e+00 1.04163964e+01 ... 1.89177508e+01\n",
      "    2.82476875e-01 1.26666701e+00]\n",
      "   [2.16565189e+00 2.47000003e+00 1.05712333e+01 ... 1.87780297e+01\n",
      "    2.80108446e-01 1.26666701e+00]\n",
      "   [2.13472973e+00 2.44950008e+00 1.07417297e+01 ... 1.87361208e+01\n",
      "    2.82171459e-01 1.26666701e+00]]\n",
      "\n",
      "  [[5.46562800e+08 1.12328000e+08 3.95380224e+08 ... 5.62037000e+07\n",
      "    4.06776000e+08 2.81494500e+08]\n",
      "   [3.41703600e+08 8.34700000e+07 2.74649076e+08 ... 4.87979000e+07\n",
      "    4.04160000e+08 2.81494500e+08]\n",
      "   [1.12554400e+09 6.47940000e+07 3.19576104e+08 ... 7.10194000e+07\n",
      "    3.53556000e+08 2.81494500e+08]\n",
      "   ...\n",
      "   [5.61162000e+08 1.16410000e+08 2.41590168e+08 ... 7.90181000e+07\n",
      "    3.32724000e+08 2.81494500e+08]\n",
      "   [6.71171200e+08 1.12530000e+08 6.52566780e+08 ... 8.85425000e+07\n",
      "    1.06560000e+09 2.81494500e+08]\n",
      "   [5.29295200e+08 1.66174000e+08 8.76594528e+08 ... 6.86801000e+07\n",
      "    2.92296000e+08 2.81494500e+08]]]\n",
      "\n",
      "\n",
      " [[[1.60427475e+00 2.15799999e+00 7.80254126e+00 ... 1.76504631e+01\n",
      "    2.52831161e-01 1.59266698e+00]\n",
      "   [1.53342807e+00 2.16849995e+00 7.60520411e+00 ... 1.78803272e+01\n",
      "    2.54359603e-01 1.59266698e+00]\n",
      "   [1.57125306e+00 2.23950005e+00 7.69517374e+00 ... 1.80683899e+01\n",
      "    2.59631693e-01 1.59266698e+00]\n",
      "   ...\n",
      "   [2.13473105e+00 2.46050000e+00 1.06907797e+01 ... 1.87920017e+01\n",
      "    2.81559885e-01 1.59266698e+00]\n",
      "   [2.14283514e+00 2.41849995e+00 1.05528421e+01 ... 1.87431068e+01\n",
      "    2.76899368e-01 1.59266698e+00]\n",
      "   [2.16475034e+00 2.40700006e+00 1.06805906e+01 ... 1.87640553e+01\n",
      "    2.76746273e-01 1.59266698e+00]]\n",
      "\n",
      "  [[1.62829129e+00 2.18650007e+00 7.91363673e+00 ... 1.77270835e+01\n",
      "    2.55276476e-01 1.66666698e+00]\n",
      "   [1.59436891e+00 2.18700004e+00 7.83137114e+00 ... 1.80196369e+01\n",
      "    2.55047272e-01 1.66666698e+00]\n",
      "   [1.57875766e+00 2.24000001e+00 7.72251299e+00 ... 1.81101822e+01\n",
      "    2.59783895e-01 1.66666698e+00]\n",
      "   ...\n",
      "   [2.17045502e+00 2.49600005e+00 1.07491852e+01 ... 1.89177477e+01\n",
      "    2.82782993e-01 1.66666698e+00]\n",
      "   [2.17945930e+00 2.50000000e+00 1.10899284e+01 ... 1.87710510e+01\n",
      "    2.84234465e-01 1.66666698e+00]\n",
      "   [2.17285595e+00 2.43000007e+00 1.07417305e+01 ... 1.87780260e+01\n",
      "    2.80796158e-01 1.66666698e+00]]\n",
      "\n",
      "  [[1.60397464e+00 2.14100003e+00 7.78862301e+00 ... 1.76226006e+01\n",
      "    2.50921285e-01 1.16933298e+00]\n",
      "   [1.51871818e+00 2.14949989e+00 7.59526243e+00 ... 1.76783283e+01\n",
      "    2.50692054e-01 1.16933298e+00]\n",
      "   [1.52532223e+00 2.15650010e+00 7.60719232e+00 ... 1.77619095e+01\n",
      "    2.52372696e-01 1.16933298e+00]\n",
      "   ...\n",
      "   [2.13322981e+00 2.46050000e+00 1.05068618e+01 ... 1.87291287e+01\n",
      "    2.77433899e-01 1.16933298e+00]\n",
      "   [2.13262827e+00 2.41599989e+00 1.04412489e+01 ... 1.86173609e+01\n",
      "    2.76211726e-01 1.16933298e+00]\n",
      "   [2.13503055e+00 2.38400006e+00 1.05545819e+01 ... 1.86313233e+01\n",
      "    2.73078724e-01 1.16933298e+00]]\n",
      "\n",
      "  [[1.61868454e+00 2.16300011e+00 7.82764383e+00 ... 1.76713599e+01\n",
      "    2.53060366e-01 1.26666701e+00]\n",
      "   [1.59316778e+00 2.16249990e+00 7.80949974e+00 ... 1.76852940e+01\n",
      "    2.53594904e-01 1.26666701e+00]\n",
      "   [1.53793067e+00 2.16899991e+00 7.62210459e+00 ... 1.78385299e+01\n",
      "    2.54435703e-01 1.26666701e+00]\n",
      "   ...\n",
      "   [2.16565189e+00 2.47000003e+00 1.05712333e+01 ... 1.87780297e+01\n",
      "    2.80108446e-01 1.26666701e+00]\n",
      "   [2.13472973e+00 2.44950008e+00 1.07417297e+01 ... 1.87361208e+01\n",
      "    2.82171459e-01 1.26666701e+00]\n",
      "   [2.15034055e+00 2.42300010e+00 1.06338653e+01 ... 1.86941963e+01\n",
      "    2.76594071e-01 1.26666701e+00]]\n",
      "\n",
      "  [[3.41703600e+08 8.34700000e+07 2.74649076e+08 ... 4.87979000e+07\n",
      "    4.04160000e+08 2.81494500e+08]\n",
      "   [1.12554400e+09 6.47940000e+07 3.19576104e+08 ... 7.10194000e+07\n",
      "    3.53556000e+08 2.81494500e+08]\n",
      "   [6.36846000e+08 1.27856000e+08 2.24327448e+08 ... 6.68071000e+07\n",
      "    5.13372000e+08 2.81494500e+08]\n",
      "   ...\n",
      "   [6.71171200e+08 1.12530000e+08 6.52566780e+08 ... 8.85425000e+07\n",
      "    1.06560000e+09 2.81494500e+08]\n",
      "   [5.29295200e+08 1.66174000e+08 8.76594528e+08 ... 6.86801000e+07\n",
      "    2.92296000e+08 2.81494500e+08]\n",
      "   [4.79108000e+08 1.10704000e+08 4.02984612e+08 ... 6.29606000e+07\n",
      "    3.04356000e+08 2.81494500e+08]]]\n",
      "\n",
      "\n",
      " [[[1.53342807e+00 2.16849995e+00 7.60520411e+00 ... 1.78803272e+01\n",
      "    2.54359603e-01 1.59266698e+00]\n",
      "   [1.57125306e+00 2.23950005e+00 7.69517374e+00 ... 1.80683899e+01\n",
      "    2.59631693e-01 1.59266698e+00]\n",
      "   [1.60937893e+00 2.26500010e+00 7.86517143e+00 ... 1.79221191e+01\n",
      "    2.61923879e-01 1.59266698e+00]\n",
      "   ...\n",
      "   [2.14283514e+00 2.41849995e+00 1.05528421e+01 ... 1.87431068e+01\n",
      "    2.76899368e-01 1.59266698e+00]\n",
      "   [2.16475034e+00 2.40700006e+00 1.06805906e+01 ... 1.87640553e+01\n",
      "    2.76746273e-01 1.59266698e+00]\n",
      "   [2.20647860e+00 2.44849992e+00 1.05958395e+01 ... 1.86732368e+01\n",
      "    2.76211858e-01 1.59266698e+00]]\n",
      "\n",
      "  [[1.59436891e+00 2.18700004e+00 7.83137114e+00 ... 1.80196369e+01\n",
      "    2.55047272e-01 1.66666698e+00]\n",
      "   [1.57875766e+00 2.24000001e+00 7.72251299e+00 ... 1.81101822e+01\n",
      "    2.59783895e-01 1.66666698e+00]\n",
      "   [1.61057927e+00 2.29200006e+00 7.89101940e+00 ... 1.80753600e+01\n",
      "    2.64292191e-01 1.66666698e+00]\n",
      "   ...\n",
      "   [2.17945930e+00 2.50000000e+00 1.10899284e+01 ... 1.87710510e+01\n",
      "    2.84234465e-01 1.66666698e+00]\n",
      "   [2.17285595e+00 2.43000007e+00 1.07417305e+01 ... 1.87780260e+01\n",
      "    2.80796158e-01 1.66666698e+00]\n",
      "   [2.20978108e+00 2.45300007e+00 1.08575481e+01 ... 1.87989828e+01\n",
      "    2.80337845e-01 1.66666698e+00]]\n",
      "\n",
      "  [[1.51871818e+00 2.14949989e+00 7.59526243e+00 ... 1.76783283e+01\n",
      "    2.50692054e-01 1.16933298e+00]\n",
      "   [1.52532223e+00 2.15650010e+00 7.60719232e+00 ... 1.77619095e+01\n",
      "    2.52372696e-01 1.16933298e+00]\n",
      "   [1.55744383e+00 2.23000002e+00 7.76153234e+00 ... 1.78385344e+01\n",
      "    2.59249333e-01 1.16933298e+00]\n",
      "   ...\n",
      "   [2.13262827e+00 2.41599989e+00 1.04412489e+01 ... 1.86173609e+01\n",
      "    2.76211726e-01 1.16933298e+00]\n",
      "   [2.13503055e+00 2.38400006e+00 1.05545819e+01 ... 1.86313233e+01\n",
      "    2.73078724e-01 1.16933298e+00]\n",
      "   [2.17765902e+00 2.38899994e+00 1.04561626e+01 ... 1.86592648e+01\n",
      "    2.73690413e-01 1.16933298e+00]]\n",
      "\n",
      "  [[1.59316778e+00 2.16249990e+00 7.80949974e+00 ... 1.76852940e+01\n",
      "    2.53594904e-01 1.26666701e+00]\n",
      "   [1.53793067e+00 2.16899991e+00 7.62210459e+00 ... 1.78385299e+01\n",
      "    2.54435703e-01 1.26666701e+00]\n",
      "   [1.57095340e+00 2.23250008e+00 7.80949939e+00 ... 1.80474976e+01\n",
      "    2.59783870e-01 1.26666701e+00]\n",
      "   ...\n",
      "   [2.13472973e+00 2.44950008e+00 1.07417297e+01 ... 1.87361208e+01\n",
      "    2.82171459e-01 1.26666701e+00]\n",
      "   [2.15034055e+00 2.42300010e+00 1.06338653e+01 ... 1.86941963e+01\n",
      "    2.76594071e-01 1.26666701e+00]\n",
      "   [2.17946027e+00 2.41450000e+00 1.07752831e+01 ... 1.87710400e+01\n",
      "    2.78045633e-01 1.26666701e+00]]\n",
      "\n",
      "  [[1.12554400e+09 6.47940000e+07 3.19576104e+08 ... 7.10194000e+07\n",
      "    3.53556000e+08 2.81494500e+08]\n",
      "   [6.36846000e+08 1.27856000e+08 2.24327448e+08 ... 6.68071000e+07\n",
      "    5.13372000e+08 2.81494500e+08]\n",
      "   [5.31633200e+08 1.21120000e+08 3.65685948e+08 ... 5.76445000e+07\n",
      "    4.58832000e+08 2.81494500e+08]\n",
      "   ...\n",
      "   [5.29295200e+08 1.66174000e+08 8.76594528e+08 ... 6.86801000e+07\n",
      "    2.92296000e+08 2.81494500e+08]\n",
      "   [4.79108000e+08 1.10704000e+08 4.02984612e+08 ... 6.29606000e+07\n",
      "    3.04356000e+08 2.81494500e+08]\n",
      "   [4.75736800e+08 1.46450000e+08 4.48427124e+08 ... 7.58009000e+07\n",
      "    2.89380000e+08 2.81494500e+08]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[2.01860901e+02 2.01119995e+02 1.68205750e+02 ... 4.51827240e+02\n",
      "    1.31783417e+02 3.34619995e+02]\n",
      "   [2.01131729e+02 2.03100006e+02 1.70510895e+02 ... 4.54113464e+02\n",
      "    1.32813293e+02 3.41040009e+02]\n",
      "   [1.95048645e+02 2.00990005e+02 1.68115936e+02 ... 4.49441162e+02\n",
      "    1.31273483e+02 3.39339996e+02]\n",
      "   ...\n",
      "   [2.33330002e+02 2.24559998e+02 2.01779541e+02 ... 5.19725647e+02\n",
      "    1.81579758e+02 3.39380005e+02]\n",
      "   [2.32779999e+02 2.30979996e+02 2.02758652e+02 ... 5.21622498e+02\n",
      "    1.82009735e+02 3.35579987e+02]\n",
      "   [2.31589996e+02 2.31029999e+02 2.03717789e+02 ... 5.19316284e+02\n",
      "    1.80439819e+02 3.30559998e+02]]\n",
      "\n",
      "  [[2.06805286e+02 2.03460007e+02 1.72776126e+02 ... 4.57028681e+02\n",
      "    1.37382703e+02 3.47350006e+02]\n",
      "   [2.02520153e+02 2.05759995e+02 1.76398504e+02 ... 4.59494633e+02\n",
      "    1.34233113e+02 3.47269989e+02]\n",
      "   [1.97475883e+02 2.02369995e+02 1.69602810e+02 ... 4.52945411e+02\n",
      "    1.32663308e+02 3.43179993e+02]\n",
      "   ...\n",
      "   [2.35000000e+02 2.24919998e+02 2.04347237e+02 ... 5.31825751e+02\n",
      "    1.83959628e+02 3.48980011e+02]\n",
      "   [2.35119995e+02 2.33110001e+02 2.04257311e+02 ... 5.25086834e+02\n",
      "    1.83009679e+02 3.40470001e+02]\n",
      "   [2.34279999e+02 2.34080002e+02 2.06255527e+02 ... 5.25236545e+02\n",
      "    1.81889735e+02 3.39299988e+02]]\n",
      "\n",
      "  [[2.00482476e+02 2.00059998e+02 1.63216258e+02 ... 4.51068478e+02\n",
      "    1.30573562e+02 3.32200012e+02]\n",
      "   [1.99473607e+02 2.00160004e+02 1.70351243e+02 ... 4.53155048e+02\n",
      "    1.31533456e+02 3.31390015e+02]\n",
      "   [1.93240699e+02 1.97850006e+02 1.67537153e+02 ... 4.48173257e+02\n",
      "    1.29143762e+02 3.33209991e+02]\n",
      "   ...\n",
      "   [2.30429993e+02 2.22000000e+02 1.97333505e+02 ... 5.18517611e+02\n",
      "    1.79339894e+02 3.38200012e+02]\n",
      "   [2.30850006e+02 2.27020004e+02 2.01050173e+02 ... 5.19286372e+02\n",
      "    1.79449882e+02 3.30399994e+02]\n",
      "   [2.29339996e+02 2.29809998e+02 2.01100135e+02 ... 5.18228107e+02\n",
      "    1.78029952e+02 3.27019989e+02]]\n",
      "\n",
      "  [[2.04937411e+02 2.01610001e+02 1.63345989e+02 ... 4.53823958e+02\n",
      "    1.33043253e+02 3.44429993e+02]\n",
      "   [2.00482472e+02 2.01380005e+02 1.71488846e+02 ... 4.54203343e+02\n",
      "    1.32213363e+02 3.31899994e+02]\n",
      "   [1.93450453e+02 1.98899994e+02 1.68704693e+02 ... 4.49241509e+02\n",
      "    1.29983652e+02 3.37920013e+02]\n",
      "   ...\n",
      "   [2.31070007e+02 2.22000000e+02 2.03947600e+02 ... 5.31236692e+02\n",
      "    1.82609698e+02 3.41500000e+02]\n",
      "   [2.34059998e+02 2.27399994e+02 2.01319936e+02 ... 5.21702383e+02\n",
      "    1.79739859e+02 3.35760010e+02]\n",
      "   [2.34000000e+02 2.32580002e+02 2.03667846e+02 ... 5.21912054e+02\n",
      "    1.81869747e+02 3.37660004e+02]]\n",
      "\n",
      "  [[5.92118000e+07 4.24609000e+07 7.34160000e+07 ... 1.92169000e+07\n",
      "    2.70608700e+08 1.02354800e+08]\n",
      "   [4.67424000e+07 3.89389000e+07 7.48644000e+07 ... 1.80256000e+07\n",
      "    1.87344000e+08 9.71134000e+07]\n",
      "   [7.84329000e+07 3.33935000e+07 3.52114000e+07 ... 1.68835000e+07\n",
      "    1.98821300e+08 8.46548000e+07]\n",
      "   ...\n",
      "   [6.98785000e+07 3.65083000e+07 2.83429000e+07 ... 1.96192000e+07\n",
      "    1.79871700e+08 6.78389000e+07]\n",
      "   [5.19163000e+07 6.15458000e+07 2.52304000e+07 ... 2.02691000e+07\n",
      "    1.29554000e+08 7.50007000e+07]\n",
      "   [5.60387000e+07 3.96492000e+07 3.49314000e+07 ... 2.52133000e+07\n",
      "    1.56602200e+08 7.43198000e+07]]]\n",
      "\n",
      "\n",
      " [[[2.01131729e+02 2.03100006e+02 1.70510895e+02 ... 4.54113464e+02\n",
      "    1.32813293e+02 3.41040009e+02]\n",
      "   [1.95048645e+02 2.00990005e+02 1.68115936e+02 ... 4.49441162e+02\n",
      "    1.31273483e+02 3.39339996e+02]\n",
      "   [1.99983047e+02 2.06020004e+02 1.72536621e+02 ... 4.59933899e+02\n",
      "    1.35482941e+02 3.62890015e+02]\n",
      "   ...\n",
      "   [2.32779999e+02 2.30979996e+02 2.02758652e+02 ... 5.21622498e+02\n",
      "    1.82009735e+02 3.35579987e+02]\n",
      "   [2.31589996e+02 2.31029999e+02 2.03717789e+02 ... 5.19316284e+02\n",
      "    1.80439819e+02 3.30559998e+02]\n",
      "   [2.30889999e+02 2.31490005e+02 2.03318161e+02 ... 5.16251282e+02\n",
      "    1.81999725e+02 3.35160004e+02]]\n",
      "\n",
      "  [[2.02520153e+02 2.05759995e+02 1.76398504e+02 ... 4.59494633e+02\n",
      "    1.34233113e+02 3.47269989e+02]\n",
      "   [1.97475883e+02 2.02369995e+02 1.69602810e+02 ... 4.52945411e+02\n",
      "    1.32663308e+02 3.43179993e+02]\n",
      "   [2.00512445e+02 2.06690002e+02 1.72806058e+02 ... 4.60193482e+02\n",
      "    1.35642924e+02 3.63790009e+02]\n",
      "   ...\n",
      "   [2.35119995e+02 2.33110001e+02 2.04257311e+02 ... 5.25086834e+02\n",
      "    1.83009679e+02 3.40470001e+02]\n",
      "   [2.34279999e+02 2.34080002e+02 2.06255527e+02 ... 5.25236545e+02\n",
      "    1.81889735e+02 3.39299988e+02]\n",
      "   [2.33119995e+02 2.31910004e+02 2.05086584e+02 ... 5.21961925e+02\n",
      "    1.82929681e+02 3.36269989e+02]]\n",
      "\n",
      "  [[1.99473607e+02 2.00160004e+02 1.70351243e+02 ... 4.53155048e+02\n",
      "    1.31533456e+02 3.31390015e+02]\n",
      "   [1.93240699e+02 1.97850006e+02 1.67537153e+02 ... 4.48173257e+02\n",
      "    1.29143762e+02 3.33209991e+02]\n",
      "   [1.97206185e+02 2.02190002e+02 1.69642722e+02 ... 4.55371392e+02\n",
      "    1.33293214e+02 3.47320007e+02]\n",
      "   ...\n",
      "   [2.30850006e+02 2.27020004e+02 2.01050173e+02 ... 5.19286372e+02\n",
      "    1.79449882e+02 3.30399994e+02]\n",
      "   [2.29339996e+02 2.29809998e+02 2.01100135e+02 ... 5.18228107e+02\n",
      "    1.78029952e+02 3.27019989e+02]\n",
      "   [2.30110001e+02 2.28330002e+02 2.02309069e+02 ... 5.13176381e+02\n",
      "    1.80579807e+02 3.29589996e+02]]\n",
      "\n",
      "  [[2.00482472e+02 2.01380005e+02 1.71488846e+02 ... 4.54203343e+02\n",
      "    1.32213363e+02 3.31899994e+02]\n",
      "   [1.93450453e+02 1.98899994e+02 1.68704693e+02 ... 4.49241509e+02\n",
      "    1.29983652e+02 3.37920013e+02]\n",
      "   [1.98075209e+02 2.03089996e+02 1.69802389e+02 ... 4.55730817e+02\n",
      "    1.34133105e+02 3.47350006e+02]\n",
      "   ...\n",
      "   [2.34059998e+02 2.27399994e+02 2.01319936e+02 ... 5.21702383e+02\n",
      "    1.79739859e+02 3.35760010e+02]\n",
      "   [2.34000000e+02 2.32580002e+02 2.03667846e+02 ... 5.21912054e+02\n",
      "    1.81869747e+02 3.37660004e+02]\n",
      "   [2.31699997e+02 2.30229996e+02 2.04017532e+02 ... 5.20733964e+02\n",
      "    1.80589816e+02 3.29619995e+02]]\n",
      "\n",
      "  [[4.67424000e+07 3.89389000e+07 7.48644000e+07 ... 1.80256000e+07\n",
      "    1.87344000e+08 9.71134000e+07]\n",
      "   [7.84329000e+07 3.33935000e+07 3.52114000e+07 ... 1.68835000e+07\n",
      "    1.98821300e+08 8.46548000e+07]\n",
      "   [5.62885000e+07 3.48920000e+07 3.79957000e+07 ... 2.09743000e+07\n",
      "    1.92953600e+08 1.20146400e+08]\n",
      "   ...\n",
      "   [5.19163000e+07 6.15458000e+07 2.52304000e+07 ... 2.02691000e+07\n",
      "    1.29554000e+08 7.50007000e+07]\n",
      "   [5.60387000e+07 3.96492000e+07 3.49314000e+07 ... 2.52133000e+07\n",
      "    1.56602200e+08 7.43198000e+07]\n",
      "   [3.74762000e+07 2.52489000e+07 1.85266000e+07 ... 2.37606000e+07\n",
      "    1.32008000e+08 5.69566000e+07]]]\n",
      "\n",
      "\n",
      " [[[1.95048645e+02 2.00990005e+02 1.68115936e+02 ... 4.49441162e+02\n",
      "    1.31273483e+02 3.39339996e+02]\n",
      "   [1.99983047e+02 2.06020004e+02 1.72536621e+02 ... 4.59933899e+02\n",
      "    1.35482941e+02 3.62890015e+02]\n",
      "   [2.00192795e+02 2.04720001e+02 1.71997757e+02 ... 4.56609375e+02\n",
      "    1.34793045e+02 3.56899994e+02]\n",
      "   ...\n",
      "   [2.31589996e+02 2.31029999e+02 2.03717789e+02 ... 5.19316284e+02\n",
      "    1.80439819e+02 3.30559998e+02]\n",
      "   [2.30889999e+02 2.31490005e+02 2.03318161e+02 ... 5.16251282e+02\n",
      "    1.81999725e+02 3.35160004e+02]\n",
      "   [2.30559998e+02 2.28009995e+02 2.01389893e+02 ... 5.08933350e+02\n",
      "    1.75630096e+02 3.29309998e+02]]\n",
      "\n",
      "  [[1.97475883e+02 2.02369995e+02 1.69602810e+02 ... 4.52945411e+02\n",
      "    1.32663308e+02 3.43179993e+02]\n",
      "   [2.00512445e+02 2.06690002e+02 1.72806058e+02 ... 4.60193482e+02\n",
      "    1.35642924e+02 3.63790009e+02]\n",
      "   [2.02500174e+02 2.07660004e+02 1.74901645e+02 ... 4.61760910e+02\n",
      "    1.37232741e+02 3.65000000e+02]\n",
      "   ...\n",
      "   [2.34279999e+02 2.34080002e+02 2.06255527e+02 ... 5.25236545e+02\n",
      "    1.81889735e+02 3.39299988e+02]\n",
      "   [2.33119995e+02 2.31910004e+02 2.05086584e+02 ... 5.21961925e+02\n",
      "    1.82929681e+02 3.36269989e+02]\n",
      "   [2.32869995e+02 2.30529999e+02 2.03258217e+02 ... 5.14314488e+02\n",
      "    1.82489710e+02 3.40549988e+02]]\n",
      "\n",
      "  [[1.93240699e+02 1.97850006e+02 1.67537153e+02 ... 4.48173257e+02\n",
      "    1.29143762e+02 3.33209991e+02]\n",
      "   [1.97206185e+02 2.02190002e+02 1.69642722e+02 ... 4.55371392e+02\n",
      "    1.33293214e+02 3.47320007e+02]\n",
      "   [1.99673380e+02 2.04410004e+02 1.71548706e+02 ... 4.56180088e+02\n",
      "    1.34773043e+02 3.55910004e+02]\n",
      "   ...\n",
      "   [2.29339996e+02 2.29809998e+02 2.01100135e+02 ... 5.18228107e+02\n",
      "    1.78029952e+02 3.27019989e+02]\n",
      "   [2.30110001e+02 2.28330002e+02 2.02309069e+02 ... 5.13176381e+02\n",
      "    1.80579807e+02 3.29589996e+02]\n",
      "   [2.29350006e+02 2.27119995e+02 1.99781331e+02 ... 5.07715351e+02\n",
      "    1.75480111e+02 3.27850006e+02]]\n",
      "\n",
      "  [[1.93450453e+02 1.98899994e+02 1.68704693e+02 ... 4.49241509e+02\n",
      "    1.29983652e+02 3.37920013e+02]\n",
      "   [1.98075209e+02 2.03089996e+02 1.69802389e+02 ... 4.55730817e+02\n",
      "    1.34133105e+02 3.47350006e+02]\n",
      "   [2.00362600e+02 2.05919998e+02 1.72796079e+02 ... 4.60463056e+02\n",
      "    1.36012893e+02 3.64839996e+02]\n",
      "   ...\n",
      "   [2.34000000e+02 2.32580002e+02 2.03667846e+02 ... 5.21912054e+02\n",
      "    1.81869747e+02 3.37660004e+02]\n",
      "   [2.31699997e+02 2.30229996e+02 2.04017532e+02 ... 5.20733964e+02\n",
      "    1.80589816e+02 3.29619995e+02]\n",
      "   [2.31279999e+02 2.30089996e+02 2.02848579e+02 ... 5.14154777e+02\n",
      "    1.82419707e+02 3.35790009e+02]]\n",
      "\n",
      "  [[7.84329000e+07 3.33935000e+07 3.52114000e+07 ... 1.68835000e+07\n",
      "    1.98821300e+08 8.46548000e+07]\n",
      "   [5.62885000e+07 3.48920000e+07 3.79957000e+07 ... 2.09743000e+07\n",
      "    1.92953600e+08 1.20146400e+08]\n",
      "   [4.53397000e+07 2.85498000e+07 3.47840000e+07 ... 1.70863000e+07\n",
      "    3.04021100e+08 9.14043000e+07]\n",
      "   ...\n",
      "   [5.60387000e+07 3.96492000e+07 3.49314000e+07 ... 2.52133000e+07\n",
      "    1.56602200e+08 7.43198000e+07]\n",
      "   [3.74762000e+07 2.52489000e+07 1.85266000e+07 ... 2.37606000e+07\n",
      "    1.32008000e+08 5.69566000e+07]\n",
      "   [3.94026000e+07 2.98910000e+07 2.42402000e+07 ... 2.14810000e+07\n",
      "    1.85229200e+08 7.59560000e+07]]]]\n"
     ]
    }
   ],
   "source": [
    "# 探查数据\n",
    "# print a batch to verify\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 3957\n",
      "Test samples: 990\n",
      "Train range: 0:3956\n",
      "Test range: 3957:4946\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "split_ratio = 0.8\n",
    "split_ix = int(n_samples * split_ratio)\n",
    "indices_train = list(range(split_ix))\n",
    "indices_test = list(range(split_ix, n_samples))\n",
    "\n",
    "print(f'Train samples: {len(indices_train)}')\n",
    "print(f'Test samples: {len(indices_test)}')\n",
    "print(f'Train range: {indices_train[0]}:{indices_train[-1]}')\n",
    "print(f'Test range: {indices_test[0]}:{indices_test[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means shape: (1, 5, 1, 1)\n",
      "Stds shape: (1, 5, 1, 1)\n",
      "Dataset and dataloaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Apply log transform to handle large value ranges\n",
    "X_log = np.where(X > 0, np.log1p(X), -np.log1p(-X))\n",
    "y_log = np.where(y > 0, np.log1p(y), -np.log1p(-y))\n",
    "\n",
    "# Scale log-transformed features\n",
    "means, stds = prepare_standard_scaler(X_log, indices=indices_train)\n",
    "print(f'Means shape: {means.shape}')\n",
    "print(f'Stds shape: {stds.shape}')\n",
    "\n",
    "# Create dataset with log-scaled data\n",
    "dataset = InRAMDataset(X_log, y_log, transform=Scale(means, stds))\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "dataloader_train = RigidDataLoader(dataset,\n",
    "                                   indices=indices_train,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "dataloader_test = RigidDataLoader(dataset,\n",
    "                                  indices=indices_test,\n",
    "                                  batch_size=batch_size)\n",
    "\n",
    "print(\"Dataset and dataloaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([32, 1, 5, 60, 7])\n",
      "y_batch shape: torch.Size([32, 5, 20, 7])\n",
      "tensor([[[[[-0.6898, -0.6796, -0.5755,  ..., -0.3949, -0.7150, -0.6902],\n",
      "           [-0.6900, -0.6798, -0.5757,  ..., -0.3940, -0.7149, -0.6902],\n",
      "           [-0.6913, -0.6796, -0.5793,  ..., -0.3897, -0.7149, -0.6902],\n",
      "           ...,\n",
      "           [-0.6796, -0.6740, -0.5259,  ..., -0.3726, -0.7145, -0.6902],\n",
      "           [-0.6802, -0.6742, -0.5224,  ..., -0.3729, -0.7144, -0.6902],\n",
      "           [-0.6801, -0.6750, -0.5249,  ..., -0.3738, -0.7145, -0.6902]],\n",
      "\n",
      "          [[-0.6961, -0.6864, -0.5805,  ..., -0.4023, -0.7213, -0.6956],\n",
      "           [-0.6963, -0.6861, -0.5817,  ..., -0.4028, -0.7213, -0.6956],\n",
      "           [-0.6969, -0.6861, -0.5832,  ..., -0.3974, -0.7213, -0.6956],\n",
      "           ...,\n",
      "           [-0.6861, -0.6804, -0.5342,  ..., -0.3807, -0.7208, -0.6956],\n",
      "           [-0.6864, -0.6804, -0.5300,  ..., -0.3811, -0.7208, -0.6956],\n",
      "           [-0.6862, -0.6804, -0.5238,  ..., -0.3838, -0.7208, -0.6956]],\n",
      "\n",
      "          [[-0.6900, -0.6803, -0.5747,  ..., -0.3917, -0.7153, -0.6981],\n",
      "           [-0.6899, -0.6799, -0.5744,  ..., -0.3906, -0.7152, -0.6981],\n",
      "           [-0.6915, -0.6797, -0.5780,  ..., -0.3895, -0.7152, -0.6981],\n",
      "           ...,\n",
      "           [-0.6799, -0.6741, -0.5265,  ..., -0.3699, -0.7148, -0.6981],\n",
      "           [-0.6801, -0.6739, -0.5236,  ..., -0.3699, -0.7147, -0.6981],\n",
      "           [-0.6801, -0.6748, -0.5248,  ..., -0.3720, -0.7148, -0.6981]],\n",
      "\n",
      "          [[-0.6935, -0.6843, -0.5769,  ..., -0.3970, -0.7188, -0.7001],\n",
      "           [-0.6936, -0.6836, -0.5790,  ..., -0.3974, -0.7188, -0.7001],\n",
      "           [-0.6941, -0.6836, -0.5794,  ..., -0.3971, -0.7188, -0.7001],\n",
      "           ...,\n",
      "           [-0.6832, -0.6778, -0.5313,  ..., -0.3744, -0.7183, -0.7001],\n",
      "           [-0.6835, -0.6779, -0.5284,  ..., -0.3770, -0.7183, -0.7001],\n",
      "           [-0.6841, -0.6783, -0.5253,  ..., -0.3777, -0.7183, -0.7001]],\n",
      "\n",
      "          [[ 1.0539, -0.4330,  0.5362,  ..., -0.6251,  0.5752,  0.1463],\n",
      "           [ 0.3524, -0.5318,  0.1228,  ..., -0.6505,  0.5663,  0.1463],\n",
      "           [ 3.0363, -0.5957,  0.2767,  ..., -0.5744,  0.3930,  0.1463],\n",
      "           ...,\n",
      "           [ 1.1039, -0.4190,  0.0096,  ..., -0.5470,  0.3217,  0.1463],\n",
      "           [ 1.4805, -0.4323,  1.4168,  ..., -0.5144,  2.8311,  0.1463],\n",
      "           [ 0.9947, -0.2486,  2.1839,  ..., -0.5824,  0.1832,  0.1463]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.6900, -0.6798, -0.5757,  ..., -0.3940, -0.7149, -0.6902],\n",
      "           [-0.6913, -0.6796, -0.5793,  ..., -0.3897, -0.7149, -0.6902],\n",
      "           [-0.6906, -0.6783, -0.5776,  ..., -0.3863, -0.7148, -0.6902],\n",
      "           ...,\n",
      "           [-0.6802, -0.6742, -0.5224,  ..., -0.3729, -0.7144, -0.6902],\n",
      "           [-0.6801, -0.6750, -0.5249,  ..., -0.3738, -0.7145, -0.6902],\n",
      "           [-0.6797, -0.6752, -0.5226,  ..., -0.3734, -0.7145, -0.6902]],\n",
      "\n",
      "          [[-0.6963, -0.6861, -0.5817,  ..., -0.4028, -0.7213, -0.6956],\n",
      "           [-0.6969, -0.6861, -0.5832,  ..., -0.3974, -0.7213, -0.6956],\n",
      "           [-0.6972, -0.6851, -0.5852,  ..., -0.3958, -0.7212, -0.6956],\n",
      "           ...,\n",
      "           [-0.6864, -0.6804, -0.5300,  ..., -0.3811, -0.7208, -0.6956],\n",
      "           [-0.6862, -0.6804, -0.5238,  ..., -0.3838, -0.7208, -0.6956],\n",
      "           [-0.6863, -0.6816, -0.5301,  ..., -0.3836, -0.7208, -0.6956]],\n",
      "\n",
      "          [[-0.6899, -0.6799, -0.5744,  ..., -0.3906, -0.7152, -0.6981],\n",
      "           [-0.6915, -0.6797, -0.5780,  ..., -0.3895, -0.7152, -0.6981],\n",
      "           [-0.6914, -0.6796, -0.5777,  ..., -0.3880, -0.7152, -0.6981],\n",
      "           ...,\n",
      "           [-0.6801, -0.6739, -0.5236,  ..., -0.3699, -0.7147, -0.6981],\n",
      "           [-0.6801, -0.6748, -0.5248,  ..., -0.3720, -0.7148, -0.6981],\n",
      "           [-0.6800, -0.6754, -0.5227,  ..., -0.3717, -0.7148, -0.6981]],\n",
      "\n",
      "          [[-0.6936, -0.6836, -0.5790,  ..., -0.3974, -0.7188, -0.7001],\n",
      "           [-0.6941, -0.6836, -0.5794,  ..., -0.3971, -0.7188, -0.7001],\n",
      "           [-0.6951, -0.6835, -0.5828,  ..., -0.3943, -0.7188, -0.7001],\n",
      "           ...,\n",
      "           [-0.6835, -0.6779, -0.5284,  ..., -0.3770, -0.7183, -0.7001],\n",
      "           [-0.6841, -0.6783, -0.5253,  ..., -0.3777, -0.7183, -0.7001],\n",
      "           [-0.6838, -0.6788, -0.5272,  ..., -0.3785, -0.7184, -0.7001]],\n",
      "\n",
      "          [[ 0.3524, -0.5318,  0.1228,  ..., -0.6505,  0.5663,  0.1463],\n",
      "           [ 3.0363, -0.5957,  0.2767,  ..., -0.5744,  0.3930,  0.1463],\n",
      "           [ 1.3630, -0.3798, -0.0495,  ..., -0.5888,  0.9402,  0.1463],\n",
      "           ...,\n",
      "           [ 1.4805, -0.4323,  1.4168,  ..., -0.5144,  2.8311,  0.1463],\n",
      "           [ 0.9947, -0.2486,  2.1839,  ..., -0.5824,  0.1832,  0.1463],\n",
      "           [ 0.8229, -0.4385,  0.5622,  ..., -0.6020,  0.2245,  0.1463]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.6913, -0.6796, -0.5793,  ..., -0.3897, -0.7149, -0.6902],\n",
      "           [-0.6906, -0.6783, -0.5776,  ..., -0.3863, -0.7148, -0.6902],\n",
      "           [-0.6899, -0.6778, -0.5745,  ..., -0.3890, -0.7148, -0.6902],\n",
      "           ...,\n",
      "           [-0.6801, -0.6750, -0.5249,  ..., -0.3738, -0.7145, -0.6902],\n",
      "           [-0.6797, -0.6752, -0.5226,  ..., -0.3734, -0.7145, -0.6902],\n",
      "           [-0.6789, -0.6744, -0.5241,  ..., -0.3751, -0.7145, -0.6902]],\n",
      "\n",
      "          [[-0.6969, -0.6861, -0.5832,  ..., -0.3974, -0.7213, -0.6956],\n",
      "           [-0.6972, -0.6851, -0.5852,  ..., -0.3958, -0.7212, -0.6956],\n",
      "           [-0.6966, -0.6842, -0.5821,  ..., -0.3964, -0.7211, -0.6956],\n",
      "           ...,\n",
      "           [-0.6862, -0.6804, -0.5238,  ..., -0.3838, -0.7208, -0.6956],\n",
      "           [-0.6863, -0.6816, -0.5301,  ..., -0.3836, -0.7208, -0.6956],\n",
      "           [-0.6857, -0.6812, -0.5280,  ..., -0.3832, -0.7208, -0.6956]],\n",
      "\n",
      "          [[-0.6915, -0.6797, -0.5780,  ..., -0.3895, -0.7152, -0.6981],\n",
      "           [-0.6914, -0.6796, -0.5777,  ..., -0.3880, -0.7152, -0.6981],\n",
      "           [-0.6908, -0.6782, -0.5749,  ..., -0.3865, -0.7151, -0.6981],\n",
      "           ...,\n",
      "           [-0.6801, -0.6748, -0.5248,  ..., -0.3720, -0.7148, -0.6981],\n",
      "           [-0.6800, -0.6754, -0.5227,  ..., -0.3717, -0.7148, -0.6981],\n",
      "           [-0.6792, -0.6753, -0.5245,  ..., -0.3712, -0.7148, -0.6981]],\n",
      "\n",
      "          [[-0.6941, -0.6836, -0.5794,  ..., -0.3971, -0.7188, -0.7001],\n",
      "           [-0.6951, -0.6835, -0.5828,  ..., -0.3943, -0.7188, -0.7001],\n",
      "           [-0.6945, -0.6823, -0.5794,  ..., -0.3904, -0.7187, -0.7001],\n",
      "           ...,\n",
      "           [-0.6841, -0.6783, -0.5253,  ..., -0.3777, -0.7183, -0.7001],\n",
      "           [-0.6838, -0.6788, -0.5272,  ..., -0.3785, -0.7184, -0.7001],\n",
      "           [-0.6833, -0.6789, -0.5246,  ..., -0.3771, -0.7183, -0.7001]],\n",
      "\n",
      "          [[ 3.0363, -0.5957,  0.2767,  ..., -0.5744,  0.3930,  0.1463],\n",
      "           [ 1.3630, -0.3798, -0.0495,  ..., -0.5888,  0.9402,  0.1463],\n",
      "           [ 1.0027, -0.4029,  0.4345,  ..., -0.6202,  0.7535,  0.1463],\n",
      "           ...,\n",
      "           [ 0.9947, -0.2486,  2.1839,  ..., -0.5824,  0.1832,  0.1463],\n",
      "           [ 0.8229, -0.4385,  0.5622,  ..., -0.6020,  0.2245,  0.1463],\n",
      "           [ 0.8114, -0.3161,  0.7178,  ..., -0.5580,  0.1733,  0.1463]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.6857, -0.6817, -0.5406,  ..., -0.3770, -0.7148, -0.6902],\n",
      "           [-0.6862, -0.6814, -0.5385,  ..., -0.3725, -0.7148, -0.6902],\n",
      "           [-0.6864, -0.6809, -0.5408,  ..., -0.3720, -0.7149, -0.6902],\n",
      "           ...,\n",
      "           [-0.6781, -0.6781, -0.5239,  ..., -0.3587, -0.7132, -0.6902],\n",
      "           [-0.6778, -0.6783, -0.5212,  ..., -0.3568, -0.7133, -0.6902],\n",
      "           [-0.6778, -0.6790, -0.5354,  ..., -0.3582, -0.7133, -0.6902]],\n",
      "\n",
      "          [[-0.6924, -0.6878, -0.5484,  ..., -0.3868, -0.7211, -0.6956],\n",
      "           [-0.6922, -0.6881, -0.5459,  ..., -0.3821, -0.7212, -0.6956],\n",
      "           [-0.6929, -0.6876, -0.5467,  ..., -0.3808, -0.7212, -0.6956],\n",
      "           ...,\n",
      "           [-0.6840, -0.6840, -0.5296,  ..., -0.3671, -0.7195, -0.6956],\n",
      "           [-0.6842, -0.6847, -0.5268,  ..., -0.3645, -0.7196, -0.6956],\n",
      "           [-0.6841, -0.6852, -0.5438,  ..., -0.3685, -0.7196, -0.6956]],\n",
      "\n",
      "          [[-0.6865, -0.6817, -0.5409,  ..., -0.3756, -0.7151, -0.6981],\n",
      "           [-0.6862, -0.6820, -0.5378,  ..., -0.3723, -0.7151, -0.6981],\n",
      "           [-0.6868, -0.6816, -0.5394,  ..., -0.3714, -0.7152, -0.6981],\n",
      "           ...,\n",
      "           [-0.6802, -0.6781, -0.5225,  ..., -0.3572, -0.7134, -0.6981],\n",
      "           [-0.6785, -0.6786, -0.5230,  ..., -0.3561, -0.7136, -0.6981],\n",
      "           [-0.6780, -0.6793, -0.5399,  ..., -0.3575, -0.7136, -0.6981]],\n",
      "\n",
      "          [[-0.6900, -0.6852, -0.5446,  ..., -0.3825, -0.7186, -0.7001],\n",
      "           [-0.6898, -0.6856, -0.5423,  ..., -0.3800, -0.7186, -0.7001],\n",
      "           [-0.6903, -0.6853, -0.5427,  ..., -0.3772, -0.7187, -0.7001],\n",
      "           ...,\n",
      "           [-0.6841, -0.6816, -0.5266,  ..., -0.3648, -0.7169, -0.7001],\n",
      "           [-0.6817, -0.6822, -0.5260,  ..., -0.3637, -0.7171, -0.7001],\n",
      "           [-0.6820, -0.6830, -0.5451,  ..., -0.3630, -0.7173, -0.7001]],\n",
      "\n",
      "          [[ 2.1888, -0.5132,  0.3899,  ..., -0.6208,  1.1351,  0.1463],\n",
      "           [ 1.3698, -0.5857,  0.4948,  ..., -0.5536,  0.4521,  0.1463],\n",
      "           [ 0.8046, -0.4786,  0.2630,  ..., -0.6118,  1.0279,  0.1463],\n",
      "           ...,\n",
      "           [ 3.9706, -0.5368,  0.3576,  ..., -0.4615,  0.2637,  0.1463],\n",
      "           [ 2.3104, -0.5398,  2.2016,  ..., -0.4928,  0.4988,  0.1463],\n",
      "           [ 0.9670, -0.3039,  2.8934,  ..., -0.5832,  0.7261,  0.1463]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.6862, -0.6814, -0.5385,  ..., -0.3725, -0.7148, -0.6902],\n",
      "           [-0.6864, -0.6809, -0.5408,  ..., -0.3720, -0.7149, -0.6902],\n",
      "           [-0.6863, -0.6814, -0.5458,  ..., -0.3731, -0.7147, -0.6902],\n",
      "           ...,\n",
      "           [-0.6778, -0.6783, -0.5212,  ..., -0.3568, -0.7133, -0.6902],\n",
      "           [-0.6778, -0.6790, -0.5354,  ..., -0.3582, -0.7133, -0.6902],\n",
      "           [-0.6797, -0.6802, -0.5380,  ..., -0.3628, -0.7135, -0.6902]],\n",
      "\n",
      "          [[-0.6922, -0.6881, -0.5459,  ..., -0.3821, -0.7212, -0.6956],\n",
      "           [-0.6929, -0.6876, -0.5467,  ..., -0.3808, -0.7212, -0.6956],\n",
      "           [-0.6924, -0.6877, -0.5500,  ..., -0.3812, -0.7211, -0.6956],\n",
      "           ...,\n",
      "           [-0.6842, -0.6847, -0.5268,  ..., -0.3645, -0.7196, -0.6956],\n",
      "           [-0.6841, -0.6852, -0.5438,  ..., -0.3685, -0.7196, -0.6956],\n",
      "           [-0.6847, -0.6858, -0.5418,  ..., -0.3695, -0.7196, -0.6956]],\n",
      "\n",
      "          [[-0.6862, -0.6820, -0.5378,  ..., -0.3723, -0.7151, -0.6981],\n",
      "           [-0.6868, -0.6816, -0.5394,  ..., -0.3714, -0.7152, -0.6981],\n",
      "           [-0.6863, -0.6813, -0.5443,  ..., -0.3692, -0.7152, -0.6981],\n",
      "           ...,\n",
      "           [-0.6785, -0.6786, -0.5230,  ..., -0.3561, -0.7136, -0.6981],\n",
      "           [-0.6780, -0.6793, -0.5399,  ..., -0.3575, -0.7136, -0.6981],\n",
      "           [-0.6795, -0.6827, -0.5360,  ..., -0.3602, -0.7137, -0.6981]],\n",
      "\n",
      "          [[-0.6898, -0.6856, -0.5423,  ..., -0.3800, -0.7186, -0.7001],\n",
      "           [-0.6903, -0.6853, -0.5427,  ..., -0.3772, -0.7187, -0.7001],\n",
      "           [-0.6902, -0.6849, -0.5461,  ..., -0.3767, -0.7188, -0.7001],\n",
      "           ...,\n",
      "           [-0.6817, -0.6822, -0.5260,  ..., -0.3637, -0.7171, -0.7001],\n",
      "           [-0.6820, -0.6830, -0.5451,  ..., -0.3630, -0.7173, -0.7001],\n",
      "           [-0.6819, -0.6830, -0.5383,  ..., -0.3629, -0.7171, -0.7001]],\n",
      "\n",
      "          [[ 1.3698, -0.5857,  0.4948,  ..., -0.5536,  0.4521,  0.1463],\n",
      "           [ 0.8046, -0.4786,  0.2630,  ..., -0.6118,  1.0279,  0.1463],\n",
      "           [ 1.0757, -0.5798,  0.6145,  ..., -0.6136,  1.9863,  0.1463],\n",
      "           ...,\n",
      "           [ 2.3104, -0.5398,  2.2016,  ..., -0.4928,  0.4988,  0.1463],\n",
      "           [ 0.9670, -0.3039,  2.8934,  ..., -0.5832,  0.7261,  0.1463],\n",
      "           [ 1.6043,  0.8060,  0.7980,  ..., -0.6290,  0.8045,  0.1463]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.6864, -0.6809, -0.5408,  ..., -0.3720, -0.7149, -0.6902],\n",
      "           [-0.6863, -0.6814, -0.5458,  ..., -0.3731, -0.7147, -0.6902],\n",
      "           [-0.6857, -0.6807, -0.5403,  ..., -0.3715, -0.7149, -0.6902],\n",
      "           ...,\n",
      "           [-0.6778, -0.6790, -0.5354,  ..., -0.3582, -0.7133, -0.6902],\n",
      "           [-0.6797, -0.6802, -0.5380,  ..., -0.3628, -0.7135, -0.6902],\n",
      "           [-0.6798, -0.6843, -0.5447,  ..., -0.3647, -0.7134, -0.6902]],\n",
      "\n",
      "          [[-0.6929, -0.6876, -0.5467,  ..., -0.3808, -0.7212, -0.6956],\n",
      "           [-0.6924, -0.6877, -0.5500,  ..., -0.3812, -0.7211, -0.6956],\n",
      "           [-0.6924, -0.6872, -0.5486,  ..., -0.3812, -0.7208, -0.6956],\n",
      "           ...,\n",
      "           [-0.6841, -0.6852, -0.5438,  ..., -0.3685, -0.7196, -0.6956],\n",
      "           [-0.6847, -0.6858, -0.5418,  ..., -0.3695, -0.7196, -0.6956],\n",
      "           [-0.6861, -0.6908, -0.5475,  ..., -0.3732, -0.7197, -0.6956]],\n",
      "\n",
      "          [[-0.6868, -0.6816, -0.5394,  ..., -0.3714, -0.7152, -0.6981],\n",
      "           [-0.6863, -0.6813, -0.5443,  ..., -0.3692, -0.7152, -0.6981],\n",
      "           [-0.6868, -0.6817, -0.5446,  ..., -0.3731, -0.7152, -0.6981],\n",
      "           ...,\n",
      "           [-0.6780, -0.6793, -0.5399,  ..., -0.3575, -0.7136, -0.6981],\n",
      "           [-0.6795, -0.6827, -0.5360,  ..., -0.3602, -0.7137, -0.6981],\n",
      "           [-0.6801, -0.6850, -0.5469,  ..., -0.3630, -0.7138, -0.6981]],\n",
      "\n",
      "          [[-0.6903, -0.6853, -0.5427,  ..., -0.3772, -0.7187, -0.7001],\n",
      "           [-0.6902, -0.6849, -0.5461,  ..., -0.3767, -0.7188, -0.7001],\n",
      "           [-0.6899, -0.6852, -0.5499,  ..., -0.3772, -0.7184, -0.7001],\n",
      "           ...,\n",
      "           [-0.6820, -0.6830, -0.5451,  ..., -0.3630, -0.7173, -0.7001],\n",
      "           [-0.6819, -0.6830, -0.5383,  ..., -0.3629, -0.7171, -0.7001],\n",
      "           [-0.6835, -0.6887, -0.5430,  ..., -0.3692, -0.7174, -0.7001]],\n",
      "\n",
      "          [[ 0.8046, -0.4786,  0.2630,  ..., -0.6118,  1.0279,  0.1463],\n",
      "           [ 1.0757, -0.5798,  0.6145,  ..., -0.6136,  1.9863,  0.1463],\n",
      "           [ 1.4606, -0.4351,  0.4314,  ..., -0.5666,  7.7549,  0.1463],\n",
      "           ...,\n",
      "           [ 0.9670, -0.3039,  2.8934,  ..., -0.5832,  0.7261,  0.1463],\n",
      "           [ 1.6043,  0.8060,  0.7980,  ..., -0.6290,  0.8045,  0.1463],\n",
      "           [ 1.5523,  1.4787,  1.6838,  ..., -0.5607,  0.9090,  0.1463]]]]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# print a batch to verify\n",
    "for X_batch, y_batch in dataloader_train:\n",
    "    print(f'X_batch shape: {X_batch.shape}')  # (batch_size, n_channels, lookback, n_assets)\n",
    "    print(f'y_batch shape: {y_batch.shape}')  # (batch_size, n_channels, horizon, n_assets)\n",
    "    print(X_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models created successfully!\n",
      "GreatNet: GreatNet(\n",
      "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "  (dense_layer): Linear(in_features=2100, out_features=7, bias=True)\n",
      "  (allocate_layer): SoftmaxAllocator()\n",
      ")\n",
      "LSTMNet: LSTMNet(\n",
      "  (lstm): LSTM(35, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "  (dense_layer): Linear(in_features=64, out_features=7, bias=True)\n",
      "  (allocate_layer): SoftmaxAllocator()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create network models\n",
    "great_net = GreatNet(n_assets, lookback, n_channels=n_channels)\n",
    "lstm_net = LSTMNet(n_assets, lookback, n_channels=n_channels, hidden_size=64, num_layers=2)\n",
    "\n",
    "# Create benchmark models\n",
    "benchmarks = {\n",
    "    '1/N': OneOverN(),\n",
    "    'Random': Random(),\n",
    "    'Inverse Volatility': InverseVolatility(),\n",
    "    'Maximum Return': MaximumReturn()\n",
    "}\n",
    "\n",
    "print(\"Models created successfully!\")\n",
    "print(f\"GreatNet: {great_net}\")\n",
    "print(f\"LSTMNet: {lstm_net}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function defined with balanced weights!\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "# 使用更细粒度的权重平衡，让风险控制和收益目标更平衡\n",
    "loss = (\n",
    "    0.2 * MaximumDrawdownLoss() +     # 最大回撤损失（风险控制）\n",
    "    0.3 * MeanReturnsLoss() +         # 平均收益率损失（收益目标）\n",
    "    0.3 * SharpeRatioLoss() +         # 夏普比率损失（风险调整收益）\n",
    "    0.2 * VolatilityLoss()            # 波动率损失（风险控制）\n",
    ")\n",
    "\n",
    "print(\"Loss function defined with balanced weights!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Models\n",
    "\n",
    "We'll train both the GreatNet and LSTMNet models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GreatNet...\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.032187, 0.443028]\n",
      "Batch x range: [-0.721540, 8.418708]\n",
      "Batch y range: [0.273690, 2356955904.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([-21.1577,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018507, 0.631829]\n",
      "Batch x range: [-0.721143, 7.754902]\n",
      "Batch y range: [0.327557, 2663768832.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([     nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "        -29.6565,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.013144, 0.512087]\n",
      "Batch x range: [-0.721164, 8.303257]\n",
      "Batch y range: [0.330079, 2663768832.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025628, 0.509921]\n",
      "Batch x range: [-0.721164, 8.303257]\n",
      "Batch y range: [0.262382, 1972146432.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.024186, 0.361984]\n",
      "Batch x range: [-0.729548, 8.303257]\n",
      "Batch y range: [0.262382, 1972146432.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([     nan,      nan,      nan,      nan, -30.3532,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023134, 0.614771]\n",
      "Batch x range: [-0.729548, 5.935117]\n",
      "Batch y range: [0.341081, 1684687232.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.032175, 0.433048]\n",
      "Batch x range: [-0.729548, 5.935117]\n",
      "Batch y range: [0.422837, 1512977152.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023934, 0.449768]\n",
      "Batch x range: [-0.747541, 4.950846]\n",
      "Batch y range: [0.472196, 3349298432.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.012530, 0.598364]\n",
      "Batch x range: [-0.747541, 10.650536]\n",
      "Batch y range: [0.428491, 3349298432.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([     nan,      nan,      nan,      nan,      nan,      nan, -24.9220,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.020118, 0.659122]\n",
      "Batch x range: [-0.747541, 10.650536]\n",
      "Batch y range: [0.428491, 2086584064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.033716, 0.425855]\n",
      "Batch x range: [-0.717948, 10.650536]\n",
      "Batch y range: [0.433534, 2086584064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.010865, 0.570510]\n",
      "Batch x range: [-0.717948, 6.326955]\n",
      "Batch y range: [0.504287, 2186629120.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018289, 0.526243]\n",
      "Batch x range: [-0.717475, 6.669514]\n",
      "Batch y range: [0.618898, 2328222464.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023029, 0.654370]\n",
      "Batch x range: [-0.716516, 7.154334]\n",
      "Batch y range: [0.677731, 2328222464.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.012840, 0.471187]\n",
      "Batch x range: [-0.713955, 7.154334]\n",
      "Batch y range: [0.667263, 1890377984.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.030204, 0.470021]\n",
      "Batch x range: [-0.716156, 7.154334]\n",
      "Batch y range: [0.511851, 3372969472.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.012223, 0.510468]\n",
      "Batch x range: [-0.716447, 10.731586]\n",
      "Batch y range: [0.396782, 3372969472.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.032187, 0.443028]\n",
      "Batch x range: [-0.721540, 8.418708]\n",
      "Batch y range: [0.273690, 2356955904.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([-21.1577,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018507, 0.631829]\n",
      "Batch x range: [-0.721143, 7.754902]\n",
      "Batch y range: [0.327557, 2663768832.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([     nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "        -29.6565,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.013144, 0.512087]\n",
      "Batch x range: [-0.721164, 8.303257]\n",
      "Batch y range: [0.330079, 2663768832.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025628, 0.509921]\n",
      "Batch x range: [-0.721164, 8.303257]\n",
      "Batch y range: [0.262382, 1972146432.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.024186, 0.361984]\n",
      "Batch x range: [-0.729548, 8.303257]\n",
      "Batch y range: [0.262382, 1972146432.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([     nan,      nan,      nan,      nan, -30.3532,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023134, 0.614771]\n",
      "Batch x range: [-0.729548, 5.935117]\n",
      "Batch y range: [0.341081, 1684687232.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.032175, 0.433048]\n",
      "Batch x range: [-0.729548, 5.935117]\n",
      "Batch y range: [0.422837, 1512977152.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023934, 0.449768]\n",
      "Batch x range: [-0.747541, 4.950846]\n",
      "Batch y range: [0.472196, 3349298432.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.012530, 0.598364]\n",
      "Batch x range: [-0.747541, 10.650536]\n",
      "Batch y range: [0.428491, 3349298432.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([     nan,      nan,      nan,      nan,      nan,      nan, -24.9220,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.020118, 0.659122]\n",
      "Batch x range: [-0.747541, 10.650536]\n",
      "Batch y range: [0.428491, 2086584064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.033716, 0.425855]\n",
      "Batch x range: [-0.717948, 10.650536]\n",
      "Batch y range: [0.433534, 2086584064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.010865, 0.570510]\n",
      "Batch x range: [-0.717948, 6.326955]\n",
      "Batch y range: [0.504287, 2186629120.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018289, 0.526243]\n",
      "Batch x range: [-0.717475, 6.669514]\n",
      "Batch y range: [0.618898, 2328222464.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023029, 0.654370]\n",
      "Batch x range: [-0.716516, 7.154334]\n",
      "Batch y range: [0.677731, 2328222464.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.012840, 0.471187]\n",
      "Batch x range: [-0.713955, 7.154334]\n",
      "Batch y range: [0.667263, 1890377984.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.030204, 0.470021]\n",
      "Batch x range: [-0.716156, 7.154334]\n",
      "Batch y range: [0.511851, 3372969472.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.012223, 0.510468]\n",
      "Batch x range: [-0.716447, 10.731586]\n",
      "Batch y range: [0.396782, 3372969472.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014410, 0.513874]\n",
      "Batch x range: [-0.718218, 10.731586]\n",
      "Batch y range: [0.396782, 1785383552.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.017398, 0.427835]\n",
      "Batch x range: [-0.718340, 10.731586]\n",
      "Batch y range: [0.403659, 2030352000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.016017, 0.402480]\n",
      "Batch x range: [-0.720609, 9.411794]\n",
      "Batch y range: [0.241828, 2987520000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.015737, 0.552768]\n",
      "Batch x range: [-0.721386, 9.411794]\n",
      "Batch y range: [0.201715, 2095260032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.022652, 0.464260]\n",
      "Batch x range: [-0.722339, 9.411794]\n",
      "Batch y range: [0.136845, 2622057216.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "            nan, -6.2742,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Weights range: [0.008498, 0.677359]\n",
      "Batch x range: [-0.723057, 8.160435]\n",
      "Batch y range: [0.131802, 2248808704.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([     nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan, -14.5477,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.006315, 0.612951]\n",
      "Batch x range: [-0.759786, 8.160435]\n",
      "Batch y range: [0.146702, 1831634048.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025071, 0.434942]\n",
      "Batch x range: [-0.759786, 6.882419]\n",
      "Batch y range: [0.162289, 1983399936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018578, 0.393092]\n",
      "Batch x range: [-0.759786, 5.973650]\n",
      "Batch y range: [0.171228, 2930564096.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.027518, 0.429359]\n",
      "Batch x range: [-0.722761, 9.216774]\n",
      "Batch y range: [0.190941, 2930564096.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.017148, 0.556201]\n",
      "Batch x range: [-0.722314, 9.216774]\n",
      "Batch y range: [0.222574, 1401872000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.039515, 0.374569]\n",
      "Batch x range: [-0.722305, 9.216774]\n",
      "Batch y range: [0.256957, 1401872000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.026345, 0.431974]\n",
      "Batch x range: [-0.721687, 3.982476]\n",
      "Batch y range: [0.264980, 1641112064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023076, 0.433125]\n",
      "Batch x range: [-0.720897, 4.801643]\n",
      "Batch y range: [0.264980, 2732184064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.024031, 0.430097]\n",
      "Batch x range: [-0.779633, 8.537514]\n",
      "Batch y range: [0.299363, 2732184064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025372, 0.378694]\n",
      "Batch x range: [-0.779633, 8.537514]\n",
      "Batch y range: [0.347270, 1867110016.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.033628, 0.398067]\n",
      "Batch x range: [-0.779633, 8.537514]\n",
      "Batch y range: [0.288360, 2493068032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.038708, 0.402103]\n",
      "Batch x range: [-0.720617, 7.718771]\n",
      "Batch y range: [0.227617, 2493068032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014410, 0.513874]\n",
      "Batch x range: [-0.718218, 10.731586]\n",
      "Batch y range: [0.396782, 1785383552.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.017398, 0.427835]\n",
      "Batch x range: [-0.718340, 10.731586]\n",
      "Batch y range: [0.403659, 2030352000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.016017, 0.402480]\n",
      "Batch x range: [-0.720609, 9.411794]\n",
      "Batch y range: [0.241828, 2987520000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.015737, 0.552768]\n",
      "Batch x range: [-0.721386, 9.411794]\n",
      "Batch y range: [0.201715, 2095260032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.022652, 0.464260]\n",
      "Batch x range: [-0.722339, 9.411794]\n",
      "Batch y range: [0.136845, 2622057216.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "            nan, -6.2742,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "            nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Weights range: [0.008498, 0.677359]\n",
      "Batch x range: [-0.723057, 8.160435]\n",
      "Batch y range: [0.131802, 2248808704.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([     nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan,      nan,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan, -14.5477,      nan,      nan,\n",
      "             nan,      nan,      nan,      nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.006315, 0.612951]\n",
      "Batch x range: [-0.759786, 8.160435]\n",
      "Batch y range: [0.146702, 1831634048.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025071, 0.434942]\n",
      "Batch x range: [-0.759786, 6.882419]\n",
      "Batch y range: [0.162289, 1983399936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018578, 0.393092]\n",
      "Batch x range: [-0.759786, 5.973650]\n",
      "Batch y range: [0.171228, 2930564096.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.027518, 0.429359]\n",
      "Batch x range: [-0.722761, 9.216774]\n",
      "Batch y range: [0.190941, 2930564096.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.017148, 0.556201]\n",
      "Batch x range: [-0.722314, 9.216774]\n",
      "Batch y range: [0.222574, 1401872000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.039515, 0.374569]\n",
      "Batch x range: [-0.722305, 9.216774]\n",
      "Batch y range: [0.256957, 1401872000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.026345, 0.431974]\n",
      "Batch x range: [-0.721687, 3.982476]\n",
      "Batch y range: [0.264980, 1641112064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023076, 0.433125]\n",
      "Batch x range: [-0.720897, 4.801643]\n",
      "Batch y range: [0.264980, 2732184064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.024031, 0.430097]\n",
      "Batch x range: [-0.779633, 8.537514]\n",
      "Batch y range: [0.299363, 2732184064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025372, 0.378694]\n",
      "Batch x range: [-0.779633, 8.537514]\n",
      "Batch y range: [0.347270, 1867110016.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.033628, 0.398067]\n",
      "Batch x range: [-0.779633, 8.537514]\n",
      "Batch y range: [0.288360, 2493068032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.038708, 0.402103]\n",
      "Batch x range: [-0.720617, 7.718771]\n",
      "Batch y range: [0.227617, 2493068032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.021490, 0.364459]\n",
      "Batch x range: [-0.721586, 7.718771]\n",
      "Batch y range: [0.198276, 2664475904.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023198, 0.493816]\n",
      "Batch x range: [-0.807257, 8.305678]\n",
      "Batch y range: [0.198276, 2664475904.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.030734, 0.412290]\n",
      "Batch x range: [-0.810343, 8.305678]\n",
      "Batch y range: [0.225783, 2142560000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.033628, 0.504367]\n",
      "Batch x range: [-0.811499, 8.305678]\n",
      "Batch y range: [0.250310, 2142560000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.022082, 0.489845]\n",
      "Batch x range: [-0.811499, 11.143643]\n",
      "Batch y range: [0.323890, 3493312000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.012523, 0.370524]\n",
      "Batch x range: [-0.806070, 11.143643]\n",
      "Batch y range: [0.389905, 3470095872.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.015245, 0.649581]\n",
      "Batch x range: [-0.796507, 11.143643]\n",
      "Batch y range: [0.385780, 2025191936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025886, 0.485744]\n",
      "Batch x range: [-0.796440, 11.064151]\n",
      "Batch y range: [0.340623, 2025191936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.039574, 0.359591]\n",
      "Batch x range: [-0.796440, 6.116747]\n",
      "Batch y range: [0.267043, 3195783936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018978, 0.415520]\n",
      "Batch x range: [-0.798777, 10.124897]\n",
      "Batch y range: [0.262917, 3195783936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023104, 0.599114]\n",
      "Batch x range: [-0.798777, 10.124897]\n",
      "Batch y range: [0.262917, 1751559936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025537, 0.577847]\n",
      "Batch x range: [-0.805279, 10.124897]\n",
      "Batch y range: [0.300509, 1751559936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.039113, 0.427197]\n",
      "Batch x range: [-0.805279, 5.179821]\n",
      "Batch y range: [0.300509, 1888588032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.028640, 0.466605]\n",
      "Batch x range: [-0.805279, 5.649010]\n",
      "Batch y range: [0.322973, 1888588032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.035759, 0.344913]\n",
      "Batch x range: [-0.800133, 5.649010]\n",
      "Batch y range: [0.271169, 1435139968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.031737, 0.463290]\n",
      "Batch x range: [-0.798844, 5.649010]\n",
      "Batch y range: [0.266584, 1435139968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.036520, 0.428433]\n",
      "Batch x range: [-0.796327, 4.096387]\n",
      "Batch y range: [0.275295, 1278744064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.052960, 0.359628]\n",
      "Batch x range: [-0.792311, 4.096387]\n",
      "Batch y range: [0.289277, 1278744064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.021490, 0.364459]\n",
      "Batch x range: [-0.721586, 7.718771]\n",
      "Batch y range: [0.198276, 2664475904.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023198, 0.493816]\n",
      "Batch x range: [-0.807257, 8.305678]\n",
      "Batch y range: [0.198276, 2664475904.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.030734, 0.412290]\n",
      "Batch x range: [-0.810343, 8.305678]\n",
      "Batch y range: [0.225783, 2142560000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.033628, 0.504367]\n",
      "Batch x range: [-0.811499, 8.305678]\n",
      "Batch y range: [0.250310, 2142560000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.022082, 0.489845]\n",
      "Batch x range: [-0.811499, 11.143643]\n",
      "Batch y range: [0.323890, 3493312000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.012523, 0.370524]\n",
      "Batch x range: [-0.806070, 11.143643]\n",
      "Batch y range: [0.389905, 3470095872.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.015245, 0.649581]\n",
      "Batch x range: [-0.796507, 11.143643]\n",
      "Batch y range: [0.385780, 2025191936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025886, 0.485744]\n",
      "Batch x range: [-0.796440, 11.064151]\n",
      "Batch y range: [0.340623, 2025191936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.039574, 0.359591]\n",
      "Batch x range: [-0.796440, 6.116747]\n",
      "Batch y range: [0.267043, 3195783936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018978, 0.415520]\n",
      "Batch x range: [-0.798777, 10.124897]\n",
      "Batch y range: [0.262917, 3195783936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023104, 0.599114]\n",
      "Batch x range: [-0.798777, 10.124897]\n",
      "Batch y range: [0.262917, 1751559936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025537, 0.577847]\n",
      "Batch x range: [-0.805279, 10.124897]\n",
      "Batch y range: [0.300509, 1751559936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.039113, 0.427197]\n",
      "Batch x range: [-0.805279, 5.179821]\n",
      "Batch y range: [0.300509, 1888588032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.028640, 0.466605]\n",
      "Batch x range: [-0.805279, 5.649010]\n",
      "Batch y range: [0.322973, 1888588032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.035759, 0.344913]\n",
      "Batch x range: [-0.800133, 5.649010]\n",
      "Batch y range: [0.271169, 1435139968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.031737, 0.463290]\n",
      "Batch x range: [-0.798844, 5.649010]\n",
      "Batch y range: [0.266584, 1435139968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.036520, 0.428433]\n",
      "Batch x range: [-0.796327, 4.096387]\n",
      "Batch y range: [0.275295, 1278744064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.052960, 0.359628]\n",
      "Batch x range: [-0.792311, 4.096387]\n",
      "Batch y range: [0.289277, 1278744064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.053672, 0.281840]\n",
      "Batch x range: [-0.794442, 3.560881]\n",
      "Batch y range: [0.255582, 1266893568.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.035143, 0.373698]\n",
      "Batch x range: [-0.795485, 3.560881]\n",
      "Batch y range: [0.255582, 1266893568.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.035993, 0.308849]\n",
      "Batch x range: [-0.798284, 4.184427]\n",
      "Batch y range: [0.274764, 1460852352.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.042584, 0.375103]\n",
      "Batch x range: [-0.798284, 4.184427]\n",
      "Batch y range: [0.277994, 969219968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.043364, 0.333899]\n",
      "Batch x range: [-0.798284, 4.184427]\n",
      "Batch y range: [0.279467, 969651200.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.051623, 0.307298]\n",
      "Batch x range: [-0.794976, 3.152887]\n",
      "Batch y range: [0.316373, 1159587968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.062129, 0.322213]\n",
      "Batch x range: [-0.781960, 3.152887]\n",
      "Batch y range: [0.305849, 906224000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.062923, 0.279313]\n",
      "Batch x range: [-0.781960, 3.152887]\n",
      "Batch y range: [0.305849, 906224000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.055806, 0.316643]\n",
      "Batch x range: [-0.781960, 2.285359]\n",
      "Batch y range: [0.340452, 753176000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.055778, 0.280391]\n",
      "Batch x range: [-0.742492, 2.259584]\n",
      "Batch y range: [0.350300, 753176000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.065150, 0.292255]\n",
      "Batch x range: [-0.768817, 2.830806]\n",
      "Batch y range: [0.361155, 1065523200.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.048270, 0.306901]\n",
      "Batch x range: [-0.768817, 2.830806]\n",
      "Batch y range: [0.384257, 902835968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.064047, 0.330882]\n",
      "Batch x range: [-0.757653, 2.830806]\n",
      "Batch y range: [0.419382, 759911616.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.044035, 0.327352]\n",
      "Batch x range: [-0.766159, 1.784380]\n",
      "Batch y range: [0.414415, 567816000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.049002, 0.329994]\n",
      "Batch x range: [-0.766159, 2.244695]\n",
      "Batch y range: [0.412511, 894348032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.057868, 0.255185]\n",
      "Batch x range: [-0.766659, 2.244695]\n",
      "Batch y range: [0.400716, 759385216.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.052270, 0.291936]\n",
      "Batch x range: [-0.766659, 2.244695]\n",
      "Batch y range: [0.400716, 691376000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.056139, 0.279764]\n",
      "Batch x range: [-0.791270, 1.782578]\n",
      "Batch y range: [0.457843, 585908416.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.053672, 0.281840]\n",
      "Batch x range: [-0.794442, 3.560881]\n",
      "Batch y range: [0.255582, 1266893568.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.035143, 0.373698]\n",
      "Batch x range: [-0.795485, 3.560881]\n",
      "Batch y range: [0.255582, 1266893568.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.035993, 0.308849]\n",
      "Batch x range: [-0.798284, 4.184427]\n",
      "Batch y range: [0.274764, 1460852352.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.042584, 0.375103]\n",
      "Batch x range: [-0.798284, 4.184427]\n",
      "Batch y range: [0.277994, 969219968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.043364, 0.333899]\n",
      "Batch x range: [-0.798284, 4.184427]\n",
      "Batch y range: [0.279467, 969651200.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.051623, 0.307298]\n",
      "Batch x range: [-0.794976, 3.152887]\n",
      "Batch y range: [0.316373, 1159587968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.062129, 0.322213]\n",
      "Batch x range: [-0.781960, 3.152887]\n",
      "Batch y range: [0.305849, 906224000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.062923, 0.279313]\n",
      "Batch x range: [-0.781960, 3.152887]\n",
      "Batch y range: [0.305849, 906224000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.055806, 0.316643]\n",
      "Batch x range: [-0.781960, 2.285359]\n",
      "Batch y range: [0.340452, 753176000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.055778, 0.280391]\n",
      "Batch x range: [-0.742492, 2.259584]\n",
      "Batch y range: [0.350300, 753176000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.065150, 0.292255]\n",
      "Batch x range: [-0.768817, 2.830806]\n",
      "Batch y range: [0.361155, 1065523200.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.048270, 0.306901]\n",
      "Batch x range: [-0.768817, 2.830806]\n",
      "Batch y range: [0.384257, 902835968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.064047, 0.330882]\n",
      "Batch x range: [-0.757653, 2.830806]\n",
      "Batch y range: [0.419382, 759911616.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.044035, 0.327352]\n",
      "Batch x range: [-0.766159, 1.784380]\n",
      "Batch y range: [0.414415, 567816000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.049002, 0.329994]\n",
      "Batch x range: [-0.766159, 2.244695]\n",
      "Batch y range: [0.412511, 894348032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.057868, 0.255185]\n",
      "Batch x range: [-0.766659, 2.244695]\n",
      "Batch y range: [0.400716, 759385216.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.052270, 0.291936]\n",
      "Batch x range: [-0.766659, 2.244695]\n",
      "Batch y range: [0.400716, 691376000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.056139, 0.279764]\n",
      "Batch x range: [-0.791270, 1.782578]\n",
      "Batch y range: [0.457843, 585908416.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.057662, 0.269515]\n",
      "Batch x range: [-0.791270, 1.549712]\n",
      "Batch y range: [0.454483, 676904000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.045554, 0.268298]\n",
      "Batch x range: [-0.791270, 1.500159]\n",
      "Batch y range: [0.492847, 542552000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.050606, 0.359984]\n",
      "Batch x range: [-0.774683, 3.108251]\n",
      "Batch y range: [0.490920, 1146552064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.046422, 0.349745]\n",
      "Batch x range: [-0.778490, 3.108251]\n",
      "Batch y range: [0.461975, 594252032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.049621, 0.291348]\n",
      "Batch x range: [-0.778490, 3.994036]\n",
      "Batch y range: [0.461975, 1405248000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.049147, 0.302239]\n",
      "Batch x range: [-0.778490, 3.994036]\n",
      "Batch y range: [0.486033, 682284032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.042566, 0.321785]\n",
      "Batch x range: [-0.763041, 3.994036]\n",
      "Batch y range: [0.617019, 1172272000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.042922, 0.345883]\n",
      "Batch x range: [-0.797338, 3.196317]\n",
      "Batch y range: [0.645220, 841452032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.032210, 0.337796]\n",
      "Batch x range: [-0.797338, 3.196317]\n",
      "Batch y range: [0.603750, 1068659968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.040125, 0.334869]\n",
      "Batch x range: [-0.797338, 2.841546]\n",
      "Batch y range: [0.759946, 545512000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.045758, 0.432345]\n",
      "Batch x range: [-0.759291, 6.408009]\n",
      "Batch y range: [0.842209, 2110256000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.047395, 0.383288]\n",
      "Batch x range: [-0.773947, 6.408009]\n",
      "Batch y range: [1.094032, 1017683968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.036705, 0.406221]\n",
      "Batch x range: [-0.781050, 6.408009]\n",
      "Batch y range: [1.272485, 1425744000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.035709, 0.333762]\n",
      "Batch x range: [-0.781050, 4.064215]\n",
      "Batch y range: [1.409591, 902444032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.040431, 0.400745]\n",
      "Batch x range: [-0.781050, 6.630873]\n",
      "Batch y range: [1.566486, 2175344128.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025562, 0.440162]\n",
      "Batch x range: [-0.788790, 7.043195]\n",
      "Batch y range: [2.087752, 2295763968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.026290, 0.503904]\n",
      "Batch x range: [-0.788790, 7.043195]\n",
      "Batch y range: [2.346846, 1651091968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.027163, 0.399864]\n",
      "Batch x range: [-0.786634, 7.043195]\n",
      "Batch y range: [2.346846, 2129095936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.027225, 0.522092]\n",
      "Batch x range: [-0.786634, 6.472518]\n",
      "Batch y range: [2.406770, 3692928000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007926, 0.481544]\n",
      "Batch x range: [-0.786634, 11.827136]\n",
      "Batch y range: [3.420916, 3692928000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018846, 0.609539]\n",
      "Batch x range: [-0.788297, 11.827136]\n",
      "Batch y range: [3.774658, 1684460032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.057662, 0.269515]\n",
      "Batch x range: [-0.791270, 1.549712]\n",
      "Batch y range: [0.454483, 676904000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.045554, 0.268298]\n",
      "Batch x range: [-0.791270, 1.500159]\n",
      "Batch y range: [0.492847, 542552000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.050606, 0.359984]\n",
      "Batch x range: [-0.774683, 3.108251]\n",
      "Batch y range: [0.490920, 1146552064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.046422, 0.349745]\n",
      "Batch x range: [-0.778490, 3.108251]\n",
      "Batch y range: [0.461975, 594252032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.049621, 0.291348]\n",
      "Batch x range: [-0.778490, 3.994036]\n",
      "Batch y range: [0.461975, 1405248000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.049147, 0.302239]\n",
      "Batch x range: [-0.778490, 3.994036]\n",
      "Batch y range: [0.486033, 682284032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.042566, 0.321785]\n",
      "Batch x range: [-0.763041, 3.994036]\n",
      "Batch y range: [0.617019, 1172272000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.042922, 0.345883]\n",
      "Batch x range: [-0.797338, 3.196317]\n",
      "Batch y range: [0.645220, 841452032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.032210, 0.337796]\n",
      "Batch x range: [-0.797338, 3.196317]\n",
      "Batch y range: [0.603750, 1068659968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.040125, 0.334869]\n",
      "Batch x range: [-0.797338, 2.841546]\n",
      "Batch y range: [0.759946, 545512000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.045758, 0.432345]\n",
      "Batch x range: [-0.759291, 6.408009]\n",
      "Batch y range: [0.842209, 2110256000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.047395, 0.383288]\n",
      "Batch x range: [-0.773947, 6.408009]\n",
      "Batch y range: [1.094032, 1017683968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.036705, 0.406221]\n",
      "Batch x range: [-0.781050, 6.408009]\n",
      "Batch y range: [1.272485, 1425744000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.035709, 0.333762]\n",
      "Batch x range: [-0.781050, 4.064215]\n",
      "Batch y range: [1.409591, 902444032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.040431, 0.400745]\n",
      "Batch x range: [-0.781050, 6.630873]\n",
      "Batch y range: [1.566486, 2175344128.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.025562, 0.440162]\n",
      "Batch x range: [-0.788790, 7.043195]\n",
      "Batch y range: [2.087752, 2295763968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.026290, 0.503904]\n",
      "Batch x range: [-0.788790, 7.043195]\n",
      "Batch y range: [2.346846, 1651091968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.027163, 0.399864]\n",
      "Batch x range: [-0.786634, 7.043195]\n",
      "Batch y range: [2.346846, 2129095936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.027225, 0.522092]\n",
      "Batch x range: [-0.786634, 6.472518]\n",
      "Batch y range: [2.406770, 3692928000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007926, 0.481544]\n",
      "Batch x range: [-0.786634, 11.827136]\n",
      "Batch y range: [3.420916, 3692928000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.018846, 0.609539]\n",
      "Batch x range: [-0.788297, 11.827136]\n",
      "Batch y range: [3.774658, 1684460032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.015754, 0.517747]\n",
      "Batch x range: [-0.789541, 11.827136]\n",
      "Batch y range: [4.020113, 1684460032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.011529, 0.454535]\n",
      "Batch x range: [-0.792160, 4.950068]\n",
      "Batch y range: [4.464731, 1396787968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014497, 0.458188]\n",
      "Batch x range: [-0.792160, 4.950068]\n",
      "Batch y range: [4.464731, 1674604032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007173, 0.557279]\n",
      "Batch x range: [-0.792160, 4.916321]\n",
      "Batch y range: [5.043776, 1674604032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.021277, 0.513669]\n",
      "Batch x range: [-0.788448, 4.916321]\n",
      "Batch y range: [5.202772, 1408999936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.013811, 0.527198]\n",
      "Batch x range: [-0.780040, 4.916321]\n",
      "Batch y range: [5.202772, 1214456064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023003, 0.668434]\n",
      "Batch x range: [-0.780040, 4.006883]\n",
      "Batch y range: [5.774364, 1143187968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.011614, 0.505740]\n",
      "Batch x range: [-0.780040, 3.340757]\n",
      "Batch y range: [5.909528, 1143187968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.017824, 0.574634]\n",
      "Batch x range: [-0.779653, 3.271304]\n",
      "Batch y range: [3.582282, 1963520000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.019881, 0.481197]\n",
      "Batch x range: [-0.776887, 5.905580]\n",
      "Batch y range: [3.085784, 1963520000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.020153, 0.515405]\n",
      "Batch x range: [-0.776887, 5.905580]\n",
      "Batch y range: [3.085784, 2511527936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014799, 0.510118]\n",
      "Batch x range: [-0.779586, 7.781979]\n",
      "Batch y range: [3.248181, 1516748032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014672, 0.707441]\n",
      "Batch x range: [-0.792599, 7.781979]\n",
      "Batch y range: [3.555313, 1022067968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014214, 0.549062]\n",
      "Batch x range: [-0.792599, 4.375816]\n",
      "Batch y range: [3.294747, 1022067968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.019708, 0.485982]\n",
      "Batch x range: [-0.792599, 3.069970]\n",
      "Batch y range: [3.569309, 1007960000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.009405, 0.670374]\n",
      "Batch x range: [-0.791895, 3.069970]\n",
      "Batch y range: [3.662238, 1007960000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.015754, 0.517747]\n",
      "Batch x range: [-0.789541, 11.827136]\n",
      "Batch y range: [4.020113, 1684460032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.011529, 0.454535]\n",
      "Batch x range: [-0.792160, 4.950068]\n",
      "Batch y range: [4.464731, 1396787968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014497, 0.458188]\n",
      "Batch x range: [-0.792160, 4.950068]\n",
      "Batch y range: [4.464731, 1674604032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007173, 0.557279]\n",
      "Batch x range: [-0.792160, 4.916321]\n",
      "Batch y range: [5.043776, 1674604032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.021277, 0.513669]\n",
      "Batch x range: [-0.788448, 4.916321]\n",
      "Batch y range: [5.202772, 1408999936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.013811, 0.527198]\n",
      "Batch x range: [-0.780040, 4.916321]\n",
      "Batch y range: [5.202772, 1214456064.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.023003, 0.668434]\n",
      "Batch x range: [-0.780040, 4.006883]\n",
      "Batch y range: [5.774364, 1143187968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.011614, 0.505740]\n",
      "Batch x range: [-0.780040, 3.340757]\n",
      "Batch y range: [5.909528, 1143187968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.017824, 0.574634]\n",
      "Batch x range: [-0.779653, 3.271304]\n",
      "Batch y range: [3.582282, 1963520000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.019881, 0.481197]\n",
      "Batch x range: [-0.776887, 5.905580]\n",
      "Batch y range: [3.085784, 1963520000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.020153, 0.515405]\n",
      "Batch x range: [-0.776887, 5.905580]\n",
      "Batch y range: [3.085784, 2511527936.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014799, 0.510118]\n",
      "Batch x range: [-0.779586, 7.781979]\n",
      "Batch y range: [3.248181, 1516748032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014672, 0.707441]\n",
      "Batch x range: [-0.792599, 7.781979]\n",
      "Batch y range: [3.555313, 1022067968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.014214, 0.549062]\n",
      "Batch x range: [-0.792599, 4.375816]\n",
      "Batch y range: [3.294747, 1022067968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.019708, 0.485982]\n",
      "Batch x range: [-0.792599, 3.069970]\n",
      "Batch y range: [3.569309, 1007960000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.009405, 0.670374]\n",
      "Batch x range: [-0.791895, 3.069970]\n",
      "Batch y range: [3.662238, 1007960000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007655, 0.517172]\n",
      "Batch x range: [-0.793596, 3.069970]\n",
      "Batch y range: [4.211303, 1053628032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007957, 0.639988]\n",
      "Batch x range: [-0.793596, 3.019975]\n",
      "Batch y range: [4.919902, 1053628032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.009298, 0.559678]\n",
      "Batch x range: [-0.796882, 3.393016]\n",
      "Batch y range: [5.613240, 1133251968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.005619, 0.712361]\n",
      "Batch x range: [-0.796882, 3.393016]\n",
      "Batch y range: [4.499854, 1133251968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007654, 0.634398]\n",
      "Batch x range: [-0.796882, 3.393016]\n",
      "Batch y range: [4.944159, 1175891968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.004093, 0.828372]\n",
      "Batch x range: [-0.780805, 3.698724]\n",
      "Batch y range: [7.357214, 1175891968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.003072, 0.688680]\n",
      "Batch x range: [-0.774764, 3.971441]\n",
      "Batch y range: [8.870261, 999868032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.003265, 0.745544]\n",
      "Batch x range: [-0.773374, 4.856843]\n",
      "Batch y range: [10.759677, 1463683968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000537, 0.942723]\n",
      "Batch x range: [-0.773681, 4.856843]\n",
      "Batch y range: [11.977435, 784419968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.001451, 0.857575]\n",
      "Batch x range: [-0.790849, 4.856843]\n",
      "Batch y range: [12.551403, 666378624.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000910, 0.830266]\n",
      "Batch x range: [-0.794637, 4.759434]\n",
      "Batch y range: [11.534707, 824435968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000259, 0.801069]\n",
      "Batch x range: [-0.794637, 4.759434]\n",
      "Batch y range: [11.534707, 869324032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000185, 0.892932]\n",
      "Batch x range: [-0.786435, 5.335026]\n",
      "Batch y range: [12.343747, 869324032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000038, 0.908412]\n",
      "Batch x range: [-0.786435, 5.566212]\n",
      "Batch y range: [13.426636, 968856000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000125, 0.898765]\n",
      "Batch x range: [-0.790881, 6.150608]\n",
      "Batch y range: [17.826628, 766555008.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000041, 0.931822]\n",
      "Batch x range: [-0.793032, 6.321031]\n",
      "Batch y range: [18.721174, 766555008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.006641, 0.597780]\n",
      "Validation batch x range: [-0.793032, 6.321031]\n",
      "Validation batch y range: [19.515892, 1153630976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.007755, 0.608970]\n",
      "Validation batch x range: [-0.793032, 6.869423]\n",
      "Validation batch y range: [24.233438, 1153630976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.004674, 0.633546]\n",
      "Validation batch x range: [-0.781313, 6.869423]\n",
      "Validation batch y range: [20.848780, 913982016.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007655, 0.517172]\n",
      "Batch x range: [-0.793596, 3.069970]\n",
      "Batch y range: [4.211303, 1053628032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007957, 0.639988]\n",
      "Batch x range: [-0.793596, 3.019975]\n",
      "Batch y range: [4.919902, 1053628032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.009298, 0.559678]\n",
      "Batch x range: [-0.796882, 3.393016]\n",
      "Batch y range: [5.613240, 1133251968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.005619, 0.712361]\n",
      "Batch x range: [-0.796882, 3.393016]\n",
      "Batch y range: [4.499854, 1133251968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.007654, 0.634398]\n",
      "Batch x range: [-0.796882, 3.393016]\n",
      "Batch y range: [4.944159, 1175891968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.004093, 0.828372]\n",
      "Batch x range: [-0.780805, 3.698724]\n",
      "Batch y range: [7.357214, 1175891968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.003072, 0.688680]\n",
      "Batch x range: [-0.774764, 3.971441]\n",
      "Batch y range: [8.870261, 999868032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.003265, 0.745544]\n",
      "Batch x range: [-0.773374, 4.856843]\n",
      "Batch y range: [10.759677, 1463683968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000537, 0.942723]\n",
      "Batch x range: [-0.773681, 4.856843]\n",
      "Batch y range: [11.977435, 784419968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.001451, 0.857575]\n",
      "Batch x range: [-0.790849, 4.856843]\n",
      "Batch y range: [12.551403, 666378624.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000910, 0.830266]\n",
      "Batch x range: [-0.794637, 4.759434]\n",
      "Batch y range: [11.534707, 824435968.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000259, 0.801069]\n",
      "Batch x range: [-0.794637, 4.759434]\n",
      "Batch y range: [11.534707, 869324032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000185, 0.892932]\n",
      "Batch x range: [-0.786435, 5.335026]\n",
      "Batch y range: [12.343747, 869324032.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000038, 0.908412]\n",
      "Batch x range: [-0.786435, 5.566212]\n",
      "Batch y range: [13.426636, 968856000.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000125, 0.898765]\n",
      "Batch x range: [-0.790881, 6.150608]\n",
      "Batch y range: [17.826628, 766555008.000000]\n",
      "Warning: NaN or Inf loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Weights range: [0.000041, 0.931822]\n",
      "Batch x range: [-0.793032, 6.321031]\n",
      "Batch y range: [18.721174, 766555008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.006641, 0.597780]\n",
      "Validation batch x range: [-0.793032, 6.321031]\n",
      "Validation batch y range: [19.515892, 1153630976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.007755, 0.608970]\n",
      "Validation batch x range: [-0.793032, 6.869423]\n",
      "Validation batch y range: [24.233438, 1153630976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.004674, 0.633546]\n",
      "Validation batch x range: [-0.781313, 6.869423]\n",
      "Validation batch y range: [20.848780, 913982016.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.005849, 0.629184]\n",
      "Validation batch x range: [-0.781313, 6.869423]\n",
      "Validation batch y range: [20.614735, 877379008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.008884, 0.614599]\n",
      "Validation batch x range: [-0.781313, 6.658914]\n",
      "Validation batch y range: [15.540419, 996574976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.009735, 0.567168]\n",
      "Validation batch x range: [-0.760812, 6.324790]\n",
      "Validation batch y range: [14.033964, 996574976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.011338, 0.568807]\n",
      "Validation batch x range: [-0.760900, 6.324790]\n",
      "Validation batch y range: [14.033964, 981859008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.021861, 0.457119]\n",
      "Validation batch x range: [-0.764340, 5.052469]\n",
      "Validation batch y range: [10.800024, 1178865024.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.017823, 0.453955]\n",
      "Validation batch x range: [-0.764340, 5.027741]\n",
      "Validation batch y range: [10.800024, 850102976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.019298, 0.445641]\n",
      "Validation batch x range: [-0.786081, 5.027741]\n",
      "Validation batch y range: [12.940453, 710894016.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.025855, 0.387832]\n",
      "Validation batch x range: [-0.786081, 4.809872]\n",
      "Validation batch y range: [13.870887, 1117995008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.030974, 0.438913]\n",
      "Validation batch x range: [-0.786081, 4.345732]\n",
      "Validation batch y range: [20.401716, 1117995008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.023907, 0.456094]\n",
      "Validation batch x range: [-0.775535, 4.874259]\n",
      "Validation batch y range: [25.829971, 1543911040.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.016436, 0.537611]\n",
      "Validation batch x range: [-0.775535, 5.649727]\n",
      "Validation batch y range: [28.024269, 1543911040.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.014376, 0.541377]\n",
      "Validation batch x range: [-0.788038, 5.847161]\n",
      "Validation batch y range: [40.073082, 1156044032.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.008562, 0.682563]\n",
      "Validation batch x range: [-0.788038, 5.847161]\n",
      "Validation batch y range: [40.283932, 1156044032.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.009143, 0.683795]\n",
      "Validation batch x range: [-0.788038, 5.847161]\n",
      "Validation batch y range: [39.206890, 899420032.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.008787, 0.640071]\n",
      "Validation batch x range: [-0.798864, 6.267113]\n",
      "Validation batch y range: [44.983490, 899420032.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.006143, 0.656151]\n",
      "Validation batch x range: [-0.798864, 8.084621]\n",
      "Validation batch y range: [47.296284, 1142269056.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.004443, 0.742101]\n",
      "Validation batch x range: [-0.798864, 8.776571]\n",
      "Validation batch y range: [66.214798, 1142269056.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.003776, 0.817454]\n",
      "Validation batch x range: [-0.789780, 9.000401]\n",
      "Validation batch y range: [75.571663, 875198016.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.003708, 0.807117]\n",
      "Validation batch x range: [-0.793313, 9.000401]\n",
      "Validation batch y range: [91.557381, 835065024.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.003076, 0.828946]\n",
      "Validation batch x range: [-0.797022, 9.250413]\n",
      "Validation batch y range: [90.656250, 552842368.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.001975, 0.883739]\n",
      "Validation batch x range: [-0.797022, 9.874375]\n",
      "Validation batch y range: [100.912430, 477155104.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.001972, 0.871854]\n",
      "Validation batch x range: [-0.796073, 10.339170]\n",
      "Validation batch y range: [115.106995, 400946592.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.001479, 0.898174]\n",
      "Validation batch x range: [-0.801403, 10.973149]\n",
      "Validation batch y range: [116.224686, 818830912.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.005849, 0.629184]\n",
      "Validation batch x range: [-0.781313, 6.869423]\n",
      "Validation batch y range: [20.614735, 877379008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.008884, 0.614599]\n",
      "Validation batch x range: [-0.781313, 6.658914]\n",
      "Validation batch y range: [15.540419, 996574976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.009735, 0.567168]\n",
      "Validation batch x range: [-0.760812, 6.324790]\n",
      "Validation batch y range: [14.033964, 996574976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.011338, 0.568807]\n",
      "Validation batch x range: [-0.760900, 6.324790]\n",
      "Validation batch y range: [14.033964, 981859008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.021861, 0.457119]\n",
      "Validation batch x range: [-0.764340, 5.052469]\n",
      "Validation batch y range: [10.800024, 1178865024.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.017823, 0.453955]\n",
      "Validation batch x range: [-0.764340, 5.027741]\n",
      "Validation batch y range: [10.800024, 850102976.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.019298, 0.445641]\n",
      "Validation batch x range: [-0.786081, 5.027741]\n",
      "Validation batch y range: [12.940453, 710894016.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.025855, 0.387832]\n",
      "Validation batch x range: [-0.786081, 4.809872]\n",
      "Validation batch y range: [13.870887, 1117995008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.030974, 0.438913]\n",
      "Validation batch x range: [-0.786081, 4.345732]\n",
      "Validation batch y range: [20.401716, 1117995008.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.023907, 0.456094]\n",
      "Validation batch x range: [-0.775535, 4.874259]\n",
      "Validation batch y range: [25.829971, 1543911040.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.016436, 0.537611]\n",
      "Validation batch x range: [-0.775535, 5.649727]\n",
      "Validation batch y range: [28.024269, 1543911040.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.014376, 0.541377]\n",
      "Validation batch x range: [-0.788038, 5.847161]\n",
      "Validation batch y range: [40.073082, 1156044032.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.008562, 0.682563]\n",
      "Validation batch x range: [-0.788038, 5.847161]\n",
      "Validation batch y range: [40.283932, 1156044032.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.009143, 0.683795]\n",
      "Validation batch x range: [-0.788038, 5.847161]\n",
      "Validation batch y range: [39.206890, 899420032.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.008787, 0.640071]\n",
      "Validation batch x range: [-0.798864, 6.267113]\n",
      "Validation batch y range: [44.983490, 899420032.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.006143, 0.656151]\n",
      "Validation batch x range: [-0.798864, 8.084621]\n",
      "Validation batch y range: [47.296284, 1142269056.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.004443, 0.742101]\n",
      "Validation batch x range: [-0.798864, 8.776571]\n",
      "Validation batch y range: [66.214798, 1142269056.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.003776, 0.817454]\n",
      "Validation batch x range: [-0.789780, 9.000401]\n",
      "Validation batch y range: [75.571663, 875198016.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.003708, 0.807117]\n",
      "Validation batch x range: [-0.793313, 9.000401]\n",
      "Validation batch y range: [91.557381, 835065024.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.003076, 0.828946]\n",
      "Validation batch x range: [-0.797022, 9.250413]\n",
      "Validation batch y range: [90.656250, 552842368.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.001975, 0.883739]\n",
      "Validation batch x range: [-0.797022, 9.874375]\n",
      "Validation batch y range: [100.912430, 477155104.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.001972, 0.871854]\n",
      "Validation batch x range: [-0.796073, 10.339170]\n",
      "Validation batch y range: [115.106995, 400946592.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.001479, 0.898174]\n",
      "Validation batch x range: [-0.801403, 10.973149]\n",
      "Validation batch y range: [116.224686, 818830912.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.000487, 0.904643]\n",
      "Validation batch x range: [-0.801403, 12.849202]\n",
      "Validation batch y range: [104.747177, 818830912.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.000327, 0.930217]\n",
      "Validation batch x range: [-0.801403, 12.849202]\n",
      "Validation batch y range: [86.609100, 612918272.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.000396, 0.938022]\n",
      "Validation batch x range: [-0.794495, 12.849202]\n",
      "Validation batch y range: [94.448112, 612918272.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.001060, 0.895702]\n",
      "Validation batch x range: [-0.794495, 13.015782]\n",
      "Validation batch y range: [129.143768, 369241888.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.000517, 0.924328]\n",
      "Validation batch x range: [-0.794495, 13.875698]\n",
      "Validation batch y range: [162.010880, 281787808.000000]\n",
      "Epoch 1 metrics:\n",
      "  train loss: nan\n",
      "  test loss: nan\n",
      "Warning: NaN or Inf detected in metric at epoch 0. Stopping training.\n",
      "GreatNet training completed!\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.000487, 0.904643]\n",
      "Validation batch x range: [-0.801403, 12.849202]\n",
      "Validation batch y range: [104.747177, 818830912.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.000327, 0.930217]\n",
      "Validation batch x range: [-0.801403, 12.849202]\n",
      "Validation batch y range: [86.609100, 612918272.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.000396, 0.938022]\n",
      "Validation batch x range: [-0.794495, 12.849202]\n",
      "Validation batch y range: [94.448112, 612918272.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.001060, 0.895702]\n",
      "Validation batch x range: [-0.794495, 13.015782]\n",
      "Validation batch y range: [129.143768, 369241888.000000]\n",
      "Warning: NaN or Inf validation loss detected. Loss value: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan])\n",
      "Validation weights range: [0.000517, 0.924328]\n",
      "Validation batch x range: [-0.794495, 13.875698]\n",
      "Validation batch y range: [162.010880, 281787808.000000]\n",
      "Epoch 1 metrics:\n",
      "  train loss: nan\n",
      "  test loss: nan\n",
      "Warning: NaN or Inf detected in metric at epoch 0. Stopping training.\n",
      "GreatNet training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train GreatNet with gradient clipping and learning rate scheduler\n",
    "print(\"Training GreatNet...\")\n",
    "optimizer = torch.optim.Adam(great_net.parameters(), lr=0.0001, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                      factor=0.5, patience=5,\n",
    "                                                      verbose=True)\n",
    "\n",
    "great_net_run = Run(great_net,\n",
    "                    loss,\n",
    "                    dataloader_train,\n",
    "                    val_dataloaders={'test': dataloader_test},\n",
    "                    optimizer=optimizer,\n",
    "                    callbacks=[\n",
    "                        EarlyStoppingCallback(\n",
    "                            metric_name='loss',\n",
    "                            dataloader_name='test',\n",
    "                            patience=15\n",
    "                        )\n",
    "                    ],\n",
    "                    grad_clip_value=1.0)  # Add gradient clipping\n",
    "\n",
    "great_net_history = great_net_run.launch(50)\n",
    "\n",
    "print(\"GreatNet training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTMNet...\n",
      "Epoch 1 metrics:\n",
      "  train loss: nan\n",
      "  test loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining LSTMNet...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m lstm_net_run \u001b[38;5;241m=\u001b[39m Run(lstm_net,\n\u001b[1;32m      4\u001b[0m                    loss,\n\u001b[1;32m      5\u001b[0m                    dataloader_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                     dataloader_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                                                     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m---> 12\u001b[0m lstm_net_history \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_net_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTMNet training completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/xiaojiucai/xiaojiucai/experiments/__init__.py:59\u001b[0m, in \u001b[0;36mRun.launch\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Launch the training experiment.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    Training history.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39madd_metric(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch, train_loss)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/xiaojiucai/xiaojiucai/experiments/__init__.py:97\u001b[0m, in \u001b[0;36mRun._train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(weights, batch_y)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/dev/xiaojiucai/xiaojiucai/models/networks.py:150\u001b[0m, in \u001b[0;36mLSTMNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookback, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_assets \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_channels)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Pass through LSTM\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Take the last output\u001b[39;00m\n\u001b[1;32m    153\u001b[0m x \u001b[38;5;241m=\u001b[39m lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train LSTMNet\n",
    "print(\"Training LSTMNet...\")\n",
    "lstm_net_run = Run(lstm_net,\n",
    "                   loss,\n",
    "                   dataloader_train,\n",
    "                   val_dataloaders={'test': dataloader_test},\n",
    "                   optimizer=torch.optim.Adam(lstm_net.parameters(), amsgrad=True, lr=0.001),\n",
    "                   callbacks=[EarlyStoppingCallback(metric_name='loss',\n",
    "                                                    dataloader_name='test',\n",
    "                                                    patience=10)])\n",
    "\n",
    "lstm_net_history = lstm_net_run.launch(50)\n",
    "\n",
    "print(\"LSTMNet training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Models\n",
    "\n",
    "Let's evaluate the trained models and compare them with benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics defined!\n"
     ]
    }
   ],
   "source": [
    "# Add trained models to benchmarks\n",
    "benchmarks['GreatNet'] = great_net\n",
    "benchmarks['LSTMNet'] = lstm_net\n",
    "\n",
    "# Define metrics for evaluation\n",
    "metrics = {\n",
    "    'Max Drawdown': MaximumDrawdownLoss(),\n",
    "    'Mean Return': MeanReturnsLoss(),\n",
    "    'Sharpe Ratio': SharpeRatioLoss(),\n",
    "    'Volatility': VolatilityLoss()\n",
    "}\n",
    "\n",
    "print(\"Evaluation metrics defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Results\n",
    "\n",
    "Let's visualize the training progress and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for GreatNet\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "train_loss = great_net_history.metrics[\n",
    "    (great_net_history.metrics['dataloader'] == 'train') & \n",
    "    (great_net_history.metrics['metric'] == 'loss')\n",
    "]\n",
    "plt.plot(train_loss['epoch'], train_loss['value'], label='Train Loss')\n",
    "\n",
    "val_loss = great_net_history.metrics[\n",
    "    (great_net_history.metrics['dataloader'] == 'test') & \n",
    "    (great_net_history.metrics['metric'] == 'loss')\n",
    "]\n",
    "plt.plot(val_loss['epoch'], val_loss['value'], label='Validation Loss')\n",
    "plt.title('GreatNet Training Progress')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "train_loss = lstm_net_history.metrics[\n",
    "    (lstm_net_history.metrics['dataloader'] == 'train') & \n",
    "    (lstm_net_history.metrics['metric'] == 'loss')\n",
    "]\n",
    "plt.plot(train_loss['epoch'], train_loss['value'], label='Train Loss')\n",
    "\n",
    "val_loss = lstm_net_history.metrics[\n",
    "    (lstm_net_history.metrics['dataloader'] == 'test') & \n",
    "    (lstm_net_history.metrics['metric'] == 'loss')\n",
    "]\n",
    "plt.plot(val_loss['epoch'], val_loss['value'], label='Validation Loss')\n",
    "plt.title('LSTMNet Training Progress')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "1. Load stock data from a local file\n",
    "2. Prepare the data for training using a rolling window approach\n",
    "3. Create dataset and data loaders\n",
    "4. Define and train neural network models for portfolio optimization\n",
    "5. Evaluate the models against traditional benchmarks\n",
    "\n",
    "The XiaoJiuCai framework provides a flexible and extensible approach to portfolio optimization using deep learning techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
