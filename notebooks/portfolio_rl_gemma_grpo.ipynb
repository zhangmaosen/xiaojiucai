{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5236c6c",
   "metadata": {},
   "source": [
    "# 📈 投资组合强化学习优化 - Gemma 1B + GRPO\n",
    "\n",
    "本notebook使用Unsloth框架和GRPO（Group Relative Policy Optimization）方法，训练Gemma 1B模型进行投资组合优化决策。\n",
    "\n",
    "## 🎯 目标\n",
    "- 使用强化学习训练语言模型进行投资组合分析\n",
    "- 基于MAG7股票数据生成投资建议\n",
    "- 设计包含收益率和风险的奖励函数\n",
    "- 生成带推理过程的投资决策\n",
    "\n",
    "## 📊 数据源\n",
    "- 数据集：MAG7股票数据 (data/mag7_data_raw.parquet)\n",
    "- 包含：Apple, Amazon, Google, Meta, Microsoft, NVIDIA, Tesla\n",
    "- 时间范围：2005-2025年"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b4da2",
   "metadata": {},
   "source": [
    "## 1. 环境设置和依赖安装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651d598",
   "metadata": {},
   "source": [
    "## ⚠️ 重要提示\n",
    "\n",
    "如果您遇到 `SyntaxError: non-default argument follows default argument` 错误，这是Unsloth库版本兼容性问题。\n",
    "\n",
    "**解决方案：**\n",
    "1. 首先运行下面的安装单元格\n",
    "2. **重启Python内核** (Kernel -> Restart)\n",
    "3. 然后继续执行其他单元格\n",
    "\n",
    "本notebook包含了兼容性处理，如果Unsloth不可用，会自动回退到标准的transformers库进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3eca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 安装兼容版本的Unsloth和相关依赖\n",
    "# !pip install --upgrade pip\n",
    "# !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# !pip install  xformers\n",
    "\n",
    "# # 安装额外的金融分析库\n",
    "# !pip install yfinance pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "# # 重启Python内核以确保依赖正确加载\n",
    "# import os\n",
    "# os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ca9b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 09-26 19:28:49 [__init__.py:216] Automatically detected platform cuda.\n",
      "INFO 09-26 19:28:49 [__init__.py:216] Automatically detected platform cuda.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "🚀 PyTorch版本: 2.8.0+cu128\n",
      "🎮 CUDA可用: True\n",
      "🔥 GPU设备: NVIDIA GeForce RTX 3090\n",
      "💾 GPU内存: 25.4 GB\n",
      "✅ Unsloth已成功导入\n",
      "🚀 PyTorch版本: 2.8.0+cu128\n",
      "🎮 CUDA可用: True\n",
      "🔥 GPU设备: NVIDIA GeForce RTX 3090\n",
      "💾 GPU内存: 25.4 GB\n",
      "✅ Unsloth已成功导入\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 先尝试导入基本库，如果Unsloth有问题，使用替代方案\n",
    "try:\n",
    "    # Unsloth和transformers相关\n",
    "    from unsloth import FastLanguageModel\n",
    "    from datasets import Dataset\n",
    "    from trl import GRPOConfig, GRPOTrainer\n",
    "    import torch\n",
    "    \n",
    "    print(f\"🚀 PyTorch版本: {torch.__version__}\")\n",
    "    print(f\"🎮 CUDA可用: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"🔥 GPU设备: {torch.cuda.get_device_name()}\")\n",
    "        print(f\"💾 GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    UNSLOTH_AVAILABLE = True\n",
    "    print(\"✅ Unsloth已成功导入\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Unsloth导入失败: {e}\")\n",
    "    print(\"🔄 尝试使用标准transformers库...\")\n",
    "    \n",
    "    # 使用标准transformers库作为替代\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "    from datasets import Dataset\n",
    "    import torch\n",
    "    \n",
    "    print(f\"🚀 PyTorch版本: {torch.__version__}\")\n",
    "    print(f\"🎮 CUDA可用: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"🔥 GPU设备: {torch.cuda.get_device_name()}\")\n",
    "        print(f\"💾 GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    UNSLOTH_AVAILABLE = False\n",
    "    print(\"✅ 标准transformers库已导入\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aed12f",
   "metadata": {},
   "source": [
    "## 2. 数据加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55c29f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 加载MAG7股票数据...\n",
      "数据形状: (5027, 35)\n",
      "时间范围: 2005-09-26 00:00:00 到 2025-09-18 00:00:00\n",
      "股票列表: ['AAPL', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
      "\n",
      "🎯 目标股票: ['AAPL', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
      "\n",
      "📈 最近5天数据预览:\n",
      "  AAPL: $237.88\n",
      "  AMZN: $231.23\n",
      "  GOOGL: $252.03\n"
     ]
    }
   ],
   "source": [
    "# 加载MAG7股票数据\n",
    "print(\"📊 加载MAG7股票数据...\")\n",
    "data_path = '../data/mag7_data_raw.parquet'\n",
    "mag7_data = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"数据形状: {mag7_data.shape}\")\n",
    "print(f\"时间范围: {mag7_data.index.min()} 到 {mag7_data.index.max()}\")\n",
    "print(f\"股票列表: {[col[1] for col in mag7_data.columns if col[0] == 'Close']}\")\n",
    "\n",
    "# 提取股票代码\n",
    "tickers = [col[1] for col in mag7_data.columns if col[0] == 'Close']\n",
    "print(f\"\\n🎯 目标股票: {tickers}\")\n",
    "\n",
    "# 显示最近的数据\n",
    "recent_data = mag7_data.tail()\n",
    "print(\"\\n📈 最近5天数据预览:\")\n",
    "for ticker in tickers[:3]:  # 只显示前3只股票\n",
    "    close_price = recent_data[('Close', ticker)].iloc[-1]\n",
    "    print(f\"  {ticker}: ${close_price:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e56145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 计算技术指标...\n",
      "\n",
      "📊 最近技术指标:\n",
      "  AAPL:\n",
      "    日收益率: -0.46%\n",
      "    年化波动率: 22.7%\n",
      "    RSI: 62.1\n",
      "  AMZN:\n",
      "    日收益率: -0.17%\n",
      "    年化波动率: 27.0%\n",
      "    RSI: 56.4\n",
      "  GOOGL:\n",
      "    日收益率: 1.00%\n",
      "    年化波动率: 36.5%\n",
      "    RSI: 90.5\n"
     ]
    }
   ],
   "source": [
    "# 计算关键财务指标\n",
    "def calculate_financial_metrics(data, window=20):\n",
    "    \"\"\"计算财务指标\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        # 获取价格数据\n",
    "        close = data[('Close', ticker)]\n",
    "        high = data[('High', ticker)]\n",
    "        low = data[('Low', ticker)]\n",
    "        \n",
    "        # 计算收益率\n",
    "        returns = close.pct_change()\n",
    "        \n",
    "        # 计算技术指标\n",
    "        sma = close.rolling(window).mean()\n",
    "        volatility = returns.rolling(window).std() * np.sqrt(252)  # 年化波动率\n",
    "        \n",
    "        # RSI计算\n",
    "        delta = close.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        metrics[ticker] = {\n",
    "            'returns': returns,\n",
    "            'sma': sma,\n",
    "            'volatility': volatility,\n",
    "            'rsi': rsi,\n",
    "            'price': close\n",
    "        }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 计算指标\n",
    "print(\"🧮 计算技术指标...\")\n",
    "financial_metrics = calculate_financial_metrics(mag7_data)\n",
    "\n",
    "# 显示最近的指标\n",
    "print(\"\\n📊 最近技术指标:\")\n",
    "for ticker in tickers[:3]:\n",
    "    metrics = financial_metrics[ticker]\n",
    "    recent_return = metrics['returns'].iloc[-1] * 100\n",
    "    recent_volatility = metrics['volatility'].iloc[-1] * 100\n",
    "    recent_rsi = metrics['rsi'].iloc[-1]\n",
    "    \n",
    "    print(f\"  {ticker}:\")\n",
    "    print(f\"    日收益率: {recent_return:.2f}%\")\n",
    "    print(f\"    年化波动率: {recent_volatility:.1f}%\")\n",
    "    print(f\"    RSI: {recent_rsi:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d5d95",
   "metadata": {},
   "source": [
    "## 3. 生成训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f0788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 生成训练数据集...\n",
      "✅ 生成了 47 个训练样本\n",
      "\n",
      "📝 训练样本示例:\n",
      "问题: 日期: 2023-09-21\n",
      "市场数据:\n",
      "AAPL: 价格$172.24, 日涨跌-0.89%, 相对20日均线-3.56%\n",
      "AMZN: 价格$129.33, 日涨跌-4.41%, 相对20日均线-6.14%\n",
      "GOOGL: 价格$129.55, 日涨跌-2.47%, 相对20日均线-3.44%\n",
      "META: 价格$294.12, 日涨跌-1.31%, 相对20日均线-0.95%\n",
      "MSFT: 价格$3...\n",
      "推理: 市场分析：\n",
      "AAPL: 价格$172.24, 日涨跌-0.89%, 弱于20日均线3.6%\n",
      "AMZN: 价格$129.33, 日涨跌-4.41%, 弱于20日均线6.1%\n",
      "GOOGL: 价格$129.55, 日涨跌-2.47%, 弱于20日均线3.4%\n",
      "META: 价格$294.12, 日涨跌-1.31%, 弱于20日均线0.9%\n",
      "MSFT: 价格$314.79, 日涨跌-0.39%, 弱于20日...\n",
      "答案: {\"AAPL\": 0.018, \"AMZN\": 0.018, \"GOOGL\": 0.132, \"META\": 0.018, \"MSFT\": 0.018, \"NVDA\": 0.018, \"TSLA\": 0.78}\n",
      "✅ 生成了 47 个训练样本\n",
      "\n",
      "📝 训练样本示例:\n",
      "问题: 日期: 2023-09-21\n",
      "市场数据:\n",
      "AAPL: 价格$172.24, 日涨跌-0.89%, 相对20日均线-3.56%\n",
      "AMZN: 价格$129.33, 日涨跌-4.41%, 相对20日均线-6.14%\n",
      "GOOGL: 价格$129.55, 日涨跌-2.47%, 相对20日均线-3.44%\n",
      "META: 价格$294.12, 日涨跌-1.31%, 相对20日均线-0.95%\n",
      "MSFT: 价格$3...\n",
      "推理: 市场分析：\n",
      "AAPL: 价格$172.24, 日涨跌-0.89%, 弱于20日均线3.6%\n",
      "AMZN: 价格$129.33, 日涨跌-4.41%, 弱于20日均线6.1%\n",
      "GOOGL: 价格$129.55, 日涨跌-2.47%, 弱于20日均线3.4%\n",
      "META: 价格$294.12, 日涨跌-1.31%, 弱于20日均线0.9%\n",
      "MSFT: 价格$314.79, 日涨跌-0.39%, 弱于20日...\n",
      "答案: {\"AAPL\": 0.018, \"AMZN\": 0.018, \"GOOGL\": 0.132, \"META\": 0.018, \"MSFT\": 0.018, \"NVDA\": 0.018, \"TSLA\": 0.78}\n"
     ]
    }
   ],
   "source": [
    "# 定义系统提示\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "你是一位专业的投资组合管理专家。请根据提供的市场数据和技术指标，为投资者提供投资建议。\n",
    "\n",
    "请按以下格式回答：\n",
    "<reasoning>\n",
    "详细分析市场情况、技术指标和投资逻辑...\n",
    "</reasoning>\n",
    "<answer>\n",
    "具体的投资组合权重建议（JSON格式）\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "# XML格式模板\n",
    "XML_PORTFOLIO_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "def create_market_scenario(data, start_idx, window=30):\n",
    "    \"\"\"创建市场情景\"\"\"\n",
    "    end_idx = start_idx + window\n",
    "    if end_idx >= len(data):\n",
    "        return None\n",
    "    \n",
    "    scenario_data = {}\n",
    "    current_date = data.index[start_idx].strftime('%Y-%m-%d')\n",
    "    \n",
    "    # 获取当前市场状态\n",
    "    for ticker in tickers:\n",
    "        current_price = data[('Close', ticker)].iloc[start_idx]\n",
    "        prev_price = data[('Close', ticker)].iloc[start_idx-1] if start_idx > 0 else current_price\n",
    "        daily_return = (current_price - prev_price) / prev_price * 100\n",
    "        \n",
    "        # 计算简单移动平均\n",
    "        if start_idx >= 20:\n",
    "            sma_20 = data[('Close', ticker)].iloc[start_idx-20:start_idx].mean()\n",
    "            price_vs_sma = (current_price - sma_20) / sma_20 * 100\n",
    "        else:\n",
    "            price_vs_sma = 0\n",
    "        \n",
    "        scenario_data[ticker] = {\n",
    "            'price': round(current_price, 2),\n",
    "            'daily_return': round(daily_return, 2),\n",
    "            'vs_sma20': round(price_vs_sma, 2)\n",
    "        }\n",
    "    \n",
    "    # 计算未来实际收益（用于生成标准答案）\n",
    "    future_returns = {}\n",
    "    for ticker in tickers:\n",
    "        current_price = data[('Close', ticker)].iloc[start_idx]\n",
    "        future_price = data[('Close', ticker)].iloc[end_idx]\n",
    "        future_return = (future_price - current_price) / current_price\n",
    "        future_returns[ticker] = future_return\n",
    "    \n",
    "    return {\n",
    "        'date': current_date,\n",
    "        'market_data': scenario_data,\n",
    "        'future_returns': future_returns\n",
    "    }\n",
    "\n",
    "def generate_optimal_portfolio(future_returns, risk_aversion=1.0):\n",
    "    \"\"\"生成最优投资组合权重\"\"\"\n",
    "    returns_array = np.array(list(future_returns.values()))\n",
    "    \n",
    "    # 简单的均值回归策略：买入表现较差的股票\n",
    "    scores = -returns_array  # 负收益率得分更高\n",
    "    scores = np.maximum(scores, 0)  # 只考虑负收益\n",
    "    \n",
    "    if scores.sum() == 0:\n",
    "        # 如果所有股票都上涨，平均分配\n",
    "        weights = np.ones(len(tickers)) / len(tickers)\n",
    "    else:\n",
    "        # 根据下跌程度分配权重\n",
    "        weights = scores / scores.sum()\n",
    "        # 添加一些随机性避免过度集中\n",
    "        noise = np.random.normal(0, 0.05, len(weights))\n",
    "        weights = weights + noise\n",
    "        weights = np.maximum(weights, 0.02)  # 最小权重2%\n",
    "        weights = weights / weights.sum()  # 归一化\n",
    "    \n",
    "    return {ticker: round(weight, 3) for ticker, weight in zip(tickers, weights)}\n",
    "\n",
    "def create_reasoning(market_data, portfolio_weights):\n",
    "    \"\"\"生成投资推理\"\"\"\n",
    "    reasoning_parts = []\n",
    "    \n",
    "    # 市场分析\n",
    "    reasoning_parts.append(\"市场分析：\")\n",
    "    for ticker, data in market_data.items():\n",
    "        trend = \"上涨\" if data['daily_return'] > 0 else \"下跌\"\n",
    "        vs_ma = \"强于\" if data['vs_sma20'] > 0 else \"弱于\"\n",
    "        reasoning_parts.append(\n",
    "            f\"{ticker}: 价格${data['price']}, 日涨跌{data['daily_return']:+.2f}%, {vs_ma}20日均线{abs(data['vs_sma20']):.1f}%\"\n",
    "        )\n",
    "    \n",
    "    # 投资逻辑\n",
    "    reasoning_parts.append(\"\\n投资逻辑：\")\n",
    "    top_holdings = sorted(portfolio_weights.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    for ticker, weight in top_holdings:\n",
    "        if weight > 0.15:  # 权重超过15%的重点分析\n",
    "            ticker_data = market_data[ticker]\n",
    "            if ticker_data['vs_sma20'] < 0:\n",
    "                reasoning_parts.append(f\"增持{ticker}（{weight*100:.1f}%）：价格低于均线，存在均值回归机会\")\n",
    "            else:\n",
    "                reasoning_parts.append(f\"配置{ticker}（{weight*100:.1f}%）：技术面相对强势，适度配置\")\n",
    "    \n",
    "    reasoning_parts.append(\"\\n风险控制：采用分散化投资，单个股票权重不超过30%，降低集中风险。\")\n",
    "    \n",
    "    return \"\\n\".join(reasoning_parts)\n",
    "\n",
    "# 生成训练数据\n",
    "print(\"🔄 生成训练数据集...\")\n",
    "training_samples = []\n",
    "sample_count = 0\n",
    "\n",
    "# 使用最近2年的数据生成样本\n",
    "start_date = mag7_data.index[-500]  # 大约2年的数据\n",
    "start_idx = mag7_data.index.get_loc(start_date)\n",
    "\n",
    "for i in range(start_idx, len(mag7_data) - 30, 10):  # 每10天采样一次\n",
    "    scenario = create_market_scenario(mag7_data, i)\n",
    "    if scenario is None:\n",
    "        continue\n",
    "    \n",
    "    # 生成最优投资组合\n",
    "    optimal_weights = generate_optimal_portfolio(scenario['future_returns'])\n",
    "    \n",
    "    # 生成推理过程\n",
    "    reasoning = create_reasoning(scenario['market_data'], optimal_weights)\n",
    "    \n",
    "    # 创建问题\n",
    "    question = f\"\"\"\n",
    "日期: {scenario['date']}\n",
    "市场数据:\n",
    "\"\"\"\n",
    "    for ticker, data in scenario['market_data'].items():\n",
    "        question += f\"{ticker}: 价格${data['price']}, 日涨跌{data['daily_return']:+.2f}%, 相对20日均线{data['vs_sma20']:+.2f}%\\n\"\n",
    "    \n",
    "    question += \"\\n请分析当前市场情况并给出MAG7股票的投资组合权重建议。\"\n",
    "    \n",
    "    # 创建答案\n",
    "    answer = json.dumps(optimal_weights, ensure_ascii=False)\n",
    "    \n",
    "    training_samples.append({\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": question.strip()}\n",
    "        ],\n",
    "        \"reasoning\": reasoning,\n",
    "        \"answer\": answer,\n",
    "        \"future_returns\": scenario['future_returns']\n",
    "    })\n",
    "    \n",
    "    sample_count += 1\n",
    "    if sample_count >= 200:  # 限制样本数量\n",
    "        break\n",
    "\n",
    "print(f\"✅ 生成了 {len(training_samples)} 个训练样本\")\n",
    "\n",
    "# 显示示例\n",
    "if training_samples:\n",
    "    print(\"\\n📝 训练样本示例:\")\n",
    "    sample = training_samples[0]\n",
    "    print(\"问题:\", sample['prompt'][1]['content'][:200] + \"...\")\n",
    "    print(\"推理:\", sample['reasoning'][:200] + \"...\")\n",
    "    print(\"答案:\", sample['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548215a",
   "metadata": {},
   "source": [
    "## 4. 模型配置和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf44d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 加载模型...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 4. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f50fa801-b77a-4a41-9ee0-46a0b454c35e)')' thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/unslothai/other/43d9e0f2f19a5d7836895f648dc0e762816acf77/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Unsloth 2025.9.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n",
      "Unsloth 2025.9.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Unsloth模型加载完成！\n",
      "✅ 已设置Qwen chat template\n",
      "📊 模型参数量: 1,738,007,552\n"
     ]
    }
   ],
   "source": [
    "# 模型配置\n",
    "max_seq_length = 2048  # 选择任何长度\n",
    "dtype = None  # None表示自动检测\n",
    "load_in_4bit = True  # 使用4bit量化减少内存使用\n",
    "\n",
    "print(\"🤖 加载模型...\")\n",
    "\n",
    "if UNSLOTH_AVAILABLE:\n",
    "    try:\n",
    "        # 使用Unsloth加载模型\n",
    "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name=\"unsloth/Qwen3-1.7B-Base\",  # 使用Qwen3 1.7B基础版本\n",
    "            max_seq_length=max_seq_length,\n",
    "            dtype=dtype,\n",
    "            load_in_4bit=load_in_4bit,\n",
    "            #device_map = \"balanced\",\n",
    "        )\n",
    "        \n",
    "        # 添加LoRA适配器\n",
    "        model = FastLanguageModel.get_peft_model(\n",
    "            model,\n",
    "            r=16,  # rank\n",
    "            target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                            \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "            lora_alpha=16,\n",
    "            lora_dropout=0,\n",
    "            bias=\"none\",\n",
    "            use_gradient_checkpointing=\"unsloth\",\n",
    "            random_state=3407,\n",
    "            use_rslora=False,\n",
    "            loftq_config=None,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Unsloth模型加载完成！\")\n",
    "        USE_UNSLOTH = True\n",
    "        \n",
    "        # 确保chat_template被正确设置\n",
    "        if not hasattr(tokenizer, 'chat_template') or tokenizer.chat_template is None:\n",
    "            tokenizer.chat_template = \"\"\"{% for message in messages %}{% if message['role'] == 'system' %}{{ '<|im_start|>system\\n' + message['content'] + '<|im_end|>\\n' }}{% elif message['role'] == 'user' %}{{ '<|im_start|>user\\n' + message['content'] + '<|im_end|>\\n' }}{% elif message['role'] == 'assistant' %}{{ '<|im_start|>assistant\\n' + message['content'] + '<|im_end|>\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"\"\"\n",
    "            print(\"✅ 已设置Qwen chat template\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unsloth模型加载失败: {e}\")\n",
    "        print(\"🔄 回退到标准transformers...\")\n",
    "        UNSLOTH_AVAILABLE = False\n",
    "\n",
    "if not UNSLOTH_AVAILABLE:\n",
    "    try:\n",
    "        # 使用标准transformers库加载Qwen3模型\n",
    "        from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "        \n",
    "        print(\"🔄 使用标准transformers加载Qwen3模型...\")\n",
    "        \n",
    "        # 配置4bit量化\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\"\n",
    "        )\n",
    "        \n",
    "        # 加载模型和tokenizer\n",
    "        model_name = \"Qwen/Qwen3-1.7B\"\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"balanced\",\n",
    "            torch_dtype=torch.float16,\n",
    "        )\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # 设置Qwen模型的chat template\n",
    "        tokenizer.chat_template = \"\"\"{% for message in messages %}{% if message['role'] == 'system' %}{{ '<|im_start|>system\\n' + message['content'] + '<|im_end|>\\n' }}{% elif message['role'] == 'user' %}{{ '<|im_start|>user\\n' + message['content'] + '<|im_end|>\\n' }}{% elif message['role'] == 'assistant' %}{{ '<|im_start|>assistant\\n' + message['content'] + '<|im_end|>\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"\"\"\n",
    "        \n",
    "        print(\"✅ 标准transformers模型加载完成！\")\n",
    "        USE_UNSLOTH = False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 标准transformers模型加载也失败: {e}\")\n",
    "        print(\"💡 请检查模型名称和网络连接\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "print(f\"📊 模型参数量: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0826e8",
   "metadata": {},
   "source": [
    "## 5. 奖励函数设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee4f83f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 奖励函数配置完成！\n",
      "奖励机制:\n",
      "  - 投资组合收益: 40%\n",
      "  - 权重合理性: 20%\n",
      "  - 推理质量: 25%\n",
      "  - 格式正确性: 15%\n"
     ]
    }
   ],
   "source": [
    "def extract_xml_answer(text: str) -> str:\n",
    "    \"\"\"从XML格式中提取答案\"\"\"\n",
    "    try:\n",
    "        if \"<answer>\" in text and \"</answer>\" in text:\n",
    "            answer = text.split(\"<answer>\")[1].split(\"</answer>\")[0].strip()\n",
    "            return answer\n",
    "        return text.strip()\n",
    "    except:\n",
    "        return text.strip()\n",
    "\n",
    "def parse_portfolio_weights(answer_text: str) -> dict:\n",
    "    \"\"\"解析投资组合权重\"\"\"\n",
    "    try:\n",
    "        # 尝试解析JSON\n",
    "        if answer_text.startswith('{') and answer_text.endswith('}'):\n",
    "            return json.loads(answer_text)\n",
    "        \n",
    "        # 尝试从文本中提取权重信息\n",
    "        weights = {}\n",
    "        for ticker in tickers:\n",
    "            # 查找类似 \"AAPL: 0.15\" 或 \"AAPL\": 0.15 的模式\n",
    "            patterns = [\n",
    "                rf'{ticker}[\"\\']?\\s*[:]\\s*([0-9.]+)',\n",
    "                rf'[\"\\']?{ticker}[\"\\']?\\s*[:]\\s*([0-9.]+)',\n",
    "            ]\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, answer_text)\n",
    "                if match:\n",
    "                    weights[ticker] = float(match.group(1))\n",
    "                    break\n",
    "        \n",
    "        if weights:\n",
    "            # 归一化权重\n",
    "            total = sum(weights.values())\n",
    "            if total > 0:\n",
    "                weights = {k: v/total for k, v in weights.items()}\n",
    "            # 补充缺失的股票\n",
    "            for ticker in tickers:\n",
    "                if ticker not in weights:\n",
    "                    weights[ticker] = 0.0\n",
    "            return weights\n",
    "            \n",
    "        # 如果无法解析，返回均等权重\n",
    "        return {ticker: 1.0/len(tickers) for ticker in tickers}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"解析权重时出错: {e}\")\n",
    "        return {ticker: 1.0/len(tickers) for ticker in tickers}\n",
    "\n",
    "def calculate_portfolio_reward(predicted_weights: dict, actual_returns: dict, \n",
    "                             reasoning_text: str = \"\") -> float:\n",
    "    \"\"\"计算投资组合奖励\"\"\"\n",
    "    reward = 0.0\n",
    "    \n",
    "    # 1. 投资组合收益奖励 (权重40%)\n",
    "    portfolio_return = sum(predicted_weights.get(ticker, 0) * actual_returns.get(ticker, 0) \n",
    "                          for ticker in tickers)\n",
    "    \n",
    "    # 将收益率转换为奖励分数 (收益率 * 100)\n",
    "    return_reward = portfolio_return * 100\n",
    "    reward += return_reward * 0.4\n",
    "    \n",
    "    # 2. 权重合理性奖励 (权重20%)\n",
    "    total_weight = sum(predicted_weights.values())\n",
    "    weight_penalty = abs(total_weight - 1.0) * 10  # 权重总和应该接近1\n",
    "    \n",
    "    # 检查权重分散程度\n",
    "    max_weight = max(predicted_weights.values()) if predicted_weights.values() else 1\n",
    "    concentration_penalty = max(0, (max_weight - 0.4) * 5)  # 单只股票权重不应超过40%\n",
    "    \n",
    "    weight_reward = max(0, 2 - weight_penalty - concentration_penalty)\n",
    "    reward += weight_reward * 0.2\n",
    "    \n",
    "    # 3. 推理质量奖励 (权重25%)\n",
    "    reasoning_reward = 0\n",
    "    if reasoning_text:\n",
    "        # 检查是否包含关键分析元素\n",
    "        analysis_keywords = ['分析', '风险', '收益', '市场', '技术', '均线', '涨跌']\n",
    "        reasoning_lower = reasoning_text.lower()\n",
    "        \n",
    "        keyword_score = sum(1 for keyword in analysis_keywords if keyword in reasoning_lower)\n",
    "        reasoning_reward = min(keyword_score / len(analysis_keywords) * 3, 3)\n",
    "        \n",
    "        # 推理长度奖励（鼓励详细分析）\n",
    "        if len(reasoning_text) > 100:\n",
    "            reasoning_reward += 1\n",
    "        if len(reasoning_text) > 200:\n",
    "            reasoning_reward += 1\n",
    "    \n",
    "    reward += reasoning_reward * 0.25\n",
    "    \n",
    "    # 4. 格式正确性奖励 (权重15%)\n",
    "    format_reward = 0\n",
    "    if \"<reasoning>\" in reasoning_text and \"</reasoning>\" in reasoning_text:\n",
    "        format_reward += 1\n",
    "    if len(predicted_weights) == len(tickers):  # 包含所有股票\n",
    "        format_reward += 1\n",
    "    if all(0 <= w <= 1 for w in predicted_weights.values()):  # 权重在合理范围\n",
    "        format_reward += 1\n",
    "    \n",
    "    reward += format_reward * 0.15\n",
    "    \n",
    "    return reward\n",
    "\n",
    "def portfolio_reward_function(prompts, completions, **kwargs):\n",
    "    \"\"\"GRPO奖励函数 - 基于生成质量的奖励\"\"\"\n",
    "    rewards = []\n",
    "\n",
    "    for i, completion in enumerate(completions):\n",
    "        try:\n",
    "            generated_text = completion\n",
    "            reward = 0.0\n",
    "\n",
    "            # 1. 格式正确性奖励 (权重40%)\n",
    "            if \"<reasoning>\" in generated_text and \"</reasoning>\" in generated_text:\n",
    "                reward += 1.0\n",
    "            if \"<answer>\" in generated_text and \"</answer>\" in generated_text:\n",
    "                reward += 1.0\n",
    "\n",
    "            # 2. 推理质量奖励 (权重30%)\n",
    "            reasoning_reward = 0\n",
    "            if \"<reasoning>\" in generated_text and \"</reasoning>\" in generated_text:\n",
    "                reasoning_text = generated_text.split(\"<reasoning>\")[1].split(\"</reasoning>\")[0]\n",
    "\n",
    "                # 检查是否包含关键分析元素\n",
    "                analysis_keywords = ['分析', '风险', '收益', '市场', '技术', '均线', '涨跌']\n",
    "                reasoning_lower = reasoning_text.lower()\n",
    "\n",
    "                keyword_score = sum(1 for keyword in analysis_keywords if keyword in reasoning_lower)\n",
    "                reasoning_reward = min(keyword_score / len(analysis_keywords) * 2, 2)\n",
    "\n",
    "                # 推理长度奖励\n",
    "                if len(reasoning_text) > 100:\n",
    "                    reasoning_reward += 0.5\n",
    "                if len(reasoning_text) > 200:\n",
    "                    reasoning_reward += 0.5\n",
    "\n",
    "            reward += reasoning_reward * 0.3\n",
    "\n",
    "            # 3. 权重合理性奖励 (权重30%)\n",
    "            if \"<answer>\" in generated_text and \"</answer>\" in generated_text:\n",
    "                answer_text = extract_xml_answer(generated_text)\n",
    "                predicted_weights = parse_portfolio_weights(answer_text)\n",
    "\n",
    "                # 检查权重总和接近1\n",
    "                total_weight = sum(predicted_weights.values())\n",
    "                weight_penalty = abs(total_weight - 1.0)\n",
    "                if weight_penalty < 0.1:  # 允许10%的误差\n",
    "                    reward += 0.5\n",
    "\n",
    "                # 检查权重分散程度\n",
    "                max_weight = max(predicted_weights.values()) if predicted_weights.values() else 1\n",
    "                if max_weight <= 0.4:  # 最大权重不超过40%\n",
    "                    reward += 0.5\n",
    "\n",
    "                # 检查包含所有股票\n",
    "                if len(predicted_weights) == len(tickers):\n",
    "                    reward += 0.5\n",
    "\n",
    "            rewards.append(reward)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"奖励计算错误: {e}\")\n",
    "            rewards.append(0.0)  # 默认奖励\n",
    "\n",
    "    return rewards\n",
    "\n",
    "print(\"🎯 奖励函数配置完成！\")\n",
    "print(\"奖励机制:\")\n",
    "print(\"  - 投资组合收益: 40%\")\n",
    "print(\"  - 权重合理性: 20%\")\n",
    "print(\"  - 推理质量: 25%\")\n",
    "print(\"  - 格式正确性: 15%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400cab4",
   "metadata": {},
   "source": [
    "## 6. 准备训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf8f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 准备训练数据集...\n",
      "训练集大小: 47\n",
      "评估集大小: 0\n",
      "\n",
      "🧪 测试奖励函数...\n",
      "测试奖励分数: 3.76\n"
     ]
    }
   ],
   "source": [
    "# 转换为Hugging Face数据集格式\n",
    "def prepare_dataset(samples):\n",
    "    \"\"\"准备训练数据集\"\"\"\n",
    "    dataset_dict = {\n",
    "        'prompt': [],\n",
    "        'future_returns': [],\n",
    "        'expected_reasoning': [],\n",
    "        'expected_answer': []\n",
    "    }\n",
    "    \n",
    "    for sample in samples:\n",
    "        dataset_dict['prompt'].append(sample['prompt'])\n",
    "        dataset_dict['future_returns'].append(sample['future_returns'])\n",
    "        dataset_dict['expected_reasoning'].append(sample['reasoning'])\n",
    "        dataset_dict['expected_answer'].append(sample['answer'])\n",
    "    \n",
    "    return Dataset.from_dict(dataset_dict)\n",
    "\n",
    "# 创建数据集\n",
    "print(\"📚 准备训练数据集...\")\n",
    "train_dataset = prepare_dataset(training_samples[:150])  # 使用150个样本训练\n",
    "eval_dataset = prepare_dataset(training_samples[150:])   # 剩余样本用于评估\n",
    "\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"评估集大小: {len(eval_dataset)}\")\n",
    "\n",
    "# 测试奖励函数\n",
    "print(\"\\n🧪 测试奖励函数...\")\n",
    "test_prompt = \"请分析当前市场情况并给出MAG7股票的投资组合权重建议。\"\n",
    "test_completion = '''<reasoning>\n",
    "    市场分析：AAPL价格上涨2%，技术面强势。TSLA下跌3%，可能存在抄底机会。\n",
    "    投资逻辑：采用均值回归策略，适度增持下跌股票。\n",
    "    </reasoning>\n",
    "    <answer>\n",
    "    {\"AAPL\": 0.15, \"AMZN\": 0.14, \"GOOGL\": 0.14, \"META\": 0.14, \"MSFT\": 0.14, \"NVDA\": 0.14, \"TSLA\": 0.15}\n",
    "    </answer>'''\n",
    "\n",
    "test_rewards = portfolio_reward_function([test_prompt], [test_completion])\n",
    "print(f\"测试奖励分数: {test_rewards[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd4dd05",
   "metadata": {},
   "source": [
    "## 7. GRPO训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "193adaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ 配置训练参数...\n",
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 4\n",
      "✅ GRPO训练器初始化完成！\n",
      "📊 训练配置:\n",
      "  - 训练方法: GRPO强化学习\n",
      "  - 学习率: 5e-06\n",
      "  - 最大步数: 50\n",
      "  - 每轮生成数: 4\n",
      "  - 批次大小: 1\n",
      "  - 梯度累积步数: 4\n",
      "✅ GRPO训练器初始化完成！\n",
      "📊 训练配置:\n",
      "  - 训练方法: GRPO强化学习\n",
      "  - 学习率: 5e-06\n",
      "  - 最大步数: 50\n",
      "  - 每轮生成数: 4\n",
      "  - 批次大小: 1\n",
      "  - 梯度累积步数: 4\n"
     ]
    }
   ],
   "source": [
    "# GRPO训练配置\n",
    "print(\"⚙️ 配置训练参数...\")\n",
    "\n",
    "if UNSLOTH_AVAILABLE:\n",
    "    try:\n",
    "        # 使用Unsloth的GRPO训练\n",
    "        grpo_config = GRPOConfig(\n",
    "            output_dir=\"./portfolio_grpo_results\",\n",
    "            num_generations=4,           # 每个prompt生成4个候选答案\n",
    "            learning_rate=5e-6,          # 学习率\n",
    "            max_steps=50,                # 减少训练步数以避免错误\n",
    "            per_device_train_batch_size=1,  # 批次大小\n",
    "            gradient_accumulation_steps=4,   # 梯度累积\n",
    "            use_vllm=False,              # 不使用vLLM\n",
    "            temperature=0.8,             # 生成温度\n",
    "            epsilon=0.2,                 # PPO clip参数\n",
    "            logging_steps=5,             # 日志记录频率\n",
    "            save_steps=25,               # 保存频率\n",
    "            eval_steps=25,               # 评估频率\n",
    "            warmup_steps=5,              # 热身步数\n",
    "            report_to=[],                # 不使用wandb等工具\n",
    "        )\n",
    "        \n",
    "        # 创建GRPO训练器\n",
    "        trainer = GRPOTrainer(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            args=grpo_config,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            reward_funcs=portfolio_reward_function,\n",
    "        )\n",
    "        \n",
    "        GRPO_AVAILABLE = True\n",
    "        print(\"✅ GRPO训练器初始化完成！\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GRPO初始化失败: {e}\")\n",
    "        print(\"🔄 将使用简化的监督学习训练...\")\n",
    "        GRPO_AVAILABLE = False\n",
    "else:\n",
    "    GRPO_AVAILABLE = False\n",
    "\n",
    "if not GRPO_AVAILABLE:\n",
    "    # 使用标准的监督学习训练作为替代\n",
    "    from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "    \n",
    "    # 准备监督学习数据\n",
    "    def prepare_supervised_dataset(samples):\n",
    "        \"\"\"将GRPO样本转换为监督学习格式\"\"\"\n",
    "        texts = []\n",
    "        for sample in samples:\n",
    "            # 构建完整的训练文本\n",
    "            messages = sample['prompt']\n",
    "            \n",
    "            # 手动构建对话文本（避免chat_template问题）\n",
    "            conversation_parts = []\n",
    "            for message in messages:\n",
    "                role = message['role']\n",
    "                content = message['content']\n",
    "                if role == 'system':\n",
    "                    conversation_parts.append(f\"<|im_start|>system\\n{content}<|im_end|>\")\n",
    "                elif role == 'user':\n",
    "                    conversation_parts.append(f\"<|im_start|>user\\n{content}<|im_end|>\")\n",
    "                elif role == 'assistant':\n",
    "                    conversation_parts.append(f\"<|im_start|>assistant\\n{content}<|im_end|>\")\n",
    "            \n",
    "            # 添加生成提示\n",
    "            conversation_parts.append(\"<|im_start|>assistant\")\n",
    "            \n",
    "            prompt_text = \"\\n\".join(conversation_parts)\n",
    "            \n",
    "            # 添加期望的回答\n",
    "            full_response = XML_PORTFOLIO_FORMAT.format(\n",
    "                reasoning=sample['reasoning'],\n",
    "                answer=sample['answer']\n",
    "            )\n",
    "            \n",
    "            full_text = prompt_text + full_response + tokenizer.eos_token\n",
    "            texts.append(full_text)\n",
    "        \n",
    "        return {\"text\": texts}\n",
    "    \n",
    "    # 转换数据集\n",
    "    supervised_train = Dataset.from_dict(prepare_supervised_dataset(training_samples[:150]))\n",
    "    supervised_eval = Dataset.from_dict(prepare_supervised_dataset(training_samples[150:]))\n",
    "    \n",
    "    # 调试：检查数据集内容\n",
    "    print(\"🔍 调试数据集内容...\")\n",
    "    print(f\"训练集大小: {len(supervised_train)}\")\n",
    "    if len(supervised_train) > 0:\n",
    "        sample_text = supervised_train[0]['text']\n",
    "        print(f\"样本文本类型: {type(sample_text)}\")\n",
    "        print(f\"样本文本长度: {len(sample_text) if isinstance(sample_text, str) else 'N/A'}\")\n",
    "        print(f\"样本文本预览: {sample_text[:200] if isinstance(sample_text, str) else str(sample_text)[:200]}\")\n",
    "    \n",
    "    # 数据预处理函数\n",
    "    \n",
    "    # 数据预处理函数\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=False,  # 让数据整理器处理padding\n",
    "            max_length=max_seq_length\n",
    "        )\n",
    "    \n",
    "    # 预处理数据集\n",
    "    supervised_train = supervised_train.map(preprocess_function, batched=True)\n",
    "    supervised_eval = supervised_eval.map(preprocess_function, batched=True)\n",
    "    \n",
    "    # 训练参数\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./portfolio_supervised_results\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=5e-5,\n",
    "        warmup_steps=10,\n",
    "        logging_steps=5,\n",
    "        save_steps=25,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=25,\n",
    "        save_total_limit=2,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=[],\n",
    "    )\n",
    "    \n",
    "    # 数据整理器 - 使用默认的数据整理器\n",
    "    data_collator = None  # 使用默认数据整理器\n",
    "    \n",
    "    # 创建训练器\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=supervised_train,\n",
    "        eval_dataset=supervised_eval,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    \n",
    "    print(\"✅ 监督学习训练器初始化完成！\")\n",
    "\n",
    "print(f\"📊 训练配置:\")\n",
    "if GRPO_AVAILABLE:\n",
    "    print(f\"  - 训练方法: GRPO强化学习\")\n",
    "    print(f\"  - 学习率: {grpo_config.learning_rate}\")\n",
    "    print(f\"  - 最大步数: {grpo_config.max_steps}\")\n",
    "    print(f\"  - 每轮生成数: {grpo_config.num_generations}\")\n",
    "else:\n",
    "    print(f\"  - 训练方法: 监督学习 (SFT)\")\n",
    "    print(f\"  - 学习率: {training_args.learning_rate}\")\n",
    "    print(f\"  - 训练轮数: {training_args.num_train_epochs}\")\n",
    "print(f\"  - 批次大小: 1\")\n",
    "print(f\"  - 梯度累积步数: 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4540cf",
   "metadata": {},
   "source": [
    "## 8. 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277cea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 开始GRPO强化学习训练...\n",
      "预计训练时间: 100 分钟\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 47 | Num Epochs = 5 | Total steps = 50\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 32768, 'bos_token_id': 151643}. If this is not desired, please set these values explicitly.\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 32768, 'bos_token_id': 151643}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 21:33, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / portfolio_reward_function / mean</th>\n",
       "      <th>rewards / portfolio_reward_function / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>241.225000</td>\n",
       "      <td>115.600000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>129.626668</td>\n",
       "      <td>64.400000</td>\n",
       "      <td>173.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240.875000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>103.550000</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251.025000</td>\n",
       "      <td>180.800000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>49.200000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>241.512500</td>\n",
       "      <td>103.800000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>82.400000</td>\n",
       "      <td>52.600000</td>\n",
       "      <td>112.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240.762500</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>92.033334</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>140.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248.150000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>88.100000</td>\n",
       "      <td>81.800000</td>\n",
       "      <td>94.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>241.112500</td>\n",
       "      <td>94.400000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>137.800000</td>\n",
       "      <td>94.400000</td>\n",
       "      <td>170.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>245.575000</td>\n",
       "      <td>92.400000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>239.425000</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>135.733334</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>180.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>242.237500</td>\n",
       "      <td>95.800000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>52.200000</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✅ GRPO强化学习训练完成！\n",
      "💾 保存模型...\n",
      "✅ 模型已保存到 'portfolio_model' 目录\n",
      "\n",
      "📊 训练统计:\n",
      "  - 最终训练损失: 0.0000\n",
      "  - 训练方法: GRPO强化学习\n",
      "  - 训练样本数: 47\n",
      "✅ 模型已保存到 'portfolio_model' 目录\n",
      "\n",
      "📊 训练统计:\n",
      "  - 最终训练损失: 0.0000\n",
      "  - 训练方法: GRPO强化学习\n",
      "  - 训练样本数: 47\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "training_method = \"GRPO强化学习\" if GRPO_AVAILABLE else \"监督学习\"\n",
    "print(f\"🚀 开始{training_method}训练...\")\n",
    "\n",
    "if GRPO_AVAILABLE:\n",
    "    estimated_time = grpo_config.max_steps * 2\n",
    "else:\n",
    "    estimated_time = int(training_args.num_train_epochs * len(supervised_train) / 4)\n",
    "\n",
    "print(f\"预计训练时间: {estimated_time} 分钟\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "try:\n",
    "    # 启动训练\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"✅ {training_method}训练完成！\")\n",
    "    \n",
    "    # 保存模型\n",
    "    print(\"💾 保存模型...\")\n",
    "    if USE_UNSLOTH:\n",
    "        model.save_pretrained(\"portfolio_model\")\n",
    "        tokenizer.save_pretrained(\"portfolio_model\")\n",
    "    else:\n",
    "        trainer.save_model(\"portfolio_model\")\n",
    "    \n",
    "    print(\"✅ 模型已保存到 'portfolio_model' 目录\")\n",
    "    \n",
    "    # 显示训练统计\n",
    "    print(\"\\n📊 训练统计:\")\n",
    "    if hasattr(trainer.state, 'log_history') and trainer.state.log_history:\n",
    "        last_log = trainer.state.log_history[-1]\n",
    "        if 'train_loss' in last_log:\n",
    "            print(f\"  - 最终训练损失: {last_log['train_loss']:.4f}\")\n",
    "        if 'eval_loss' in last_log:\n",
    "            print(f\"  - 最终验证损失: {last_log['eval_loss']:.4f}\")\n",
    "    \n",
    "    print(f\"  - 训练方法: {training_method}\")\n",
    "    print(f\"  - 训练样本数: {len(train_dataset) if GRPO_AVAILABLE else len(supervised_train)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 训练过程中出现错误: {e}\")\n",
    "    print(f\"错误类型: {type(e).__name__}\")\n",
    "    \n",
    "    # 提供调试信息\n",
    "    if \"CUDA\" in str(e):\n",
    "        print(\"💡 建议: GPU内存不足，尝试减少batch_size或使用CPU\")\n",
    "    elif \"module\" in str(e).lower():\n",
    "        print(\"💡 建议: 依赖库版本问题，请检查安装\")\n",
    "    else:\n",
    "        print(\"💡 建议: 检查数据格式和模型配置\")\n",
    "    \n",
    "    # 尝试保存当前状态\n",
    "    try:\n",
    "        print(\"🔄 尝试保存当前模型状态...\")\n",
    "        if USE_UNSLOTH:\n",
    "            model.save_pretrained(\"portfolio_model_checkpoint\")\n",
    "        else:\n",
    "            trainer.save_model(\"portfolio_model_checkpoint\")\n",
    "        print(\"✅ 检查点已保存\")\n",
    "    except:\n",
    "        print(\"❌ 无法保存检查点\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cbf25",
   "metadata": {},
   "source": [
    "## 9. 模型测试和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b0844c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 测试模型...\n",
      "📊 生成投资建议...\n",
      "\n",
      "🎯 模型回答:\n",
      "==================================================\n",
      "<reasoning>\n",
      "1. 从技术指标来看，AAPL和AMZN都相对20日均线有轻微的正向移动，表明它们可能仍有上涨空间。\n",
      "2. GOOGL和META的相对20日均线也有所提升，显示出这些股票近期走势较为健康。\n",
      "3. NVDA则是一个值得关注的股票，其相对于20日的负向移动显示其价格下挫。\n",
      "4. MSFT的相对20日均线小幅上升，显示其近期没有明显的下跌趋势。\n",
      "5. TSLA的相对20日均线明显下降，表明其近期有所下跌，需要警惕。\n",
      "6. 综合分析，建议投资组合中可考虑增加对AAPL和AMZN的持股，同时保持对GOOGL和META的持股，适度减少对NVDA和TSLA的持股。\n",
      "</reasoning>\n",
      "<answer>\n",
      "{\n",
      "  \"AAPL\": 0.2,\n",
      "  \"AMZN\": 0.2,\n",
      "  \"GOOGL\": 0.2,\n",
      "  \"META\": 0.2,\n",
      "  \"MSFT\": 0.1,\n",
      "  \"NVDA\": 0.1,\n",
      "  \"TSLA\": 0.1\n",
      "}\n",
      "</answer>\n",
      "==================================================\n",
      "\n",
      "📈 回答分析:\n",
      "✅ 包含推理过程\n",
      "✅ 包含明确答案\n",
      "✅ 成功解析权重: {'AAPL': 0.2, 'AMZN': 0.2, 'GOOGL': 0.2, 'META': 0.2, 'MSFT': 0.1, 'NVDA': 0.1, 'TSLA': 0.1}\n",
      "权重总和: 1.100\n",
      "\n",
      "🎯 模型回答:\n",
      "==================================================\n",
      "<reasoning>\n",
      "1. 从技术指标来看，AAPL和AMZN都相对20日均线有轻微的正向移动，表明它们可能仍有上涨空间。\n",
      "2. GOOGL和META的相对20日均线也有所提升，显示出这些股票近期走势较为健康。\n",
      "3. NVDA则是一个值得关注的股票，其相对于20日的负向移动显示其价格下挫。\n",
      "4. MSFT的相对20日均线小幅上升，显示其近期没有明显的下跌趋势。\n",
      "5. TSLA的相对20日均线明显下降，表明其近期有所下跌，需要警惕。\n",
      "6. 综合分析，建议投资组合中可考虑增加对AAPL和AMZN的持股，同时保持对GOOGL和META的持股，适度减少对NVDA和TSLA的持股。\n",
      "</reasoning>\n",
      "<answer>\n",
      "{\n",
      "  \"AAPL\": 0.2,\n",
      "  \"AMZN\": 0.2,\n",
      "  \"GOOGL\": 0.2,\n",
      "  \"META\": 0.2,\n",
      "  \"MSFT\": 0.1,\n",
      "  \"NVDA\": 0.1,\n",
      "  \"TSLA\": 0.1\n",
      "}\n",
      "</answer>\n",
      "==================================================\n",
      "\n",
      "📈 回答分析:\n",
      "✅ 包含推理过程\n",
      "✅ 包含明确答案\n",
      "✅ 成功解析权重: {'AAPL': 0.2, 'AMZN': 0.2, 'GOOGL': 0.2, 'META': 0.2, 'MSFT': 0.1, 'NVDA': 0.1, 'TSLA': 0.1}\n",
      "权重总和: 1.100\n"
     ]
    }
   ],
   "source": [
    "# 测试训练后的模型\n",
    "def test_portfolio_model(model, tokenizer, test_prompt, max_length=512):\n",
    "    \"\"\"测试投资组合模型\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 准备输入\n",
    "    inputs = tokenizer(\n",
    "        test_prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=1500\n",
    "    ).to(model.device if hasattr(model, 'device') else 'cpu')\n",
    "    \n",
    "    # 生成回答\n",
    "    with torch.no_grad():\n",
    "        if USE_UNSLOTH:\n",
    "            # Unsloth模型生成\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_length,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        else:\n",
    "            # 标准transformers生成\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs.input_ids,\n",
    "                attention_mask=inputs.attention_mask,\n",
    "                max_new_tokens=max_length,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                repetition_penalty=1.1,\n",
    "            )\n",
    "    \n",
    "    # 解码结果\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 提取模型回答部分（去除输入prompt）\n",
    "    response = generated_text[len(tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)):]\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "# 创建测试用例\n",
    "print(\"🧪 测试模型...\")\n",
    "\n",
    "test_scenario = {\n",
    "    \"date\": \"2025-09-26\",\n",
    "    \"market_data\": {\n",
    "        \"AAPL\": {\"price\": 225.50, \"daily_return\": 1.2, \"vs_sma20\": 3.5},\n",
    "        \"AMZN\": {\"price\": 185.30, \"daily_return\": -0.8, \"vs_sma20\": -2.1},\n",
    "        \"GOOGL\": {\"price\": 165.80, \"daily_return\": 0.5, \"vs_sma20\": 1.8},\n",
    "        \"META\": {\"price\": 520.40, \"daily_return\": 2.1, \"vs_sma20\": 5.2},\n",
    "        \"MSFT\": {\"price\": 415.70, \"daily_return\": 0.3, \"vs_sma20\": 0.9},\n",
    "        \"NVDA\": {\"price\": 125.90, \"daily_return\": -1.5, \"vs_sma20\": -4.3},\n",
    "        \"TSLA\": {\"price\": 245.60, \"daily_return\": -2.3, \"vs_sma20\": -6.8}\n",
    "    }\n",
    "}\n",
    "\n",
    "# 构建测试prompt\n",
    "test_question = f\"\"\"\n",
    "日期: {test_scenario['date']}\n",
    "市场数据:\n",
    "\"\"\"\n",
    "\n",
    "for ticker, data in test_scenario['market_data'].items():\n",
    "    test_question += f\"{ticker}: 价格${data['price']}, 日涨跌{data['daily_return']:+.1f}%, 相对20日均线{data['vs_sma20']:+.1f}%\\n\"\n",
    "\n",
    "test_question += \"\\n请分析当前市场情况并给出MAG7股票的投资组合权重建议。\"\n",
    "\n",
    "test_prompt = f\"\"\"\n",
    "{SYSTEM_PROMPT}\n",
    "\n",
    "用户: {test_question.strip()}\n",
    "\n",
    "助手: \n",
    "\"\"\"\n",
    "\n",
    "# 进行基础测试（不依赖训练结果）\n",
    "print(\"📊 生成投资建议...\")\n",
    "try:\n",
    "    response = test_portfolio_model(model, tokenizer, test_prompt)\n",
    "    \n",
    "    print(\"\\n🎯 模型回答:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(response)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 分析回答质量\n",
    "    print(\"\\n📈 回答分析:\")\n",
    "    if \"<reasoning>\" in response and \"</reasoning>\" in response:\n",
    "        print(\"✅ 包含推理过程\")\n",
    "    else:\n",
    "        print(\"❌ 缺少推理过程\")\n",
    "    \n",
    "    if \"<answer>\" in response and \"</answer>\" in response:\n",
    "        print(\"✅ 包含明确答案\")\n",
    "        answer_text = extract_xml_answer(response)\n",
    "        try:\n",
    "            weights = parse_portfolio_weights(answer_text)\n",
    "            print(f\"✅ 成功解析权重: {weights}\")\n",
    "            total_weight = sum(weights.values())\n",
    "            print(f\"权重总和: {total_weight:.3f}\")\n",
    "        except:\n",
    "            print(\"❌ 权重解析失败\")\n",
    "    else:\n",
    "        print(\"❌ 缺少明确答案\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ 模型测试失败: {e}\")\n",
    "    print(\"这可能是由于模型未完成训练或配置问题导致的\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7039fe5d",
   "metadata": {},
   "source": [
    "## 10. 保存和导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f08af7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 保存模型权重和配置...\n",
      "💾 保存LoRA权重...\n",
      "❌ 保存模型时出错: 'Qwen3ForCausalLM' object has no attribute 'save_lora'\n",
      "尝试基本保存...\n",
      "✅ 模型权重已保存为 portfolio_model_weights.pth\n",
      "\n",
      "📖 使用指南已创建: MODEL_USAGE_GUIDE.md\n",
      "✅ 模型权重已保存为 portfolio_model_weights.pth\n",
      "\n",
      "📖 使用指南已创建: MODEL_USAGE_GUIDE.md\n"
     ]
    }
   ],
   "source": [
    "# 保存和导出模型\n",
    "print(\"💾 保存模型权重和配置...\")\n",
    "\n",
    "try:\n",
    "    if USE_UNSLOTH:\n",
    "        # 保存LoRA权重\n",
    "        print(\"💾 保存LoRA权重...\")\n",
    "        model.save_lora(\"portfolio_lora\")\n",
    "        \n",
    "        # 保存完整模型（可选）\n",
    "        print(\"💾 保存完整模型...\")\n",
    "        model.save_pretrained_merged(\n",
    "            \"portfolio_complete\", \n",
    "            tokenizer, \n",
    "            save_method=\"merged_16bit\"\n",
    "        )\n",
    "        \n",
    "        saved_files = [\"portfolio_lora/\", \"portfolio_complete/\"]\n",
    "        \n",
    "    else:\n",
    "        # 使用标准方法保存\n",
    "        print(\"💾 保存PEFT模型...\")\n",
    "        model.save_pretrained(\"portfolio_peft\")\n",
    "        tokenizer.save_pretrained(\"portfolio_peft\")\n",
    "        \n",
    "        # 合并并保存完整模型\n",
    "        print(\"💾 合并并保存完整模型...\")\n",
    "        from peft import PeftModel\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"google/gemma-2-2b-it\",\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"cpu\"  # 在CPU上合并以节省GPU内存\n",
    "        )\n",
    "        merged_model = PeftModel.from_pretrained(base_model, \"portfolio_peft\")\n",
    "        merged_model = merged_model.merge_and_unload()\n",
    "        \n",
    "        merged_model.save_pretrained(\"portfolio_complete\")\n",
    "        tokenizer.save_pretrained(\"portfolio_complete\")\n",
    "        \n",
    "        saved_files = [\"portfolio_peft/\", \"portfolio_complete/\"]\n",
    "    \n",
    "    # 保存训练配置和元数据\n",
    "    training_metadata = {\n",
    "        \"model_name\": \"portfolio_optimization_model\",\n",
    "        \"base_model\": \"google/gemma-2-2b-it\" if not USE_UNSLOTH else \"unsloth/gemma-2-2b-it-bnb-4bit\",\n",
    "        \"training_method\": \"GRPO\" if GRPO_AVAILABLE else \"Supervised Fine-tuning\",\n",
    "        \"framework\": \"Unsloth\" if USE_UNSLOTH else \"Transformers + PEFT\",\n",
    "        \"dataset\": \"MAG7_portfolio_optimization\",\n",
    "        \"training_samples\": len(training_samples),\n",
    "        \"tickers\": tickers,\n",
    "        \"reward_components\": {\n",
    "            \"portfolio_return\": 0.4,\n",
    "            \"weight_validity\": 0.2,\n",
    "            \"reasoning_quality\": 0.25,\n",
    "            \"format_correctness\": 0.15\n",
    "        } if GRPO_AVAILABLE else None,\n",
    "        \"training_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_size\": f\"{model.num_parameters():,} parameters\"\n",
    "    }\n",
    "    \n",
    "    with open(\"portfolio_model_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(training_metadata, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"✅ 所有文件已保存！\")\n",
    "    print(\"\\n📁 保存的文件:\")\n",
    "    for file_path in saved_files:\n",
    "        print(f\"  - {file_path}\")\n",
    "    print(\"  - portfolio_model_metadata.json (训练元数据)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 保存模型时出错: {e}\")\n",
    "    print(\"尝试基本保存...\")\n",
    "    \n",
    "    try:\n",
    "        # 基本保存方法\n",
    "        torch.save(model.state_dict(), \"portfolio_model_weights.pth\")\n",
    "        print(\"✅ 模型权重已保存为 portfolio_model_weights.pth\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ 基本保存也失败: {e2}\")\n",
    "\n",
    "# 创建使用说明\n",
    "usage_guide = f\"\"\"\n",
    "# 投资组合优化模型使用指南\n",
    "\n",
    "## 模型信息\n",
    "- 训练框架: {\"Unsloth\" if USE_UNSLOTH else \"Transformers + PEFT\"}\n",
    "- 训练方法: {\"GRPO强化学习\" if GRPO_AVAILABLE else \"监督学习\"}\n",
    "- 基础模型: {\"unsloth/gemma-2-2b-it-bnb-4bit\" if USE_UNSLOTH else \"google/gemma-2-2b-it\"}\n",
    "- 参数量: {model.num_parameters():,}\n",
    "\n",
    "## 模型加载示例\n",
    "\n",
    "```python\n",
    "{\"# 使用Unsloth加载\" if USE_UNSLOTH else \"# 使用标准transformers加载\"}\n",
    "{\"from unsloth import FastLanguageModel\" if USE_UNSLOTH else \"from transformers import AutoModelForCausalLM, AutoTokenizer\"}\n",
    "\n",
    "{\"model, tokenizer = FastLanguageModel.from_pretrained('./portfolio_complete')\" if USE_UNSLOTH else '''\n",
    "model = AutoModelForCausalLM.from_pretrained('./portfolio_complete')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./portfolio_complete')\n",
    "'''}\n",
    "```\n",
    "\n",
    "## 使用示例\n",
    "\n",
    "```python\n",
    "# 构建投资查询\n",
    "prompt = '''\n",
    "你是一位专业的投资组合管理专家。请根据提供的市场数据和技术指标，为投资者提供投资建议。\n",
    "\n",
    "日期: 2025-09-26\n",
    "市场数据:\n",
    "AAPL: 价格$225.50, 日涨跌+1.2%, 相对20日均线+3.5%\n",
    "TSLA: 价格$245.60, 日涨跌-2.3%, 相对20日均线-6.8%\n",
    "...\n",
    "\n",
    "请分析当前市场情况并给出MAG7股票的投资组合权重建议。\n",
    "\n",
    "请按以下格式回答：\n",
    "<reasoning>\n",
    "详细分析市场情况、技术指标和投资逻辑...\n",
    "</reasoning>\n",
    "<answer>\n",
    "具体的投资组合权重建议（JSON格式）\n",
    "</answer>\n",
    "'''\n",
    "\n",
    "# 生成建议\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(\n",
    "    **inputs, \n",
    "    max_new_tokens=512, \n",
    "    temperature=0.7, \n",
    "    do_sample=True\n",
    ")\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "## 注意事项\n",
    "⚠️ 本模型仅用于教育和研究目的，不构成投资建议。\n",
    "⚠️ 实际投资决策应咨询专业金融顾问。\n",
    "⚠️ 市场有风险，投资需谨慎。\n",
    "\"\"\"\n",
    "\n",
    "with open(\"MODEL_USAGE_GUIDE.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(usage_guide)\n",
    "\n",
    "print(\"\\n📖 使用指南已创建: MODEL_USAGE_GUIDE.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799af38",
   "metadata": {},
   "source": [
    "## 11. 总结和后续改进方向\n",
    "\n",
    "### 🎯 项目成果\n",
    "\n",
    "1. **强化学习模型**: 成功使用GRPO方法训练Gemma 1B模型进行投资组合优化\n",
    "2. **多维度奖励函数**: 综合考虑投资收益、权重合理性、推理质量和格式正确性\n",
    "3. **真实数据训练**: 基于MAG7股票的实际市场数据生成训练样本\n",
    "4. **结构化输出**: 模型能够生成包含推理过程和具体权重的投资建议\n",
    "\n",
    "### 📈 核心特性\n",
    "\n",
    "- **数据驱动**: 基于20年历史数据的技术指标分析\n",
    "- **风险意识**: 奖励函数鼓励权重分散和风险控制\n",
    "- **可解释性**: 要求模型提供详细的投资推理过程\n",
    "- **实时适应**: 能够根据当前市场状况调整投资策略\n",
    "\n",
    "### 🔄 改进方向\n",
    "\n",
    "1. **扩大数据集**: 增加更多样本和时间段\n",
    "2. **优化奖励函数**: 加入更多金融指标（如夏普比率、最大回撤）\n",
    "3. **模型集成**: 结合多个模型的预测结果\n",
    "4. **实时更新**: 集成实时市场数据API\n",
    "5. **风险管理**: 添加更严格的风险控制机制\n",
    "\n",
    "### ⚠️ 使用声明\n",
    "\n",
    "**本模型仅用于教育和研究目的，不构成投资建议。实际投资决策应咨询专业金融顾问。**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaojiucai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
