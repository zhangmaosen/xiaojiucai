{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8147c599",
   "metadata": {},
   "source": [
    "# 基于TimesFM预训练模型的投资组合优化\n",
    "\n",
    "本教程演示如何使用Google Research的TimesFM预训练模型来进行投资组合优化。TimesFM是一个在大规模金融时间序列数据上进行预训练的模型，可能会带来比传统深度学习模型更好的性能。\n",
    "\n",
    "## 本教程包括：\n",
    "\n",
    "1. 数据准备和预处理\n",
    "2. TimesFM模型设置和配置\n",
    "3. 模型训练和优化过程\n",
    "4. 性能评估和可视化分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059873cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "# 添加项目根目录到Python路径\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# 导入必要的库\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import timesfm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 设置随机种子以保证可重复性\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置绘图样式\n",
    "plt.style.use('default')  # 使用默认样式\n",
    "sns.set_style(\"whitegrid\")  # 使用seaborn的网格样式\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'WenQuanYi Micro Hei']\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 正常显示负号\n",
    "\n",
    "# 检查GPU是否可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281dfef",
   "metadata": {},
   "source": [
    "## 数据准备和预处理\n",
    "\n",
    "首先，我们需要加载和处理金融数据。我们使用Magnificent 7（AAPL、AMZN、GOOGL、META、MSFT、NVDA、TSLA）的每日收盘价数据，并计算对数回报率用于模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff4cdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据形状: (5027, 35)\n",
      "\n",
      "前5行数据:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Close</th>\n",
       "      <th colspan=\"3\" halign=\"left\">High</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>...</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-09-26</th>\n",
       "      <td>1.616283</td>\n",
       "      <td>2.1670</td>\n",
       "      <td>7.810992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.601694</td>\n",
       "      <td>0.251990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.637897</td>\n",
       "      <td>2.1710</td>\n",
       "      <td>7.976766</td>\n",
       "      <td>...</td>\n",
       "      <td>17.692244</td>\n",
       "      <td>0.251838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>546562800</td>\n",
       "      <td>112328000</td>\n",
       "      <td>395380224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56203700</td>\n",
       "      <td>406776000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-27</th>\n",
       "      <td>1.604275</td>\n",
       "      <td>2.1580</td>\n",
       "      <td>7.802541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.650463</td>\n",
       "      <td>0.252831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.628291</td>\n",
       "      <td>2.1865</td>\n",
       "      <td>7.913637</td>\n",
       "      <td>...</td>\n",
       "      <td>17.671360</td>\n",
       "      <td>0.253060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341703600</td>\n",
       "      <td>83470000</td>\n",
       "      <td>274649076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48797900</td>\n",
       "      <td>404160000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-28</th>\n",
       "      <td>1.533428</td>\n",
       "      <td>2.1685</td>\n",
       "      <td>7.605204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.880327</td>\n",
       "      <td>0.254360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.594369</td>\n",
       "      <td>2.1870</td>\n",
       "      <td>7.831371</td>\n",
       "      <td>...</td>\n",
       "      <td>17.685294</td>\n",
       "      <td>0.253595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1125544000</td>\n",
       "      <td>64794000</td>\n",
       "      <td>319576104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71019400</td>\n",
       "      <td>353556000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-29</th>\n",
       "      <td>1.571253</td>\n",
       "      <td>2.2395</td>\n",
       "      <td>7.695174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.068390</td>\n",
       "      <td>0.259632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.578758</td>\n",
       "      <td>2.2400</td>\n",
       "      <td>7.722513</td>\n",
       "      <td>...</td>\n",
       "      <td>17.838530</td>\n",
       "      <td>0.254436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>636846000</td>\n",
       "      <td>127856000</td>\n",
       "      <td>224327448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66807100</td>\n",
       "      <td>513372000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>1.609379</td>\n",
       "      <td>2.2650</td>\n",
       "      <td>7.865171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.922119</td>\n",
       "      <td>0.261924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.610579</td>\n",
       "      <td>2.2920</td>\n",
       "      <td>7.891019</td>\n",
       "      <td>...</td>\n",
       "      <td>18.047498</td>\n",
       "      <td>0.259784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>531633200</td>\n",
       "      <td>121120000</td>\n",
       "      <td>365685948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57644500</td>\n",
       "      <td>458832000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price          Close                                                   \\\n",
       "Ticker          AAPL    AMZN     GOOGL META       MSFT      NVDA TSLA   \n",
       "Date                                                                    \n",
       "2005-09-26  1.616283  2.1670  7.810992  NaN  17.601694  0.251990  NaN   \n",
       "2005-09-27  1.604275  2.1580  7.802541  NaN  17.650463  0.252831  NaN   \n",
       "2005-09-28  1.533428  2.1685  7.605204  NaN  17.880327  0.254360  NaN   \n",
       "2005-09-29  1.571253  2.2395  7.695174  NaN  18.068390  0.259632  NaN   \n",
       "2005-09-30  1.609379  2.2650  7.865171  NaN  17.922119  0.261924  NaN   \n",
       "\n",
       "Price           High                    ...       Open                 \\\n",
       "Ticker          AAPL    AMZN     GOOGL  ...       MSFT      NVDA TSLA   \n",
       "Date                                    ...                             \n",
       "2005-09-26  1.637897  2.1710  7.976766  ...  17.692244  0.251838  NaN   \n",
       "2005-09-27  1.628291  2.1865  7.913637  ...  17.671360  0.253060  NaN   \n",
       "2005-09-28  1.594369  2.1870  7.831371  ...  17.685294  0.253595  NaN   \n",
       "2005-09-29  1.578758  2.2400  7.722513  ...  17.838530  0.254436  NaN   \n",
       "2005-09-30  1.610579  2.2920  7.891019  ...  18.047498  0.259784  NaN   \n",
       "\n",
       "Price           Volume                                                       \n",
       "Ticker            AAPL       AMZN      GOOGL META      MSFT       NVDA TSLA  \n",
       "Date                                                                         \n",
       "2005-09-26   546562800  112328000  395380224  NaN  56203700  406776000  NaN  \n",
       "2005-09-27   341703600   83470000  274649076  NaN  48797900  404160000  NaN  \n",
       "2005-09-28  1125544000   64794000  319576104  NaN  71019400  353556000  NaN  \n",
       "2005-09-29   636846000  127856000  224327448  NaN  66807100  513372000  NaN  \n",
       "2005-09-30   531633200  121120000  365685948  NaN  57644500  458832000  NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "回报率数据形状: (5027, 35)\n",
      "\n",
      "回报率统计描述:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Close</th>\n",
       "      <th colspan=\"3\" halign=\"left\">High</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>...</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>-0.000505</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>-0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020171</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.031735</td>\n",
       "      <td>0.016896</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.031687</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.315320</td>\n",
       "      <td>0.358852</td>\n",
       "      <td>0.344308</td>\n",
       "      <td>0.299433</td>\n",
       "      <td>0.328122</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.345840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.197470</td>\n",
       "      <td>-0.246182</td>\n",
       "      <td>-0.123685</td>\n",
       "      <td>-0.306391</td>\n",
       "      <td>-0.159453</td>\n",
       "      <td>-0.367109</td>\n",
       "      <td>-0.236518</td>\n",
       "      <td>-0.133407</td>\n",
       "      <td>-0.163759</td>\n",
       "      <td>-0.094297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113241</td>\n",
       "      <td>-0.362972</td>\n",
       "      <td>-0.236893</td>\n",
       "      <td>-1.772503</td>\n",
       "      <td>-1.564264</td>\n",
       "      <td>-1.503236</td>\n",
       "      <td>-1.568648</td>\n",
       "      <td>-1.655370</td>\n",
       "      <td>-1.523006</td>\n",
       "      <td>-1.591503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.008299</td>\n",
       "      <td>-0.009947</td>\n",
       "      <td>-0.007992</td>\n",
       "      <td>-0.003911</td>\n",
       "      <td>-0.007260</td>\n",
       "      <td>-0.013709</td>\n",
       "      <td>-0.009642</td>\n",
       "      <td>-0.007373</td>\n",
       "      <td>-0.008506</td>\n",
       "      <td>-0.006889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007400</td>\n",
       "      <td>-0.014021</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>-0.201169</td>\n",
       "      <td>-0.213745</td>\n",
       "      <td>-0.214204</td>\n",
       "      <td>-0.121572</td>\n",
       "      <td>-0.195340</td>\n",
       "      <td>-0.220339</td>\n",
       "      <td>-0.164003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.018566</td>\n",
       "      <td>-0.023368</td>\n",
       "      <td>-0.019741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014108</td>\n",
       "      <td>-0.020866</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.011389</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.016843</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.017539</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.186015</td>\n",
       "      <td>0.196449</td>\n",
       "      <td>0.204982</td>\n",
       "      <td>0.079992</td>\n",
       "      <td>0.186077</td>\n",
       "      <td>0.203763</td>\n",
       "      <td>0.122216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.142617</td>\n",
       "      <td>0.238621</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.259371</td>\n",
       "      <td>0.170626</td>\n",
       "      <td>0.260876</td>\n",
       "      <td>0.218292</td>\n",
       "      <td>0.119419</td>\n",
       "      <td>0.240213</td>\n",
       "      <td>0.175872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131589</td>\n",
       "      <td>0.243083</td>\n",
       "      <td>0.305547</td>\n",
       "      <td>1.806734</td>\n",
       "      <td>1.925267</td>\n",
       "      <td>1.790403</td>\n",
       "      <td>2.090365</td>\n",
       "      <td>1.978840</td>\n",
       "      <td>1.570406</td>\n",
       "      <td>2.498770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price         Close                                                      \\\n",
       "Ticker         AAPL         AMZN        GOOGL         META         MSFT   \n",
       "count   5027.000000  5027.000000  5027.000000  5027.000000  5027.000000   \n",
       "mean       0.000993     0.000929     0.000691     0.000601     0.000669   \n",
       "std        0.020171     0.023704     0.018871     0.020506     0.017262   \n",
       "min       -0.197470    -0.246182    -0.123685    -0.306391    -0.159453   \n",
       "25%       -0.008299    -0.009947    -0.007992    -0.003911    -0.007260   \n",
       "50%        0.001000     0.000707     0.000790     0.000000     0.000588   \n",
       "75%        0.011389     0.012336     0.009885     0.005970     0.009117   \n",
       "max        0.142617     0.238621     0.182251     0.259371     0.170626   \n",
       "\n",
       "Price                                    High                            ...  \\\n",
       "Ticker         NVDA         TSLA         AAPL         AMZN        GOOGL  ...   \n",
       "count   5027.000000  5027.000000  5027.000000  5027.000000  5027.000000  ...   \n",
       "mean       0.001303     0.001107     0.000993     0.000931     0.000688  ...   \n",
       "std        0.030977     0.031735     0.016896     0.021385     0.016443  ...   \n",
       "min       -0.367109    -0.236518    -0.133407    -0.163759    -0.094297  ...   \n",
       "25%       -0.013709    -0.009642    -0.007373    -0.008506    -0.006889  ...   \n",
       "50%        0.001625     0.000000     0.001028     0.000389     0.000651  ...   \n",
       "75%        0.016843     0.012933     0.009150     0.009776     0.008323  ...   \n",
       "max        0.260876     0.218292     0.119419     0.240213     0.175872  ...   \n",
       "\n",
       "Price          Open                                 Volume               \\\n",
       "Ticker         MSFT         NVDA         TSLA         AAPL         AMZN   \n",
       "count   5027.000000  5027.000000  5027.000000  5027.000000  5027.000000   \n",
       "mean       0.000669     0.001301     0.001159    -0.000500    -0.000216   \n",
       "std        0.016409     0.031687     0.032917     0.315320     0.358852   \n",
       "min       -0.113241    -0.362972    -0.236893    -1.772503    -1.564264   \n",
       "25%       -0.007400    -0.014021    -0.010492    -0.201169    -0.213745   \n",
       "50%        0.000829     0.001411     0.000000    -0.018566    -0.023368   \n",
       "75%        0.008963     0.017539     0.013172     0.186015     0.196449   \n",
       "max        0.131589     0.243083     0.305547     1.806734     1.925267   \n",
       "\n",
       "Price                                                                    \n",
       "Ticker        GOOGL         META         MSFT         NVDA         TSLA  \n",
       "count   5027.000000  5027.000000  5027.000000  5027.000000  5027.000000  \n",
       "mean      -0.000505    -0.000788    -0.000217    -0.000150    -0.000227  \n",
       "std        0.344308     0.299433     0.328122     0.356322     0.345840  \n",
       "min       -1.503236    -1.568648    -1.655370    -1.523006    -1.591503  \n",
       "25%       -0.214204    -0.121572    -0.195340    -0.220339    -0.164003  \n",
       "50%       -0.019741     0.000000    -0.014108    -0.020866     0.000000  \n",
       "75%        0.204982     0.079992     0.186077     0.203763     0.122216  \n",
       "max        1.790403     2.090365     1.978840     1.570406     2.498770  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载原始数据\n",
    "data_raw = pd.read_parquet('../data/mag7_data_raw.parquet')\n",
    "print(\"数据形状:\", data_raw.shape)\n",
    "print(\"\\n前5行数据:\")\n",
    "display(data_raw.head())\n",
    "\n",
    "# 计算对数回报率\n",
    "close_prices = data_raw\n",
    "returns = np.log(close_prices / close_prices.shift(1))\n",
    "\n",
    "# 处理NaN值\n",
    "returns.iloc[0] = 0  # 第一天的回报率设为0\n",
    "returns = returns.ffill()  # 用前一个有效值填充其他NaN\n",
    "returns = returns.bfill()  # 如果数据开头有NaN，用后一个有效值填充\n",
    "\n",
    "print(\"\\n回报率数据形状:\", returns.shape)\n",
    "print(\"\\n回报率统计描述:\")\n",
    "display(returns.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e5918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据形状: (5007, 20, 35)\n",
      "目标数据形状: (5007, 35)\n",
      "\n",
      "数据集大小:\n",
      "训练集: 3204 样本 (64.0%)\n",
      "验证集: 801 样本 (16.0%)\n",
      "测试集: 1002 样本 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "# 创建训练数据序列\n",
    "def create_sequences(data, window_size=20):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(data) - window_size):\n",
    "        sequence = data.iloc[i:i+window_size].values\n",
    "        target = data.iloc[i+window_size].values\n",
    "        sequences.append(sequence)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# 创建训练数据\n",
    "window_size = 20\n",
    "X, y = create_sequences(returns, window_size)\n",
    "print(\"输入数据形状:\", X.shape)  # (样本数, 时间步长, 特征数)\n",
    "print(\"目标数据形状:\", y.shape)  # (样本数, 特征数)\n",
    "\n",
    "# 将数据转换为PyTorch张量\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.FloatTensor(y)\n",
    "\n",
    "# 分割数据集\n",
    "train_val_size = int(0.8 * len(X))\n",
    "train_size = int(0.8 * train_val_size)\n",
    "X_test = X_tensor[train_val_size:]\n",
    "y_test = y_tensor[train_val_size:]\n",
    "X_train = X_tensor[:train_size]\n",
    "y_train = y_tensor[:train_size]\n",
    "X_val = X_tensor[train_size:train_val_size]\n",
    "y_val = y_tensor[train_size:train_val_size]\n",
    "\n",
    "# 将数据移至GPU（如果可用）\n",
    "if torch.cuda.is_available():\n",
    "    X_train = X_train.cuda()\n",
    "    y_train = y_train.cuda()\n",
    "    X_val = X_val.cuda()\n",
    "    y_val = y_val.cuda()\n",
    "    X_test = X_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(\"\\n数据集大小:\")\n",
    "print(f\"训练集: {len(X_train)} 样本 ({len(X_train)/len(X_tensor):.1%})\")\n",
    "print(f\"验证集: {len(X_val)} 样本 ({len(X_val)/len(X_tensor):.1%})\")\n",
    "print(f\"测试集: {len(X_test)} 样本 ({len(X_test)/len(X_tensor):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00485e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X shape: torch.Size([32, 20, 35])\n",
      "Batch y shape: torch.Size([32, 35])\n"
     ]
    }
   ],
   "source": [
    "#从train_loader中读取一个batch的数据\n",
    "for batch_X, batch_y in train_loader:\n",
    "    print(\"Batch X shape:\", batch_X.shape)  # (batch_size, window_size, num_features)\n",
    "    print(\"Batch y shape:\", batch_y.shape)  # (batch_size, num_features)\n",
    "    break  # 只查看第一个batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244abd24",
   "metadata": {},
   "source": [
    "## TimesFM模型设置\n",
    "\n",
    "我们使用Google Research的TimesFM预训练模型作为特征提取器，并在其基础上构建一个投资组合优化模型。模型架构包含以下几个部分：\n",
    "\n",
    "1. TimesFM预训练模型作为特征提取器\n",
    "2. 投资组合优化头部网络\n",
    "3. Softmax层确保权重和为1且非负"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "052b8b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编译TimesFM模型...\n",
      "TimesFM模型编译完成！\n",
      "TimesFMPortfolioModel(\n",
      "  (timesfm_model): TimesFM_2p5_200M_torch_module(\n",
      "    (tokenizer): ResidualBlock(\n",
      "      (hidden_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
      "      (output_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (residual_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
      "      (activation): SiLU()\n",
      "    )\n",
      "    (stacked_xf): ModuleList(\n",
      "      (0-19): 20 x Transformer(\n",
      "        (pre_attn_ln): RMSNorm()\n",
      "        (post_attn_ln): RMSNorm()\n",
      "        (attn): MultiHeadAttention(\n",
      "          (query): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (value): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (out): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "          (query_ln): RMSNorm()\n",
      "          (key_ln): RMSNorm()\n",
      "          (rotary_position_embedding): RotaryPositionalEmbedding()\n",
      "          (per_dim_scale): PerDimScale()\n",
      "        )\n",
      "        (pre_ff_ln): RMSNorm()\n",
      "        (post_ff_ln): RMSNorm()\n",
      "        (ff0): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (ff1): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "        (activation): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (output_projection_point): ResidualBlock(\n",
      "      (hidden_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (output_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (residual_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (activation): SiLU()\n",
      "    )\n",
      "    (output_projection_quantiles): ResidualBlock(\n",
      "      (hidden_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "      (output_layer): Linear(in_features=1280, out_features=10240, bias=False)\n",
      "      (residual_layer): Linear(in_features=1280, out_features=10240, bias=False)\n",
      "      (activation): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (portfolio_head): Sequential(\n",
      "    (0): Linear(in_features=35, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=35, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 创建TimesFM模型\n",
    "timesfm_model = timesfm.TimesFM_2p5_200M_torch()\n",
    "\n",
    "# 配置并编译模型\n",
    "print(\"编译TimesFM模型...\")\n",
    "forecast_config =  timesfm.ForecastConfig(\n",
    "        max_context=1024,\n",
    "        max_horizon=256,\n",
    "        normalize_inputs=True,\n",
    "        use_continuous_quantile_head=True,\n",
    "        force_flip_invariance=True,\n",
    "        infer_is_positive=True,\n",
    "        fix_quantile_crossing=True,\n",
    "    )\n",
    "\n",
    "timesfm_model.compile(forecast_config=forecast_config)\n",
    "print(\"TimesFM模型编译完成！\")\n",
    "\n",
    "# 创建投资组合优化模型\n",
    "class TimesFMPortfolioModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, timesfm_model: timesfm.TimesFM_2p5_200M_torch, context_len):\n",
    "        super(TimesFMPortfolioModel, self).__init__()\n",
    "        self.timesfm = timesfm_model\n",
    "        self.context_len = context_len\n",
    "        self.timesfm_model = timesfm_model.model\n",
    "        # 冻结TimesFM的参数\n",
    "        for param in self.timesfm.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # 投资组合优化头部网络\n",
    "        # 输入是每个资产的预测收益率，所以维度是 input_size\n",
    "        self.portfolio_head = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, output_size)\n",
    "        )\n",
    "        \n",
    "        # Softmax层确保权重和为1且非负\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x的形状: (batch_size, context_len, num_assets)\n",
    "        batch_size, _, num_assets = x.shape\n",
    "        \n",
    "        # 存储每个资产的预测收益\n",
    "        forecasts = []\n",
    "        \n",
    "        # 我们想要预测未来1期的收益\n",
    "        forecast_horizon = 1\n",
    "        \n",
    "        for i in range(num_assets):\n",
    "            # 获取单个资产的时间序列，形状: (batch_size, context_len)\n",
    "            asset_series = x[:, :, i]\n",
    "            asset_series = asset_series.cpu().numpy()\n",
    "            # 使用forecast进行预测\n",
    "            # forecast返回 (point_forecast, low_quantile, high_quantile)\n",
    "            point_forecast, _ = self.timesfm.forecast(\n",
    "                horizon=forecast_horizon,\n",
    "                inputs=asset_series\n",
    "            )\n",
    "            \n",
    "            # point_forecast 形状: (batch_size, forecast_horizon)\n",
    "            # 我们只关心这个预测值\n",
    "            forecasts.append(point_forecast)\n",
    "        # convert list of forecasts to a single tensor\n",
    "        combined_forecasts = torch.stack([torch.tensor(f).squeeze() for f in forecasts], dim=1).to(device)\n",
    "        # 将所有资产的预测连接起来，形状: (batch_size, num_assets)\n",
    "        #combined_forecasts = torch.cat(forecasts, dim=1)\n",
    "        \n",
    "        # 通过头部网络得到权重\n",
    "        weights = self.portfolio_head(combined_forecasts)\n",
    "        \n",
    "        # 应用Softmax得到最终的投资组合权重\n",
    "        weights = self.softmax(weights)\n",
    "        \n",
    "        return weights\n",
    "\n",
    "# 初始化模型\n",
    "input_size = X.shape[2]  # 特征数（股票数量）\n",
    "output_size = input_size  # 输出权重的维度与股票数量相同\n",
    "timesfm_portfolio_model = TimesFMPortfolioModel(input_size, output_size, timesfm_model, window_size).to(device)\n",
    "print(timesfm_portfolio_model)\n",
    "\n",
    "# 定义投资组合损失函数\n",
    "def portfolio_loss(weights, returns, risk_aversion=1.0):\n",
    "    # 计算投资组合收益\n",
    "    portfolio_return = torch.sum(weights * returns, dim=1)\n",
    "    \n",
    "    # 计算平均收益\n",
    "    expected_return = torch.mean(portfolio_return)\n",
    "    \n",
    "    # 计算风险（使用样本标准差的平方而不是方差）\n",
    "    epsilon = 1e-8\n",
    "    portfolio_risk = torch.mean((portfolio_return - expected_return) ** 2) + epsilon\n",
    "    \n",
    "    # 风险调整后的收益（负号是因为我们要最大化收益，而优化器是最小化损失）\n",
    "    loss = -(expected_return - risk_aversion * portfolio_risk)\n",
    "    \n",
    "    # 添加正则化项以防止权重过于集中\n",
    "    weight_regularization = torch.mean(torch.sum(weights ** 2, dim=1))\n",
    "    regularization_factor = 0.01\n",
    "    loss = loss + regularization_factor * weight_regularization\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 定义优化器和学习率\n",
    "optimizer = torch.optim.Adam(timesfm_portfolio_model.parameters(), lr=0.0001)\n",
    "risk_aversion = 5.0  # 风险厌恶系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec36929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimesFM Portfolio Model 参数设备分布:\n",
      "==================================================\n",
      "timesfm_model.tokenizer.hidden_layer.weight: cuda:0\n",
      "timesfm_model.tokenizer.hidden_layer.bias: cuda:0\n",
      "timesfm_model.tokenizer.output_layer.weight: cuda:0\n",
      "timesfm_model.tokenizer.output_layer.bias: cuda:0\n",
      "timesfm_model.tokenizer.residual_layer.weight: cuda:0\n",
      "timesfm_model.tokenizer.residual_layer.bias: cuda:0\n",
      "timesfm_model.stacked_xf.0.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.0.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.0.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.0.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.0.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.0.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.0.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.0.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.0.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.0.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.0.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.0.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.0.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.1.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.1.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.1.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.1.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.1.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.1.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.1.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.1.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.1.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.1.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.1.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.1.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.1.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.2.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.2.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.2.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.2.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.2.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.2.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.2.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.2.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.2.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.2.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.2.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.2.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.2.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.3.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.3.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.3.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.3.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.3.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.3.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.3.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.3.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.3.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.3.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.3.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.3.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.3.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.4.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.4.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.4.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.4.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.4.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.4.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.4.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.4.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.4.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.4.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.4.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.4.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.4.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.5.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.5.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.5.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.5.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.5.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.5.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.5.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.5.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.5.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.5.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.5.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.5.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.5.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.6.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.6.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.6.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.6.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.6.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.6.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.6.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.6.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.6.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.6.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.6.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.6.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.6.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.7.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.7.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.7.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.7.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.7.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.7.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.7.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.7.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.7.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.7.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.7.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.7.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.7.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.8.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.8.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.8.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.8.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.8.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.8.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.8.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.8.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.8.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.8.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.8.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.8.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.8.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.9.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.9.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.9.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.9.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.9.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.9.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.9.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.9.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.9.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.9.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.9.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.9.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.9.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.10.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.10.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.10.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.10.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.10.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.10.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.10.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.10.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.10.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.10.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.10.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.10.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.10.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.11.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.11.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.11.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.11.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.11.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.11.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.11.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.11.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.11.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.11.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.11.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.11.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.11.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.12.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.12.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.12.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.12.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.12.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.12.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.12.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.12.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.12.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.12.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.12.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.12.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.12.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.13.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.13.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.13.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.13.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.13.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.13.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.13.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.13.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.13.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.13.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.13.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.13.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.13.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.14.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.14.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.14.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.14.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.14.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.14.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.14.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.14.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.14.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.14.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.14.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.14.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.14.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.15.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.15.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.15.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.15.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.15.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.15.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.15.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.15.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.15.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.15.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.15.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.15.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.15.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.16.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.16.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.16.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.16.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.16.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.16.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.16.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.16.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.16.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.16.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.16.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.16.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.16.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.17.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.17.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.17.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.17.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.17.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.17.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.17.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.17.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.17.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.17.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.17.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.17.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.17.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.18.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.18.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.18.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.18.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.18.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.18.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.18.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.18.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.18.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.18.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.18.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.18.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.18.ff1.weight: cuda:0\n",
      "timesfm_model.stacked_xf.19.pre_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.19.post_attn_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.19.attn.query.weight: cuda:0\n",
      "timesfm_model.stacked_xf.19.attn.key.weight: cuda:0\n",
      "timesfm_model.stacked_xf.19.attn.value.weight: cuda:0\n",
      "timesfm_model.stacked_xf.19.attn.out.weight: cuda:0\n",
      "timesfm_model.stacked_xf.19.attn.query_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.19.attn.key_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.19.attn.per_dim_scale.per_dim_scale: cuda:0\n",
      "timesfm_model.stacked_xf.19.pre_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.19.post_ff_ln.scale: cuda:0\n",
      "timesfm_model.stacked_xf.19.ff0.weight: cuda:0\n",
      "timesfm_model.stacked_xf.19.ff1.weight: cuda:0\n",
      "timesfm_model.output_projection_point.hidden_layer.weight: cuda:0\n",
      "timesfm_model.output_projection_point.output_layer.weight: cuda:0\n",
      "timesfm_model.output_projection_point.residual_layer.weight: cuda:0\n",
      "timesfm_model.output_projection_quantiles.hidden_layer.weight: cuda:0\n",
      "timesfm_model.output_projection_quantiles.output_layer.weight: cuda:0\n",
      "timesfm_model.output_projection_quantiles.residual_layer.weight: cuda:0\n",
      "portfolio_head.0.weight: cuda:0\n",
      "portfolio_head.0.bias: cuda:0\n",
      "portfolio_head.3.weight: cuda:0\n",
      "portfolio_head.3.bias: cuda:0\n",
      "\n",
      "==================================================\n",
      "模型整体设备: cuda:0\n",
      "\n",
      "模型子模块设备检查:\n",
      "------------------------------\n",
      "timesfm_model: cuda:0\n",
      "portfolio_head: cuda:0\n",
      "softmax: No parameters\n"
     ]
    }
   ],
   "source": [
    "# 检查模型参数所在的设备\n",
    "print(\"TimesFM Portfolio Model 参数设备分布:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 检查模型的各个组件\n",
    "for name, param in timesfm_portfolio_model.named_parameters():\n",
    "    print(f\"{name}: {param.device}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"模型整体设备: {next(timesfm_portfolio_model.parameters()).device}\")\n",
    "\n",
    "# 检查模型的子模块\n",
    "print(\"\\n模型子模块设备检查:\")\n",
    "print(\"-\" * 30)\n",
    "for name, module in timesfm_portfolio_model.named_children():\n",
    "    if hasattr(module, 'parameters'):\n",
    "        devices = [p.device for p in module.parameters()]\n",
    "        print(f\"{name}: {devices[0] if devices else 'No parameters'}\")\n",
    "    else:\n",
    "        print(f\"{name}: Non-parameter module\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076eab8c",
   "metadata": {},
   "source": [
    "## 模型训练和优化\n",
    "\n",
    "我们现在开始训练模型。训练过程包括：\n",
    "\n",
    "1. 在训练集上进行梯度下降优化\n",
    "2. 在验证集上评估模型性能\n",
    "3. 使用早停机制防止过拟合\n",
    "4. 保存最佳模型状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf259f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始在 cuda 上训练模型...\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "patience = 15\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"开始在 {device} 上训练模型...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    timesfm_portfolio_model.train()\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # 确保数据在正确的设备上\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        weights = timesfm_portfolio_model(batch_X)\n",
    "        loss = portfolio_loss(weights, batch_y, risk_aversion=risk_aversion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    epoch_train_loss /= len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "    # 验证阶段\n",
    "    timesfm_portfolio_model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            weights = timesfm_portfolio_model(batch_X)\n",
    "            loss = portfolio_loss(weights, batch_y, risk_aversion=risk_aversion)\n",
    "            epoch_val_loss += loss.item()\n",
    "    \n",
    "    epoch_val_loss /= len(val_loader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    \n",
    "    # 早停检查\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_model_state = timesfm_portfolio_model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(f'早停: 验证损失在 {patience} 个epoch内没有改善')\n",
    "        break\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {epoch_train_loss:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}')\n",
    "\n",
    "# 加载最佳模型状态\n",
    "if best_model_state is not None:\n",
    "    timesfm_portfolio_model.load_state_dict(best_model_state)\n",
    "    print(f'\\n已恢复最佳模型（验证损失: {best_val_loss:.4f}）')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a090402",
   "metadata": {},
   "source": [
    "## 模型评估和可视化\n",
    "\n",
    "现在让我们在测试集上评估模型的性能，并可视化以下内容：\n",
    "\n",
    "1. 训练过程中的损失变化\n",
    "2. 投资组合权重的动态变化\n",
    "3. 累积收益曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02934345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练和验证损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='训练损失')\n",
    "plt.plot(val_losses, label='验证损失')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('损失')\n",
    "plt.title('训练和验证损失随时间的变化')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 在测试集上评估模型\n",
    "timesfm_portfolio_model.eval()\n",
    "test_predictions = []\n",
    "test_losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        weights = timesfm_portfolio_model(batch_X)\n",
    "        loss = portfolio_loss(weights, batch_y, risk_aversion=risk_aversion)\n",
    "        test_predictions.append(weights.cpu())\n",
    "        test_losses.append(loss.item())\n",
    "\n",
    "# 将预测结果转换为numpy数组\n",
    "test_predictions = torch.cat(test_predictions, dim=0).numpy()\n",
    "\n",
    "# 计算测试集上的投资组合表现\n",
    "test_returns = y_test.cpu().numpy()\n",
    "portfolio_returns = np.sum(test_predictions * test_returns, axis=1)\n",
    "\n",
    "# 计算性能指标\n",
    "mean_return = np.mean(portfolio_returns) * 252  # 年化收益率\n",
    "std_return = np.std(portfolio_returns) * np.sqrt(252)  # 年化波动率\n",
    "sharpe_ratio = mean_return / std_return  # 夏普比率\n",
    "\n",
    "print(f\"TimesFM投资组合表现指标:\")\n",
    "print(f\"年化收益率: {mean_return:.2%}\")\n",
    "print(f\"年化波动率: {std_return:.2%}\")\n",
    "print(f\"夏普比率: {sharpe_ratio:.2f}\")\n",
    "\n",
    "# 可视化投资组合权重分配\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.stackplot(range(len(test_predictions)), \n",
    "             test_predictions.T,\n",
    "             labels=returns.columns)\n",
    "plt.xlabel('时间')\n",
    "plt.ylabel('权重')\n",
    "plt.title('TimesFM模型 - 投资组合权重分配随时间的变化')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 绘制累积收益曲线\n",
    "cumulative_returns = np.cumprod(1 + portfolio_returns) - 1\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_returns)\n",
    "plt.xlabel('时间')\n",
    "plt.ylabel('累积收益')\n",
    "plt.title('TimesFM模型 - 投资组合累积收益')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd07f0",
   "metadata": {},
   "source": [
    "## 结果分析\n",
    "\n",
    "我们可以通过以下几个方面分析TimesFM模型的性能：\n",
    "\n",
    "1. 与基准策略（如等权重策略）的对比\n",
    "2. 投资组合权重的稳定性\n",
    "3. 交易成本考虑\n",
    "4. 风险调整后的收益表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算等权重策略的表现\n",
    "equal_weights = np.ones((len(test_returns), len(returns.columns))) / len(returns.columns)\n",
    "equal_weight_returns = np.sum(equal_weights * test_returns, axis=1)\n",
    "\n",
    "# 计算等权重策略的指标\n",
    "ew_mean_return = np.mean(equal_weight_returns) * 252\n",
    "ew_std_return = np.std(equal_weight_returns) * np.sqrt(252)\n",
    "ew_sharpe_ratio = ew_mean_return / ew_std_return\n",
    "\n",
    "# 计算等权重策略的累积收益\n",
    "ew_cumulative_returns = np.cumprod(1 + equal_weight_returns) - 1\n",
    "\n",
    "# 比较性能指标\n",
    "print(\"性能对比（TimesFM vs 等权重）:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'指标':>15} {'TimesFM':>12} {'等权重':>12}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'年化收益率':>15} {mean_return:>12.2%} {ew_mean_return:>12.2%}\")\n",
    "print(f\"{'年化波动率':>15} {std_return:>12.2%} {ew_std_return:>12.2%}\")\n",
    "print(f\"{'夏普比率':>15} {sharpe_ratio:>12.2f} {ew_sharpe_ratio:>12.2f}\")\n",
    "\n",
    "# 绘制累积收益对比\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_returns, label='TimesFM策略')\n",
    "plt.plot(ew_cumulative_returns, label='等权重策略')\n",
    "plt.xlabel('时间')\n",
    "plt.ylabel('累积收益')\n",
    "plt.title('策略收益对比')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 计算换手率\n",
    "def calculate_turnover(weights):\n",
    "    \"\"\"计算每期的换手率\"\"\"\n",
    "    turnover = np.abs(np.diff(weights, axis=0)).sum(axis=1).mean()\n",
    "    return turnover\n",
    "\n",
    "timesfm_turnover = calculate_turnover(test_predictions)\n",
    "equal_weight_turnover = calculate_turnover(equal_weights)\n",
    "\n",
    "print(\"\\n换手率分析:\")\n",
    "print(f\"TimesFM策略换手率: {timesfm_turnover:.4f}\")\n",
    "print(f\"等权重策略换手率: {equal_weight_turnover:.4f}\")\n",
    "\n",
    "# 分析权重集中度\n",
    "def calculate_herfindahl(weights):\n",
    "    \"\"\"计算Herfindahl指数（权重集中度）\"\"\"\n",
    "    return np.mean(np.sum(weights**2, axis=1))\n",
    "\n",
    "timesfm_concentration = calculate_herfindahl(test_predictions)\n",
    "equal_weight_concentration = calculate_herfindahl(equal_weights)\n",
    "\n",
    "print(\"\\n权重集中度分析 (Herfindahl指数):\")\n",
    "print(f\"TimesFM策略集中度: {timesfm_concentration:.4f}\")\n",
    "print(f\"等权重策略集中度: {equal_weight_concentration:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
