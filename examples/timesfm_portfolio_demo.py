"""
TimesFMæŠ•èµ„ç»„åˆä¼˜åŒ– - ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨é‡æ„åçš„xiaojiucaié¡¹ç›®è¿›è¡Œç«¯åˆ°ç«¯çš„æŠ•èµ„ç»„åˆä¼˜åŒ–
"""

import torch
import pandas as pd
import numpy as np
from pathlib import Path

# å¯¼å…¥é‡æ„åçš„xiaojiucaiæ¨¡å—
from xiaojiucai import (
    # æ ¸å¿ƒæ¨¡å‹
    TimesFMPortfolioModel,
    PortfolioLoss,
    
    # æ•°æ®å¤„ç†
    MAG7DataProcessor,
    create_data_loaders,
    calculate_benchmark_portfolios,
    
    # è®­ç»ƒ
    PortfolioTrainer,
    ExperimentManager,
    create_trainer_from_config,
    
    # è¯„ä¼°
    PortfolioEvaluator,
    PortfolioVisualizer
)


def main():
    """ä¸»å‡½æ•° - å®Œæ•´çš„æŠ•èµ„ç»„åˆä¼˜åŒ–æµç¨‹"""
    
    print("ğŸš€ TimesFMæŠ•èµ„ç»„åˆä¼˜åŒ–ç³»ç»Ÿ - é‡æ„ç‰ˆæœ¬æ¼”ç¤º")
    print("=" * 60)
    
    # =================================================================
    # 1. é…ç½®å‚æ•°
    # =================================================================
    
    # èµ„äº§åˆ—è¡¨
    asset_names = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'TSLA', 'META']
    
    # æ•°æ®é…ç½®
    data_config = {
        'data_path': 'data/mag7_data.csv',  # æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´
        'sequence_length': 60,
        'prediction_horizon': 1,
        'train_ratio': 0.7,
        'val_ratio': 0.15
    }
    
    # æ¨¡å‹é…ç½®
    model_config = {
        'input_dim': 4,
        'hidden_dim': 256,
        'num_assets': len(asset_names),
        'num_heads': 8,
        'dropout': 0.1
    }
    
    # è®­ç»ƒé…ç½®
    training_config = {
        'epochs': 20,
        'batch_size': 32,
        'learning_rate': 1e-4,
        'weight_decay': 1e-5,
        'min_lr': 1e-6,
        'patience': 10,
        'gradient_clip': 1.0,
        'validate_every': 1,
        'save_every': 5,
        'model_save_dir': 'models/experiments'
    }
    
    # æŸå¤±å‡½æ•°é…ç½®
    loss_config = {
        'risk_aversion': 1.0,
        'weight_penalty': 0.1
    }
    
    # å®éªŒé…ç½®
    experiment_config = {
        'name': 'timesfm_portfolio_demo',
        'description': 'é‡æ„åçš„TimesFMæŠ•èµ„ç»„åˆä¼˜åŒ–æ¼”ç¤º'
    }
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # =================================================================
    # 2. æ•°æ®å¤„ç†
    # =================================================================
    
    print("\nğŸ“Š å¼€å§‹æ•°æ®å¤„ç†...")
    
    # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
    data_processor = MAG7DataProcessor(asset_names=asset_names)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(data_config['data_path']).exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_config['data_path']}")
        print("è¯·ç¡®ä¿MAG7æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼Œæˆ–ä½¿ç”¨notebookä¸­çš„æ•°æ®åŠ è½½ä»£ç ")
        return
    
    try:
        # åŠ è½½å’Œå¤„ç†æ•°æ®
        raw_df = data_processor.load_data(data_config['data_path'])
        clean_df = data_processor.clean_data(raw_df)
        features_df = data_processor.engineer_features(clean_df)
        
        # è½¬æ¢ä¸ºæ·±åº¦å­¦ä¹ æ ¼å¼
        X, y = data_processor.to_deepdow_format(
            features_df,
            sequence_length=data_config['sequence_length'],
            prediction_horizon=data_config['prediction_horizon']
        )
        
        # æ•°æ®åˆ†å‰²
        train_data, val_data, test_data = data_processor.create_data_splits(
            X, y,
            train_ratio=data_config['train_ratio'],
            val_ratio=data_config['val_ratio']
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = create_data_loaders(
            train_data, val_data, test_data,
            batch_size=training_config['batch_size']
        )
        
        print("âœ… æ•°æ®å¤„ç†å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
        print("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        n_samples = 1000
        X = torch.randn(n_samples, model_config['input_dim'], data_config['sequence_length'], model_config['num_assets'])
        y = torch.randn(n_samples, model_config['num_assets'], data_config['prediction_horizon'])
        
        train_data, val_data, test_data = data_processor.create_data_splits(X, y)
        train_loader, val_loader, test_loader = create_data_loaders(
            train_data, val_data, test_data,
            batch_size=training_config['batch_size']
        )
        
        print("âœ… æ¨¡æ‹Ÿæ•°æ®åˆ›å»ºå®Œæˆ")
    
    # =================================================================
    # 3. æ¨¡å‹åˆ›å»º
    # =================================================================
    
    print("\nğŸ¤– åˆ›å»ºTimesFMæŠ•èµ„ç»„åˆæ¨¡å‹...")
    
    # åˆ›å»ºæ¨¡å‹
    model = TimesFMPortfolioModel(**model_config).to(device)
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    criterion = PortfolioLoss(**loss_config)
    
    print("âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ")
    
    # =================================================================
    # 4. è®­ç»ƒæ¨¡å‹
    # =================================================================
    
    print("\nğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
    
    # åˆ›å»ºè®­ç»ƒå™¨å’Œä¼˜åŒ–å™¨
    trainer, optimizer, scheduler = create_trainer_from_config(
        model, criterion, device, training_config
    )
    
    # è®­ç»ƒæ¨¡å‹
    try:
        history, best_val_loss = trainer.train(
            train_loader=train_loader,
            val_loader=val_loader,
            optimizer=optimizer,
            scheduler=scheduler,
            config=training_config,
            experiment_name=experiment_config['name']
        )
        
        print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"ğŸ“ˆ æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        print("ç»§ç»­ä½¿ç”¨å½“å‰æ¨¡å‹è¿›è¡Œæ¼”ç¤º...")
        history = {'train_loss': [], 'val_loss': [], 'epochs': []}
    
    # =================================================================
    # 5. æ¨¡å‹è¯„ä¼°
    # =================================================================
    
    print("\nğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...")
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = PortfolioEvaluator(asset_names=asset_names)
    
    # è¯„ä¼°æ¨¡å‹
    try:
        evaluation_results = evaluator.evaluate_model(
            model, test_loader, device, criterion
        )
        
        print("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ")
        print(f"ğŸ“Š æµ‹è¯•æŸå¤±: {evaluation_results.get('test_loss', 'N/A')}")
        
        # æ‰“å°å…³é”®æŒ‡æ ‡
        metrics = evaluation_results['metrics']
        print(f"ğŸ“ˆ æŠ•èµ„ç»„åˆå¤æ™®æ¯”ç‡: {metrics['portfolio_sharpe_ratio']:.4f}")
        print(f"âš–ï¸  å¹³å‡æƒé‡é›†ä¸­åº¦: {metrics['avg_weight_concentration']:.4f}")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}")
        evaluation_results = None
    
    # =================================================================
    # 6. å¯è§†åŒ–åˆ†æ
    # =================================================================
    
    print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–åˆ†æ...")
    
    # åˆ›å»ºå¯è§†åŒ–å·¥å…·
    visualizer = PortfolioVisualizer(asset_names=asset_names)
    
    try:
        # è®­ç»ƒå†å²å¯è§†åŒ–
        if history and history['epochs']:
            fig1 = visualizer.plot_training_history(
                history, 
                save_path='outputs/training_history.png'
            )
            print("âœ… è®­ç»ƒå†å²å›¾ç”Ÿæˆå®Œæˆ")
        
        # æƒé‡åˆ†æå¯è§†åŒ–
        if evaluation_results:
            weights = evaluation_results['predictions']['weights']
            fig2 = visualizer.plot_portfolio_weights(
                weights,
                title="TimesFMæ¨¡å‹æƒé‡åˆ†æ",
                save_path='outputs/portfolio_weights.png'
            )
            print("âœ… æƒé‡åˆ†æå›¾ç”Ÿæˆå®Œæˆ")
        
    except Exception as e:
        print(f"âš ï¸ å¯è§†åŒ–ç”Ÿæˆéƒ¨åˆ†å¤±è´¥: {e}")
    
    # =================================================================
    # 7. å®éªŒç®¡ç†
    # =================================================================
    
    print("\nğŸ—‚ï¸  å®éªŒç®¡ç†æ¼”ç¤º...")
    
    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    experiment_manager = ExperimentManager(training_config['model_save_dir'])
    
    try:
        # åˆ—å‡ºæ‰€æœ‰å®éªŒ
        experiments = experiment_manager.list_experiments()
        
        if experiments:
            # è·å–æœ€æ–°å®éªŒçš„æ‘˜è¦
            latest_exp = experiments[-1]
            summary = experiment_manager.get_experiment_summary(latest_exp['path'])
            print(f"ğŸ“‹ æœ€æ–°å®éªŒæ‘˜è¦: {latest_exp['dir_name']}")
            print(f"   æ£€æŸ¥ç‚¹æ•°é‡: {len(summary.get('checkpoints', []))}")
        
    except Exception as e:
        print(f"âš ï¸ å®éªŒç®¡ç†æ¼”ç¤ºå¤±è´¥: {e}")
    
    # =================================================================
    # 8. æ€»ç»“
    # =================================================================
    
    print("\n" + "=" * 60)
    print("ğŸ‰ TimesFMæŠ•èµ„ç»„åˆä¼˜åŒ–ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    
    print("ğŸ“¦ é‡æ„æˆæœ:")
    print("  âœ… æ¨¡å—åŒ–æ¶æ„ - æ¸…æ™°åˆ†ç¦»æ•°æ®å¤„ç†ã€æ¨¡å‹ã€è®­ç»ƒã€è¯„ä¼°")
    print("  âœ… TimesFMé›†æˆ - é¢„è®­ç»ƒæ—¶é—´åºåˆ—æ¨¡å‹ç‰¹å¾æå–")
    print("  âœ… å®Œæ•´è®­ç»ƒæµç¨‹ - è®­ç»ƒã€éªŒè¯ã€ä¿å­˜ã€å®éªŒç®¡ç†")
    print("  âœ… æ€§èƒ½è¯„ä¼° - å¤šç»´åº¦æŒ‡æ ‡åˆ†æå’ŒåŸºå‡†æ¯”è¾ƒ")
    print("  âœ… å¯è§†åŒ–å·¥å…· - è®­ç»ƒå†å²ã€æƒé‡åˆ†æã€æ€§èƒ½æ¯”è¾ƒ")
    print("  âœ… å®éªŒç®¡ç† - ç‰ˆæœ¬æ§åˆ¶ã€æ£€æŸ¥ç‚¹ç®¡ç†ã€é…ç½®è¿½è¸ª")
    
    print("\nğŸ› ï¸  ä¸‹ä¸€æ­¥å»ºè®®:")
    print("  1. ä½¿ç”¨çœŸå®MAG7æ•°æ®è¿›è¡Œå®Œæ•´è®­ç»ƒ")
    print("  2. è°ƒä¼˜è¶…å‚æ•°ä»¥è·å¾—æ›´å¥½æ€§èƒ½")
    print("  3. æ‰©å±•åˆ°æ›´å¤šèµ„äº§å’Œç­–ç•¥")
    print("  4. é›†æˆæ›´å¤šåŸºå‡†ç­–ç•¥è¿›è¡Œæ¯”è¾ƒ")
    print("  5. æ·»åŠ å®æ—¶é¢„æµ‹å’Œéƒ¨ç½²åŠŸèƒ½")


if __name__ == "__main__":
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path("outputs").mkdir(exist_ok=True)
    Path("models/experiments").mkdir(parents=True, exist_ok=True)
    
    # è¿è¡Œä¸»ç¨‹åº
    main()