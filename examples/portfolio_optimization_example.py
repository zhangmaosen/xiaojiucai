#!/usr/bin/env python3
"""
TimesFMæŠ•èµ„ç»„åˆä¼˜åŒ–ç¤ºä¾‹è„šæœ¬

å±•ç¤ºå¦‚ä½•ä½¿ç”¨é‡æ„åçš„å·¥å…·ç±»è¿›è¡ŒæŠ•èµ„ç»„åˆä¼˜åŒ–
"""

import sys
import os
sys.path.insert(0, os.path.abspath('.'))

import torch
import numpy as np

# å¯¼å…¥é¡¹ç›®å·¥å…·ç±»
from xiaojiucai.data import (
    DataProcessor, prepare_data_tensors, create_data_loaders,
    FEATURE_CONFIGS
)
from xiaojiucai.models import create_timesfm_model, TimesFMPortfolioModelV2
from xiaojiucai.losses import portfolio_loss
from xiaojiucai.utils import TrainingConfig, ModelTrainer
from xiaojiucai.visualize import setup_matplotlib_chinese, create_comprehensive_report


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("TimesFMæŠ•èµ„ç»„åˆä¼˜åŒ– - é‡æ„ç‰ˆæœ¬ç¤ºä¾‹")
    print("=" * 60)
    
    # 1. ç¯å¢ƒè®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    torch.manual_seed(42)
    np.random.seed(42)
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 2. æ•°æ®å¤„ç†
    print("\nğŸ“Š æ•°æ®å¤„ç†...")
    processor = DataProcessor(
        selected_features=FEATURE_CONFIGS['close_only'],
        test_mode=True,  # å¯ç”¨æµ‹è¯•æ¨¡å¼ä»¥åŠ å¿«è¿è¡Œ
        test_data_size=600
    )
    
    features_data, returns, tickers = processor.load_and_preprocess('data/mag7_data_raw.parquet')
    
    # 3. åˆ›å»ºè®­ç»ƒæ•°æ®
    print("\nğŸ”§ åˆ›å»ºè®­ç»ƒæ•°æ®...")
    window_size = 100  # æµ‹è¯•æ¨¡å¼ä½¿ç”¨è¾ƒå°çª—å£
    data_dict = prepare_data_tensors(
        features_data, returns, window_size,
        train_ratio=0.8, val_ratio=0.8, device=device
    )
    
    batch_size = 64  # æµ‹è¯•æ¨¡å¼ä½¿ç”¨è¾ƒå°æ‰¹æ¬¡
    train_loader, val_loader, test_loader = create_data_loaders(data_dict, batch_size)
    
    # 4. æ¨¡å‹åˆ›å»º
    print("\nğŸ¤– åˆ›å»ºæ¨¡å‹...")
    timesfm_model, timesfm_wrapper = create_timesfm_model()
    
    portfolio_model = TimesFMPortfolioModelV2(
        input_size=data_dict['input_size'],
        output_size=data_dict['input_size'], 
        feature_size=data_dict['feature_size'],
        timesfm_wrapper=timesfm_wrapper,
        context_len=data_dict['window_size'],
        finetune_timesfm=False  # æµ‹è¯•æ¨¡å¼ä¸å¯ç”¨å¾®è°ƒä»¥åŠ å¿«é€Ÿåº¦
    ).to(device)
    
    # 5. è®­ç»ƒé…ç½®
    print("\nâš™ï¸ é…ç½®è®­ç»ƒå‚æ•°...")
    config = TrainingConfig()
    config.update(
        window_size=window_size,
        batch_size=batch_size,
        num_epochs=5,  # æµ‹è¯•æ¨¡å¼ä½¿ç”¨è¾ƒå°‘epochs
        patience=10,
        finetune_timesfm=False,
        risk_aversion=1.0,
        sharpe_weight=0.5
    )
    
    # 6. æ¨¡å‹è®­ç»ƒ
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    def loss_fn(weights, returns):
        return portfolio_loss(weights, returns, config.risk_aversion, config.sharpe_weight)
    
    trainer = ModelTrainer(
        model=portfolio_model,
        config=config,
        loss_fn=loss_fn,
        device=device,
        model_save_dir='models'
    )
    
    training_results = trainer.train(train_loader, val_loader)
    
    # 7. æ¨¡å‹è¯„ä¼°
    print("\nğŸ“ˆ æ¨¡å‹è¯„ä¼°...")
    portfolio_model.eval()
    test_predictions = []
    
    with torch.no_grad():
        for batch_X, batch_y in test_loader:
            batch_X = batch_X.to(device)
            batch_y = batch_y.to(device)
            weights = portfolio_model(batch_X)
            test_predictions.append(weights.cpu())
    
    test_predictions = torch.cat(test_predictions, dim=0).numpy()
    test_returns = data_dict['y_test'].cpu().numpy()
    portfolio_returns = np.sum(test_predictions * test_returns, axis=1)
    
    # 8. æ˜¾ç¤ºç»“æœ
    print("\nğŸ“Š è®­ç»ƒç»“æœ:")
    print(f"  æœ€ä½³éªŒè¯æŸå¤±: {training_results['best_val_loss']:.4f}")
    print(f"  æŠ•èµ„ç»„åˆå¹³å‡æ”¶ç›Š: {np.mean(portfolio_returns):.4f}")
    print(f"  æŠ•èµ„ç»„åˆæ”¶ç›Šæ³¢åŠ¨: {np.std(portfolio_returns):.4f}")
    print(f"  å¤æ™®æ¯”ç‡: {np.mean(portfolio_returns) / np.std(portfolio_returns):.4f}")
    
    # æ˜¾ç¤ºå¹³å‡æƒé‡åˆ†é…
    avg_weights = np.mean(test_predictions, axis=0)
    print(f"\nğŸ’° å¹³å‡æƒé‡åˆ†é…:")
    for ticker, weight in zip(tickers, avg_weights):
        print(f"  {ticker}: {weight:.3f} ({weight*100:.1f}%)")
    
    print("\nâœ… ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("\nğŸ’¡ æç¤º:")
    print("  - è¦è¿›è¡Œå®Œæ•´è®­ç»ƒï¼Œè¯·åœ¨é…ç½®ä¸­è®¾ç½® test_mode=False")
    print("  - è¦å¯ç”¨TimesFMå¾®è°ƒï¼Œè¯·è®¾ç½® finetune_timesfm=True")
    print("  - è¦æŸ¥çœ‹å¯è§†åŒ–ç»“æœï¼Œè¯·è¿è¡Œnotebookç‰ˆæœ¬")
    
    return training_results


if __name__ == "__main__":
    try:
        results = main()
        print(f"\nğŸ¯ ç¨‹åºæ­£å¸¸ç»“æŸ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)