"""
TimesFMæŠ•èµ„ç»„åˆè®­ç»ƒæ¨¡å—

åŒ…å«æ¨¡å‹è®­ç»ƒã€éªŒè¯ã€ä¿å­˜å’Œå®éªŒç®¡ç†åŠŸèƒ½
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR
import os
import json
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any, Union
import numpy as np
from tqdm import tqdm


class PortfolioTrainer:
    """æŠ•èµ„ç»„åˆæ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model: nn.Module,
        criterion: nn.Module,
        device: torch.device,
        model_save_dir: str = "models/experiments"
    ):
        self.model = model
        self.criterion = criterion
        self.device = device
        self.model_save_dir = model_save_dir
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(model_save_dir, exist_ok=True)
        
    def train_epoch(
        self, 
        train_loader, 
        optimizer, 
        gradient_clip: float = 1.0
    ) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        total_samples = 0
        
        progress_bar = tqdm(train_loader, desc="Training", leave=False)
        for batch_idx, batch in enumerate(progress_bar):
            features = batch[0].to(self.device)
            future_returns = batch[1].squeeze(2).to(self.device)
            future_returns = future_returns[:, -1, :]

            optimizer.zero_grad()
            outputs = self.model(features)
            loss_dict = self.criterion(outputs, future_returns)
            loss = loss_dict['total_loss']
            loss.backward()
            
            if gradient_clip > 0:
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), gradient_clip)
            
            optimizer.step()

            batch_size = features.size(0)
            total_loss += loss.item() * batch_size
            total_samples += batch_size
            
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}', 
                'avg_loss': f'{total_loss/total_samples:.4f}'
            })
            
        return total_loss / total_samples

    def validate_epoch(self, val_loader) -> Tuple[float, Dict[str, float]]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0.0
        total_samples = 0
        all_weights = []
        all_returns = []
        all_risks = []

        with torch.no_grad():
            progress_bar = tqdm(val_loader, desc="Validating", leave=False)
            for batch in progress_bar:
                features = batch[0].to(self.device)
                future_returns = batch[1].squeeze(2).to(self.device)
                future_returns = future_returns[:, -1, :]

                outputs = self.model(features)
                loss_dict = self.criterion(outputs, future_returns)
                loss = loss_dict['total_loss']

                batch_size = features.size(0)
                total_loss += loss.item() * batch_size
                total_samples += batch_size

                all_weights.append(outputs['weights'].cpu())
                all_returns.append(outputs['returns'].cpu())
                all_risks.append(outputs['risks'].cpu())

                progress_bar.set_postfix({'val_loss': f'{loss.item():.4f}'})

        # è®¡ç®—æƒé‡ç»Ÿè®¡
        weights = torch.cat(all_weights, dim=0)
        returns = torch.cat(all_returns, dim=0)
        risks = torch.cat(all_risks, dim=0)

        weight_stats = {
            'mean_abs_weight': weights.abs().mean().item(),
            'max_weight': weights.max().item(),
            'min_weight': weights.min().item(),
            'weight_concentration': (weights**2).sum(dim=1).mean().item(),
        }

        return total_loss / total_samples, weight_stats

    def save_checkpoint(
        self,
        model: nn.Module,
        optimizer: optim.Optimizer,
        scheduler: optim.lr_scheduler._LRScheduler,
        epoch: int,
        loss: float,
        timestamp: str,
        is_best: bool = False,
        experiment_name: str = None
    ) -> str:
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        
        # åˆ›å»ºå®éªŒç›®å½•
        if experiment_name:
            experiment_dir = os.path.join(self.model_save_dir, f"{experiment_name}_{timestamp}")
        else:
            experiment_dir = os.path.join(self.model_save_dir, f"experiment_{timestamp}")
        
        os.makedirs(experiment_dir, exist_ok=True)
        
        # ä¿å­˜å®éªŒå…ƒæ•°æ® (é¦–æ¬¡ä¿å­˜æ—¶)
        experiment_metadata_path = os.path.join(experiment_dir, 'experiment_metadata.json')
        if not os.path.exists(experiment_metadata_path):
            experiment_metadata = {
                'experiment_name': experiment_name or 'default_experiment',
                'timestamp': timestamp,
                'experiment_dir': experiment_dir,
                'created_at': datetime.now().isoformat(),
                'total_parameters': sum(p.numel() for p in model.parameters()),
                'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),
            }
            with open(experiment_metadata_path, 'w') as f:
                json.dump(experiment_metadata, f, indent=2)
        
        # æ„å»ºæ£€æŸ¥ç‚¹
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'loss': loss,
            'timestamp': timestamp,
            'experiment_dir': experiment_dir,
            'is_best': is_best,
            'saved_at': datetime.now().isoformat(),
        }
        
        # æ–‡ä»¶å
        if is_best:
            filename = f'timesfm_portfolio_model_best_{timestamp}.pth'
        else:
            filename = f'timesfm_portfolio_checkpoint_epoch_{epoch:02d}_{timestamp}.pth'
        
        checkpoint_path = os.path.join(experiment_dir, filename)
        torch.save(checkpoint, checkpoint_path)
        
        return checkpoint_path

    def train(
        self,
        train_loader,
        val_loader,
        optimizer: optim.Optimizer,
        scheduler: optim.lr_scheduler._LRScheduler,
        config: Dict[str, Any],
        experiment_name: str = None
    ) -> Tuple[Dict[str, List], float]:
        """è®­ç»ƒæ¨¡å‹"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒTimesFMæŠ•èµ„ç»„åˆä¼˜åŒ–æ¨¡å‹...")
        print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_loader)} æ‰¹æ¬¡ | éªŒè¯é›†: {len(val_loader)} æ‰¹æ¬¡")
        
        # åˆ›å»ºå®éªŒç›®å½•
        if experiment_name:
            experiment_dir = os.path.join(self.model_save_dir, f"{experiment_name}_{timestamp}")
        else:
            experiment_dir = os.path.join(self.model_save_dir, f"experiment_{timestamp}")
        
        os.makedirs(experiment_dir, exist_ok=True)
        print(f"ğŸ“ å®éªŒç›®å½•: {experiment_dir}")
        
        # ä¿å­˜é…ç½®
        config_path = os.path.join(experiment_dir, 'training_config.json')
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        print(f"âš™ï¸ è®­ç»ƒé…ç½®å·²ä¿å­˜: {os.path.basename(config_path)}")

        # è®­ç»ƒå†å²
        history = {
            'train_loss': [], 
            'val_loss': [], 
            'weight_stats': [], 
            'learning_rates': [], 
            'epochs': []
        }
        best_val_loss = float('inf')
        patience_counter = 0

        # è®­ç»ƒå¾ªç¯
        for epoch in range(config['epochs']):
            print(f"\nğŸ“ˆ Epoch [{epoch+1:3d}/{config['epochs']:3d}]")

            # è®­ç»ƒ
            train_loss = self.train_epoch(
                train_loader, 
                optimizer, 
                gradient_clip=config.get('gradient_clip', 1.0)
            )

            # éªŒè¯
            if (epoch + 1) % config.get('validate_every', 1) == 0:
                val_loss, weight_stats = self.validate_epoch(val_loader)
                history['val_loss'].append(val_loss)
                history['weight_stats'].append(weight_stats)

                print(f"ğŸ“‰ éªŒè¯æŸå¤±: {val_loss:.6f}")
                print(f"âš–ï¸  æƒé‡ç»Ÿè®¡: å¹³å‡|æƒé‡|={weight_stats['mean_abs_weight']:.4f}, é›†ä¸­åº¦={weight_stats['weight_concentration']:.4f}")

                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    patience_counter = 0
                    checkpoint_path = self.save_checkpoint(
                        self.model, optimizer, scheduler, epoch+1, val_loss, 
                        timestamp, is_best=True, experiment_name=experiment_name
                    )
                    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {os.path.basename(checkpoint_path)}")
                else:
                    patience_counter += 1
                    print(f"â³ éªŒè¯æŸå¤±æœªæ”¹å–„ ({patience_counter}/{config.get('patience', 10)})")

            # è®°å½•å†å²
            history['train_loss'].append(train_loss)
            history['learning_rates'].append(optimizer.param_groups[0]['lr'])
            history['epochs'].append(epoch + 1)

            print(f"ğŸ”¥ è®­ç»ƒæŸå¤±: {train_loss:.6f} | å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}")
            scheduler.step()

            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % config.get('save_every', 5) == 0:
                checkpoint_path = self.save_checkpoint(
                    self.model, optimizer, scheduler, epoch+1, train_loss, 
                    timestamp, is_best=False, experiment_name=experiment_name
                )
                print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {os.path.basename(checkpoint_path)}")

            # æ—©åœ
            if patience_counter >= config.get('patience', 10):
                print(f"\nâ¹ï¸  æ—©åœè§¦å‘ï¼éªŒè¯æŸå¤±{config.get('patience', 10)}ä¸ªepochæœªæ”¹å–„")
                break

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_checkpoint = self.save_checkpoint(
            self.model, optimizer, scheduler, epoch+1, train_loss, 
            timestamp, is_best=False, experiment_name=experiment_name
        )
        final_path = final_checkpoint.replace('checkpoint_epoch', 'model_final')
        os.rename(final_checkpoint, final_path)

        # ä¿å­˜è®­ç»ƒå†å²
        history_path = os.path.join(experiment_dir, f'training_summary_{timestamp}.json')
        with open(history_path, 'w') as f:
            # è½¬æ¢numpyç±»å‹ä¸ºPythonç±»å‹
            json_history = {}
            for key, value in history.items():
                if isinstance(value, list) and len(value) > 0:
                    if isinstance(value[0], dict):
                        json_history[key] = value
                    else:
                        json_history[key] = [
                            float(v) if isinstance(v, (np.float32, np.float64)) else v 
                            for v in value
                        ]
                else:
                    json_history[key] = value
            json.dump(json_history, f, indent=2)

        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ˆ æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
        print(f"ğŸ“ å®éªŒç›®å½•: {experiment_dir}")
        print(f"ğŸ“¦ æœ€ç»ˆæ¨¡å‹: {os.path.basename(final_path)}")
        print(f"ğŸ“Š è®­ç»ƒå†å²: {os.path.basename(history_path)}")
        
        return history, best_val_loss


class ExperimentManager:
    """å®éªŒç®¡ç†å·¥å…·"""
    
    def __init__(self, model_save_dir: str = "models/experiments"):
        self.model_save_dir = model_save_dir
        
    def list_experiments(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å®éªŒ"""
        if not os.path.exists(self.model_save_dir):
            print(f"âŒ æ¨¡å‹ä¿å­˜ç›®å½•ä¸å­˜åœ¨: {self.model_save_dir}")
            return []
        
        experiments = []
        for item in os.listdir(self.model_save_dir):
            item_path = os.path.join(self.model_save_dir, item)
            if os.path.isdir(item_path):
                metadata_path = os.path.join(item_path, 'experiment_metadata.json')
                if os.path.exists(metadata_path):
                    try:
                        with open(metadata_path, 'r') as f:
                            metadata = json.load(f)
                        experiments.append({
                            'dir_name': item,
                            'path': item_path,
                            'metadata': metadata
                        })
                    except:
                        print(f"âš ï¸ æ— æ³•è¯»å–å®éªŒå…ƒæ•°æ®: {metadata_path}")
        
        if experiments:
            print(f"ğŸ“ æ‰¾åˆ° {len(experiments)} ä¸ªå®éªŒ:")
            print("-" * 80)
            for exp in experiments:
                meta = exp['metadata']
                print(f"ğŸ§ª {meta.get('experiment_name', 'Unknown')}")
                print(f"   ğŸ“… åˆ›å»ºæ—¶é—´: {meta.get('created_at', 'Unknown')}")
                print(f"   ğŸ“ ç›®å½•: {exp['dir_name']}")
                print(f"   ğŸ—ï¸ å‚æ•°: {meta.get('total_parameters', 0):,}")
                print()
        else:
            print("ğŸ“­ æœªæ‰¾åˆ°ä»»ä½•å®éªŒ")
        
        return experiments

    def load_checkpoint(
        self, 
        experiment_dir: str, 
        checkpoint_type: Union[str, int] = 'best'
    ) -> Tuple[Dict[str, Any], str]:
        """åŠ è½½å®éªŒæ£€æŸ¥ç‚¹"""
        if not os.path.exists(experiment_dir):
            raise FileNotFoundError(f"å®éªŒç›®å½•ä¸å­˜åœ¨: {experiment_dir}")
        
        # æŸ¥æ‰¾æ£€æŸ¥ç‚¹æ–‡ä»¶
        checkpoint_files = []
        for file in os.listdir(experiment_dir):
            if file.endswith('.pth'):
                if checkpoint_type == 'best' and 'model_best' in file:
                    checkpoint_files.append(file)
                elif checkpoint_type == 'final' and 'model_final' in file:
                    checkpoint_files.append(file)
                elif isinstance(checkpoint_type, int) and f'epoch_{checkpoint_type:02d}' in file:
                    checkpoint_files.append(file)
        
        if not checkpoint_files:
            available_files = [f for f in os.listdir(experiment_dir) if f.endswith('.pth')]
            raise FileNotFoundError(f"æœªæ‰¾åˆ° {checkpoint_type} ç±»å‹çš„æ£€æŸ¥ç‚¹ã€‚å¯ç”¨æ–‡ä»¶: {available_files}")
        
        # åŠ è½½æœ€æ–°åŒ¹é…æ–‡ä»¶
        checkpoint_file = sorted(checkpoint_files)[-1]
        checkpoint_path = os.path.join(experiment_dir, checkpoint_file)
        
        print(f"ğŸ“¦ åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_file}")
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        return checkpoint, checkpoint_path

    def get_experiment_summary(self, experiment_dir: str) -> Dict[str, Any]:
        """è·å–å®éªŒæ‘˜è¦"""
        if not os.path.exists(experiment_dir):
            raise FileNotFoundError(f"å®éªŒç›®å½•ä¸å­˜åœ¨: {experiment_dir}")
        
        summary = {}
        
        # è¯»å–å®éªŒå…ƒæ•°æ®
        metadata_path = os.path.join(experiment_dir, 'experiment_metadata.json')
        if os.path.exists(metadata_path):
            with open(metadata_path, 'r') as f:
                summary['metadata'] = json.load(f)
        
        # è¯»å–è®­ç»ƒé…ç½®
        config_path = os.path.join(experiment_dir, 'training_config.json')
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                summary['config'] = json.load(f)
        
        # è¯»å–è®­ç»ƒå†å²
        history_files = [f for f in os.listdir(experiment_dir) if f.startswith('training_summary_')]
        if history_files:
            history_path = os.path.join(experiment_dir, sorted(history_files)[-1])
            with open(history_path, 'r') as f:
                summary['history'] = json.load(f)
        
        # åˆ—å‡ºå¯ç”¨æ£€æŸ¥ç‚¹
        checkpoints = [f for f in os.listdir(experiment_dir) if f.endswith('.pth')]
        summary['checkpoints'] = sorted(checkpoints)
        
        return summary


def create_trainer_from_config(
    model: nn.Module,
    criterion: nn.Module,
    device: torch.device,
    config: Dict[str, Any]
) -> Tuple[PortfolioTrainer, optim.Optimizer, optim.lr_scheduler._LRScheduler]:
    """ä»é…ç½®åˆ›å»ºè®­ç»ƒå™¨å’Œä¼˜åŒ–å™¨"""
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = PortfolioTrainer(
        model=model,
        criterion=criterion,
        device=device,
        model_save_dir=config.get('model_save_dir', 'models/experiments')
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.get('learning_rate', 1e-4),
        weight_decay=config.get('weight_decay', 1e-5),
        betas=(0.9, 0.999),
        eps=1e-8
    )
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = CosineAnnealingLR(
        optimizer,
        T_max=config.get('epochs', 100),
        eta_min=config.get('min_lr', 1e-6)
    )
    
    return trainer, optimizer, scheduler